"""
Streamlit interface for the Analyser IA pipeline.

Ce module est le point d'entrée principal de l'application d'analyse de données.
Il gère l'interface utilisateur et orchestre les différentes fonctionnalités.
"""
from __future__ import annotations
import os
import sys
import tempfile
import traceback
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, Union, Callable

# Configuration du chemin d'importation
sys.path.append(str(Path(__file__).parent.parent))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pandasql as psql
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import pytz
import re
import json
from typing import Dict, List, Tuple, Any, Optional, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import hashlib
import base64
import time
import traceback
from pathlib import Path
import io
from pandas.api.types import is_numeric_dtype
import streamlit as st
from pandasql import sqldf
from openpyxl.utils.dataframe import dataframe_to_rows

# Import des modules personnalisés
from analyser_ia.app.ui_enhancements import (
    set_custom_theme,
    Spinner,
    info_box,
    success_message,
    error_message,
    warning_message,
    card
)
from analyser_ia.app.caching import cache_data, clear_cache

from analyser_ia.app.ai_interpreter import interpret
from analyser_ia.app.pipeline import load_data, clean_data, run_analysis
from analyser_ia.app.report_generator import (
    export_report,
    generate_html_report,
    AUTHOR_INFO
)

# Version de l'application
VERSION = "1.0.0"
from analyser_ia.app.visualization import (
    histogram,
    boxplot,
    correlation_heatmap,
    pairplot_matrix,
    pca_scatter,
    timeseries_line,
    scatter_plot
)

# ============================================
# 1. Configuration initiale
# ============================================

# Configuration des chemins
REPORTS_DIR = Path("D:/Dev/Analyser/reports")
REPORTS_DIR.mkdir(parents=True, exist_ok=True)

# Configuration de la page
st.set_page_config(
    page_title="📊 Analyser IA | Plateforme d'Analyse de Données",
    page_icon="📊",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/your-repo/analyser-ia/issues',
        'Report a bug': 'https://github.com/your-repo/analyser-ia/issues',
        'About': "### Analyser IA\nUne application puissante pour l'analyse de données assistée par IA\n\nDéveloppé par Sidoine YEBADOKPO\nContact: +229 01 96 91 13 46"
    }
)

# Application du thème personnalisé
set_custom_theme()

# Initialisation de l'état de session
def join_dataframes(df1: pd.DataFrame, df2: pd.DataFrame, on_columns: list, how: str = 'inner') -> pd.DataFrame:
    """
    Joint deux DataFrames sur les colonnes spécifiées.
    
    Args:
        df1: Premier DataFrame
        df2: Deuxième DataFrame
        on_columns: Liste des colonnes de jointure
        how: Type de jointure ('inner', 'left', 'right', 'outer')
        
    Returns:
        DataFrame: Le résultat de la jointure
    """
    try:
        # Vérifier que les colonnes de jointure existent dans les deux DataFrames
        missing_in_df1 = [col for col in on_columns if col not in df1.columns]
        missing_in_df2 = [col for col in on_columns if col not in df2.columns]
        
        if missing_in_df1:
            raise ValueError(f"Colonnes manquantes dans la première table: {', '.join(missing_in_df1)}")
        if missing_in_df2:
            raise ValueError(f"Colonnes manquantes dans la deuxième table: {', '.join(missing_in_df2)}")
            
        # Effectuer la jointure
        return df1.merge(df2, on=on_columns, how=how)
        
    except Exception as e:
        st.error(f"Erreur lors de la jointure des tables: {str(e)}")
        return None

def init_session_state():
    """Initialise l'état de la session avec des valeurs par défaut."""
    if 'step' not in st.session_state:
        # État de l'interface utilisateur
        st.session_state.ui_state = {
            'sidebar_expanded': True,
            'show_config': False,
            'show_quick_preview': False,
            'dark_mode': False,
            'show_advanced': False,
            'selected_cols': [],
            'selected_analysis': None
        }
        
        # Configuration
        st.session_state.config = {
            'ai_model': 'GPT-4',
            'detail_level': 3,
            'require_manual_approval': True,
            'limit_query_results': True,
            'include_raw_data': True,
            'include_charts': True,
            'generate_summary': True,
            'include_source_code': False
        }
        
        # Données
        st.session_state.df_raw = None  # Données brutes
        st.session_state.df_clean = None  # Données nettoyées
        st.session_state.df_secondary = None  # Deuxième ensemble de données pour jointure
        st.session_state.df_joined = None  # Résultat de la jointure
        st.session_state.data_loaded = False  # Indique si des données sont chargées
        st.session_state.data_cleaned = False  # Indique si les données ont été nettoyées
        st.session_state.join_columns = []  # Colonnes de jointure
        st.session_state.join_type = 'inner'  # Type de jointure par défaut
        
        # Navigation
        st.session_state.step = 0  # Étape actuelle (0=Contexte, 1=Chargement, 2=Nettoyage, 3=Analyse, 4=Rapport)
        st.session_state.previous_step = None  # Étape précédente pour la navigation
        st.session_state.app_start_time = datetime.now()  # Heure de démarrage de la session
        st.session_state.last_interaction = None  # Dernière interaction utilisateur
        
        # Contexte et objectifs
        st.session_state.context_objective = ""  # Objectif de l'analyse
        st.session_state.context_metrics = []  # Métriques clés à surveiller
        st.session_state.context_constraints = []  # Contraintes connues
        
        # Requêtes et analyses
        st.session_state.suggested_queries = []  # Requêtes suggérées par l'IA
        st.session_state.custom_queries = []  # Requêtes personnalisées de l'utilisateur
        st.session_state.custom_analysis_results = {}  # Résultats des analyses personnalisées
        st.session_state.selected_analysis_types = ["Statistiques descriptives", "Corrélations"]  # Types d'analyses sélectionnés
        st.session_state.widget_counter = 0  # Compteur pour les clés uniques
        
        # Sorties et résultats
        st.session_state.outputs = []
        
        # Configuration et paramètres
        st.session_state.cleaning_steps = []  # Étapes de nettoyage appliquées
        st.session_state.config_saved = False  # Configuration enregistrée
        st.session_state.generated_code = None  # Code généré
        st.session_state.show_generated_code = False  # Afficher le code généré
        st.session_state.cache_enabled = True  # Activer la mise en cache
        st.session_state.performance_mode = False  # Mode performance (désactive certaines fonctionnalités)

# ============================================
# 2. Fonctions utilitaires
# ============================================

def generate_interpretation(data):
    """
    Génère une interprétation automatique des données d'un DataFrame ou d'une structure de données.
    
    Args:
        data: Données à analyser (DataFrame, Series, dict, list, résultats de modèle, etc.)
        
    Returns:
        str: Interprétation textuelle des données
    """
    try:
        # Vérifier si les données sont vides
        if data is None:
            return "Aucune donnée à analyser (None)."
        
        # Vérifier si c'est un résultat de régression statsmodels
        if hasattr(data, 'summary'):
            return _interpret_regression_results(data)
            
        # Vérifier si c'est une liste de résultats
        if isinstance(data, (list, tuple)) and len(data) > 0:
            # Si le premier élément est un résultat de régression
            if hasattr(data[0], 'summary'):
                return _interpret_regression_results(data[0])
            # Si c'est une liste de DataFrames ou de résultats
            interpretations = []
            for i, item in enumerate(data):
                if hasattr(item, 'summary'):  # Résultat de régression
                    interpretations.append(f"## Résultat de régression {i+1}")
                    interpretations.append(_interpret_regression_results(item))
                elif hasattr(item, 'to_string'):  # DataFrame ou similaire
                    try:
                        df = pd.DataFrame(item) if not isinstance(item, pd.DataFrame) else item
                        interpretations.append(f"## Tableau de données {i+1}")
                        interpretations.append(_analyze_dataframe(df))
                    except:
                        interpretations.append(f"## Élément {i+1}")
                        interpretations.append(f"Type: {type(item).__name__}")
                        interpretations.append(str(item)[:500] + ("..." if len(str(item)) > 500 else ""))
            
            if interpretations:
                return "\n\n".join(interpretations)
            
        # Convertir en DataFrame si ce n'en est pas un
        if not isinstance(data, pd.DataFrame):
            if hasattr(data, 'to_frame'):
                return _analyze_dataframe(data.to_frame())
            elif hasattr(data, 'to_dict'):
                return _analyze_dataframe(pd.DataFrame(data.to_dict()))
            elif isinstance(data, (dict, list, tuple)) and data:
                try:
                    return _analyze_dataframe(pd.DataFrame(data))
                except Exception as e:
                    return f"### ❌ Erreur de conversion\nImpossible de convertir les données en DataFrame: {str(e)}"
            else:
                # Pour les types simples (nombres, chaînes, etc.)
                return f"### 📋 Résultat\nValeur unique : {data}"
        
        # Si on arrive ici, c'est un DataFrame
        return _analyze_dataframe(data)
    
    except Exception as e:
        # En cas d'erreur, retourner un message d'erreur détaillé
        error_msg = [
            "### ❌ Erreur lors de l'analyse",
            "Impossible de générer une interprétation automatique.",
            "",
            f"**Détails de l'erreur:**",
            f"```",
            f"{str(e)[:1000]}",  # Limiter la taille pour éviter les problèmes d'affichage
            f"```",
            "",
            f"**Type de données reçu:** {type(data).__name__}",
            ""
        ]
        
        # Ajouter un aperçu des données si possible
        try:
            if hasattr(data, 'head') and callable(data.head):
                error_msg.extend([
                    "",
                    "**Aperçu des données:**",
                    f"```",
                    f"{data.head().to_string()}",
                    f"```"
                ])
            elif hasattr(data, '__str__'):
                error_msg.extend([
                    "",
                    "**Contenu:**",
                    f"```",
                    f"{str(data)[:1000]}",
                    f"..." if len(str(data)) > 1000 else "",
                    f"```"
                ])
        except:
            pass
            
        return "\n".join(str(item) for item in error_msg)

def _interpret_regression_results(reg_result):
    """Interprète les résultats d'une régression statsmodels."""
    try:
        interpretation = ["## 📈 Résultats de la régression linéaire"]
        
        # Récupérer le résumé sous forme de texte
        summary = str(reg_result.summary())
        
        # Extraire les informations clés avec des expressions régulières
        import re
        
        # R-carré
        r_sq = re.search(r'R-squared:\s+([0-9.]+)', summary)
        adj_r_sq = re.search(r'Adj. R-squared:\s+([0-9.]+)', summary)
        
        if r_sq and adj_r_sq:
            interpretation.append(f"- **Qualité du modèle**:")
            interpretation.append(f"  - R² = {float(r_sq.group(1)):.3f} (plus proche de 1, meilleur est le modèle)")
            interpretation.append(f"  - R² ajusté = {float(adj_r_sq.group(1)):.3f} (tient compte du nombre de variables)")
        
        # Variables et coefficients
        coef_section = re.search(r'={5,}\n(.+?)\n={5,}', summary, re.DOTALL)
        if coef_section:
            interpretation.append("\n### 🔍 Coefficients du modèle:")
            lines = coef_section.group(1).strip().split('\n')
            
            # En-tête
            if len(lines) > 1:
                headers = [h.strip() for h in re.split('\s{2,}', lines[0].strip()) if h.strip()]
                var_lines = lines[2:]  # Sauter l'en-tête et la ligne de séparation
                
                for line in var_lines:
                    if not line.strip():
                        continue
                    parts = [p.strip() for p in re.split('\s{2,}', line.strip()) if p.strip()]
                    if len(parts) >= len(headers):
                        var_name = parts[0]
                        coef = parts[1]
                        p_value = parts[4] if len(parts) > 4 else 'N/A'
                        ci_low = parts[5] if len(parts) > 5 else 'N/A'
                        ci_high = parts[6] if len(parts) > 6 else 'N/A'
                        
                        interpretation.append(f"- **{var_name}**:")
                        interpretation.append(f"  - Coefficient = {coef}")
                        interpretation.append(f"  - p-valeur = {p_value}")
                        interpretation.append(f"  - Intervalle de confiance à 95%: [{ci_low}, {ci_high}]")
        
        # Tests de diagnostic
        diag_section = re.search(r'Omnibus:.+', summary, re.DOTALL)
        if diag_section:
            interpretation.append("\n### 🔍 Tests de diagnostic:")
            diag_lines = diag_section.group(0).split('\n')
            for line in diag_lines:
                if ':' in line:
                    test, value = line.split(':', 1)
                    interpretation.append(f"- **{test.strip()}**: {value.strip()}")
        
        # Notes et avertissements
        if 'Notes:' in summary:
            notes = summary.split('Notes:')[1].strip()
            if notes:
                interpretation.append("\n### ⚠️ Notes importantes:")
                for note in notes.split('\n'):
                    if note.strip():
                        interpretation.append(f"- {note.strip()}")
        
        # Interprétation du R²
        if r_sq:
            r2 = float(r_sq.group(1))
            interpretation.append("\n### 📊 Interprétation du R²:")
            if r2 < 0.2:
                interpretation.append("- Le modèle explique très peu de la variance des données (R² < 0.2).")
            elif r2 < 0.5:
                interpretation.append("- Le modèle explique une partie modeste de la variance des données (0.2 ≤ R² < 0.5).")
            elif r2 < 0.7:
                interpretation.append("- Le modèle explique une part substantielle de la variance des données (0.5 ≤ R² < 0.7).")
            else:
                interpretation.append("- Le modèle explique bien la variance des données (R² ≥ 0.7).")
        
        return "\n".join(interpretation)
    
    except Exception as e:
        return f"### ❌ Erreur d'interprétation des résultats de régression\n{str(e)}"

def _analyze_dataframe(df):
    """Analyse un DataFrame et retourne une interprétation."""
    try:
        interpretation = []
        
        # Vérifier si le DataFrame est vide
        if df.empty:
            return "Aucune donnée à analyser (DataFrame vide)."
        
        # Informations de base
        interpretation.append("### 📊 Aperçu des données")
        interpretation.append(f"- Nombre de lignes : {len(df)}")
        interpretation.append(f"- Nombre de colonnes : {len(df.columns)}")
        
        # Aperçu des colonnes
        interpretation.append("\n### 📋 Aperçu des colonnes")
        for col in df.columns:
            try:
                dtype = str(df[col].dtype)
                unique_count = df[col].nunique()
                interpretation.append(f"- **{col}** (*{dtype}*) : {unique_count} valeurs uniques")
            except Exception as e:
                interpretation.append(f"- **{col}** : Erreur lors de l'analyse")
        
        # Analyse des colonnes numériques
        try:
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            if numeric_cols:
                interpretation.append("\n### 🔢 Variables numériques")
                
                for col in numeric_cols[:10]:  # Limiter à 10 colonnes
                    try:
                        if is_numeric_dtype(df[col]):
                            stats = df[col].describe()
                            interpretation.append(
                                f"- **{col}**: "
                                f"Moyenne = {stats.get('mean', 'N/A'):.2f}, "
                                f"Médiane = {stats.get('50%', 'N/A'):.2f}, "
                                f"Min = {stats.get('min', 'N/A')}, "
                                f"Max = {stats.get('max', 'N/A')}"
                            )
                    except Exception as e:
                        interpretation.append(f"- **{col}**: Impossible d'analyser cette colonne numérique")
        except Exception as e:
            interpretation.append("\n⚠️ Impossible d'analyser les variables numériques")
        
        # Analyse des colonnes catégorielles
        try:
            cat_cols = df.select_dtypes(include=['object', 'category', 'bool', 'string']).columns.tolist()
            if cat_cols:
                interpretation.append("\n### 🔤 Variables catégorielles")
                
                for col in cat_cols[:10]:  # Limiter à 10 colonnes
                    try:
                        unique_count = df[col].nunique()
                        if unique_count < 20:  # Limite pour éviter les sorties trop longues
                            value_counts = df[col].value_counts().head(5)
                            interpretation.append(f"- **{col}**: {unique_count} valeurs uniques")
                            for val, count in value_counts.items():
                                interpretation.append(f"  - {val}: {count} ({count/len(df)*100:.1f}%)")
                        else:
                            interpretation.append(f"- **{col}**: {unique_count} valeurs uniques (trop pour l'affichage)")
                    except Exception as e:
                        interpretation.append(f"- **{col}**: Impossible d'analyser cette colonne catégorielle")
        except Exception as e:
            interpretation.append("\n⚠️ Impossible d'analyser les variables catégorielles")
        
        # Détection des corrélations pour les données numériques
        try:
            if len(numeric_cols) > 1:
                # Calculer la matrice de corrélation
                corr_matrix = df[numeric_cols].corr()
                # Obtenir les paires de corrélations
                corr_pairs = corr_matrix.unstack().sort_values(ascending=False)
                # Filtrer les corrélations avec soi-même et les doublons
                corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]
                corr_pairs = corr_pairs[~corr_pairs.index.duplicated()]
                # Prendre les 3 premières corrélations les plus fortes
                corr_pairs = corr_pairs.head(3)
                
                if len(corr_pairs) > 0:
                    interpretation.append("\n### 🔗 Corrélations notables")
                    for (col1, col2), value in corr_pairs.items():
                        if abs(value) > 0.5:  # Seuil de corrélation modéré
                            direction = "positive" if value > 0 else "négative"
                            interpretation.append(
                                f"- Corrélation {direction} entre **{col1}** et **{col2}** "
                                f"(r = {value:.2f})"
                            )
        except Exception as e:
            # En cas d'erreur, on passe simplement à la suite
            pass
        
        # Conseils d'analyse
        interpretation.append("\n### 💡 Conseils pour l'analyse")
        if numeric_cols:
            interpretation.append("- Visualisez la distribution des variables numériques avec des histogrammes")
        if cat_cols:
            interpretation.append("- Explorez les relations entre variables catégorielles avec des diagrammes en barres ou camemberts")
        if len(numeric_cols) >= 2:
            interpretation.append("- Examinez les relations entre variables numériques avec des nuages de points ou des matrices de corrélation")
        
        return "\n".join(str(item) for item in interpretation)
    
    except Exception as e:
        return f"### ❌ Erreur lors de l'analyse du DataFrame\n{str(e)}"

def generate_ai_interpretation(context: str, data_description: str, chart_type: str = "") -> str:
    """
    Génère une interprétation automatique des données ou graphiques.
    
    Args:
        context: Contexte de l'analyse (description de ce qui est affiché)
        data_description: Description des données (statistiques, tendances, valeurs clés)
        chart_type: Type de graphique (optionnel)
        
    Returns:
        str: Interprétation générée par l'IA
    """
    try:
        # Construction du prompt pour l'IA
        prompt = f"""
        Tu es un expert en analyse de données. Analyse les informations suivantes et fournis une interprétation claire et concise en français.
        
        Contexte: {context}
        Type de visualisation: {chart_type if chart_type else 'Tableau de données'}
        Données: {data_description}
        
        Fournis une analyse en 3 parties:
        1. Ce que montrent les données
        2. Les tendances ou points marquants
        3. 1-2 recommandations d'actions basées sur ces données
        """
        
        return call_gemini_api(prompt)
        
    except Exception as e:
        st.warning(f"Impossible de générer l'interprétation: {str(e)}")
        return ""

def display_with_interpretation(content, context: str, data_description: str, chart_type: str = ""):
    """
    Affiche un contenu (graphique ou tableau) avec son interprétation automatique.
    """
    # Afficher le contenu principal
    st.write(content)
    
    # Générer et afficher l'interprétation
    with st.expander("🔍 Interprétation automatique", expanded=True):
        with st.spinner("Génération de l'interprétation..."):
            interpretation = generate_ai_interpretation(context, data_description, chart_type)
            if interpretation:
                st.markdown(interpretation)
            else:
                st.info("Impossible de générer une interprétation pour ces données.")

def call_gemini_api(prompt: str, model_name: str = "gemini-1.5-flash") -> str:
    """
    Appelle l'API Gemini avec le prompt donné et retourne la réponse.
    
    Args:
        prompt: Le prompt à envoyer à l'API
        model_name: Le nom du modèle à utiliser (par défaut: gemini-1.5-flash)
        
    Returns:
        str: La réponse de l'API ou un message d'erreur
    """
    try:
        import google.generativeai as genai
        
        # Configuration de l'API (à sécuriser dans les variables d'environnement)
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("Clé API Google non configurée. Veuillez définir la variable d'environnement GEMINI_API_KEY dans le fichier .env")
            
        genai.configure(api_key=api_key)
        
        # Liste des modèles disponibles avec leurs priorités
        available_models = [
            "gemini-1.5-flash",      # Dernier modèle Flash (rapide et efficace)
            "gemini-1.5-pro",        # Dernier modèle Pro (plus puissant)
            "gemini-pro"             # Ancien modèle Pro (rétrocompatibilité)
        ]
        
        # Si le modèle demandé n'est pas disponible, on essaie les autres dans l'ordre
        if model_name not in available_models:
            model_name = available_models[0]  # Utilise le premier modèle disponible
            
        st.session_state.last_used_model = model_name  # Sauvegarder le modèle utilisé
        
        # Création du modèle
        model = genai.GenerativeModel(model_name)
        
        # Configuration de la génération
        generation_config = {
            "temperature": 0.7,
            "top_p": 1,
            "top_k": 40,
            "max_output_tokens": 2048,
        }
        
        # Appel à l'API
        response = model.generate_content(
            prompt,
            generation_config=generation_config,
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        # Vérification de la réponse
        if not response or not response.text:
            raise ValueError("Réponse vide de l'API Gemini")
            
        return response.text
        
    except Exception as e:
        raise Exception(f"Erreur lors de l'appel à l'API Gemini: {str(e)}")
        


def safe_json(obj: Any, label: str) -> None:
    """Affiche un objet JSON ou une erreur lisible si ce n'est pas un dict."""
    st.subheader(label)
    if isinstance(obj, dict):
        st.json(obj, expanded=False)
    else:
        st.error(str(obj))

def reset_analysis():
    """Réinitialise les étapes d'analyse."""
    st.session_state.df_clean = None
    st.session_state.step = 1

def detect_analysis_type(query: str) -> str:
    """
    Détecte le type d'analyse à partir d'une requête en langage naturel.
    
    Args:
        query: La requête en langage naturel
        
    Returns:
        str: Le type d'analyse détecté ('time_series', 'correlation', 'distribution', 'groupby', 'other')
    """
    if not query or not isinstance(query, str):
        return 'other'
        
    query = query.lower()
    
    # Détection des séries temporelles
    time_keywords = ['série temporelle', 'évolution dans le temps', 'tendance', 'au fil du temps',
                   'historique', 'période', 'date', 'mois', 'année', 'jour', 'heure']
    if any(keyword in query for keyword in time_keywords):
        return 'time_series'
    
    # Détection des corrélations
    corr_keywords = ['corrélation', 'relation entre', 'lié à', 'associé à', 'dépend de',
                   'influence de', 'impact de', 'lien entre']
    if any(keyword in query for keyword in corr_keywords):
        return 'correlation'
    
    # Détection des distributions
    dist_keywords = ['distribution', 'répartition', 'histogramme', 'fréquence', 
                   'densité', 'distribution des valeurs']
    if any(keyword in query for keyword in dist_keywords):
        return 'distribution'
    
    # Détection des regroupements
    group_keywords = ['par catégorie', 'par région', 'par type', 'grouper par', 
                    'regrouper par', 'agréger par', 'agrégation par']
    if any(keyword in query for keyword in group_keywords):
        return 'groupby'
        
    # Par défaut, retourner 'other' si aucun type spécifique n'est détecté
    return 'other'

def clean_column_name(column_name: str) -> str:
    """
    Nettoie un nom de colonne en supprimant les balises HTML et en remplaçant les caractères spéciaux.
    
    Args:
        column_name: Nom de la colonne à nettoyer
        
    Returns:
        str: Nom de colonne nettoyé et valide
        
    Exemples:
        >>> clean_column_name("Nom de l'article")
        'nom_de_l_article'
        >>> clean_column_name("Prix (€)")
        'prix_eur'
        >>> clean_column_name("  Date d'achat  ")
        'date_d_achat'
    """
    if not isinstance(column_name, str):
        column_name = str(column_name)
        
    # Suppression des balises HTML
    clean_name = re.sub(r'<[^>]*>', '', column_name)
    
    # Remplacement des caractères spéciaux par des underscores
    # Conversion en minuscules pour la cohérence
    clean_name = clean_name.lower()
    
    # Remplacement des caractères accentués
    clean_name = (
        clean_name
        .replace('é', 'e').replace('è', 'e').replace('ê', 'e')
        .replace('à', 'a').replace('â', 'a')
        .replace('î', 'i').replace('ï', 'i')
        .replace('ô', 'o').replace('ö', 'o')
        .replace('ù', 'u').replace('û', 'u').replace('ü', 'u')
        .replace('ç', 'c')
    )
    
    # Remplacement des caractères spéciaux
    clean_name = re.sub(r'[^a-z0-9_]+', '_', clean_name)
    
    # Suppression des underscores multiples
    clean_name = re.sub(r'_+', '_', clean_name)
    
    # Suppression des underscores en début et fin
    clean_name = clean_name.strip('_')
    
    # Vérification que le nom n'est pas vide après nettoyage
    if not clean_name:
        clean_name = 'unnamed_column'
    
    # Vérification que le nom ne commence pas par un chiffre (invalide en Python)
    if clean_name[0].isdigit():
        clean_name = f'col_{clean_name}'
    
    return clean_name

def clean_dataframe_columns(df: pd.DataFrame, inplace: bool = False) -> pd.DataFrame:
    """
    Nettoie les noms de colonnes d'un DataFrame.
    
    Args:
        df: DataFrame dont les colonnes doivent être nettoyées
        inplace: Si True, modifie le DataFrame en place. Sinon, retourne une copie.
        
    Returns:
        DataFrame: DataFrame avec des noms de colonnes nettoyés
        
    Exemples:
        >>> df = pd.DataFrame({'Nom du client': [1], 'Âge (ans)': [25]})
        >>> clean_dataframe_columns(df).columns.tolist()
        ['nom_du_client', 'age_ans']
    """
    if df is None:
        return None
        
    if df.empty:
        return df.copy() if not inplace else df
    
    # Création d'un dictionnaire de mappage des anciens noms vers les nouveaux
    column_mapping = {}
    name_counts = {}
    
    for col in df.columns:
        clean_name = clean_column_name(col)
        
        # Gestion des doublons potentiels après nettoyage
        if clean_name in name_counts:
            name_counts[clean_name] += 1
            clean_name = f"{clean_name}_{name_counts[clean_name]}"
        else:
            name_counts[clean_name] = 0
            
        column_mapping[col] = clean_name
    
    # Vérification des colonnes en double après nettoyage
    if len(column_mapping) != len(set(column_mapping.values())):
        duplicates = {}
        for orig, new in column_mapping.items():
            duplicates[new] = duplicates.get(new, []) + [orig]
        
        duplicates = {k: v for k, v in duplicates.items() if len(v) > 1}
        if duplicates:
            st.warning(f"Attention : Certaines colonnes ont le même nom après nettoyage : {duplicates}")
    
    # Application du nettoyage des noms de colonnes
    if inplace:
        df.rename(columns=column_mapping, inplace=True)
        return df
    else:
        return df.rename(columns=column_mapping)

def split_sql_queries(sql: str) -> list:
    """
    Divise une chaîne SQL contenant plusieurs requêtes en une liste de requêtes individuelles.
    Gère les blocs BEGIN/END et les procédures stockées.
    
    Args:
        sql: Chaîne SQL contenant potentiellement plusieurs requêtes
        
    Returns:
        list: Liste des requêtes SQL individuelles
        
    Exemples:
    ```python
    # Séparation de requêtes simples
    split_sql_queries("SELECT * FROM table1; SELECT * FROM table2;")
    # Retourne: ['SELECT * FROM table1', 'SELECT * FROM table2']
    ```
    """
    if not sql or not isinstance(sql, str):
        return []
        
    # Suppression des commentaires (lignes commençant par --)
    sql = re.sub(r'--.*?$', '', sql, flags=re.MULTILINE)
    # Suppression des commentaires multi-lignes (/* ... */)
    sql = re.sub(r'/\*.*?\*/', '', sql, flags=re.DOTALL)
    
    # Normalisation des espaces blancs
    sql = ' '.join(sql.split())
    
    # Détection des blocs BEGIN...END et procédures
    queries = []
    current_query = []
    in_block = False
    block_level = 0
    
    # Parcours caractère par caractère
    i = 0
    n = len(sql)
    while i < n:
        # Vérification des blocs BEGIN...END
        if sql.startswith('BEGIN', i) and (i == 0 or not sql[i-1].isalnum()):
            in_block = True
            block_level += 1
            current_query.append('BEGIN')
            i += 5
            continue
            
        if sql.startswith('END', i) and (i == 0 or not sql[i-1].isalnum()):
            block_level = max(0, block_level - 1)
            current_query.append('END')
            i += 3
            if block_level == 0:
                in_block = False
            continue
        
        # Gestion des points-virgules
        if sql[i] == ';' and not in_block:
            query = ''.join(current_query).strip()
            if query:
                queries.append(query)
            current_query = []
        else:
            current_query.append(sql[i])
            
        i += 1
    
    # Ajout de la dernière requête si elle existe
    last_query = ''.join(current_query).strip()
    if last_query:
        queries.append(last_query)
    
    # Nettoyage des requêtes vides
    return [q for q in queries if q.strip()]

def execute_sql_query(query: str, df: pd.DataFrame, max_rows: int = 10000) -> tuple[bool, str, pd.DataFrame | None]:
    """
    Exécute une seule requête SQL sur un DataFrame avec gestion des erreurs et des performances.
    
    Args:
        query: Requête SQL à exécuter
        df: DataFrame source
        max_rows: Nombre maximum de lignes à retourner (pour éviter les fuites de mémoire)
        
    Returns:
        tuple: (succès: bool, message: str, résultat: DataFrame ou None)
        
    Exemples:
        >>> df = pd.DataFrame({'nom': ['Alice', 'Bob'], 'age': [25, 30]})
        >>> success, msg, result = execute_sql_query("SELECT * FROM df WHERE age > 25", df)
        >>> success
        True
        >>> len(result)
        1
    """
    # Vérification des entrées
    if not query or not isinstance(query, str) or not query.strip():
        return False, "La requête SQL ne peut pas être vide.", None
        
    if df is None or df.empty:
        return False, "Le DataFrame source est vide.", None
    
    try:
        # Nettoyage de la requête
        query = query.strip()
        
        # Vérification des requêtes potentiellement dangereuses (optionnel)
        if any(cmd in query.upper() for cmd in ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER']):
            return False, "Les opérations de modification de données ne sont pas autorisées.", None
        
        # Nettoyage des noms de colonnes dans le DataFrame
        start_time = time.time()
        df_clean = clean_dataframe_columns(df)
        clean_time = time.time() - start_time
        
        # Limitation du nombre de lignes pour les requêtes non limitées
        if 'LIMIT' not in query.upper():
            query = f"{query.rstrip(';')} LIMIT {max_rows}"
        
        # Exécution de la requête avec gestion du temps d'exécution
        start_time = time.time()
        try:
            result = psql.sqldf(query, {'df': df_clean})
            exec_time = time.time() - start_time
            
            # Vérification si le résultat est vide
            if result is None or result.empty:
                return False, "La requête n'a retourné aucun résultat.", None
                
            # Nettoyage des noms de colonnes dans le résultat
            result = clean_dataframe_columns(result)
            
            # Journalisation des performances
            st.session_state.setdefault('query_metrics', []).append({
                'query': query[:100] + ('...' if len(query) > 100 else ''),
                'execution_time': round(exec_time, 4),
                'clean_time': round(clean_time, 4),
                'result_rows': len(result),
                'result_columns': list(result.columns),
                'timestamp': time.time()
            })
            
            return True, f"Requête exécutée en {exec_time:.2f}s. {len(result)} lignes retournées.", result
            
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            
            # Messages d'erreur plus conviviaux
            if 'no such table' in error_msg.lower():
                error_msg = "Erreur: La table spécifiée n'existe pas. Vérifiez le nom de la table dans votre requête."
            elif 'no such column' in error_msg.lower():
                error_msg = f"Erreur: Colonne non trouvée. Vérifiez les noms des colonnes: {', '.join(df_clean.columns)}"
            elif 'syntax error' in error_msg.lower():
                error_msg = f"Erreur de syntaxe SQL: {error_msg}"
                
            return False, f"Erreur lors de l'exécution de la requête: {error_msg}", None
            
    except Exception as e:
        # Erreur inattendue
        error_msg = f"Erreur inattendue: {str(e)}"
        st.error(f"Erreur critique: {error_msg}")
        import traceback
        st.error(traceback.format_exc())
        return False, error_msg, None

def execute_code(
    code: str, 
    code_type: str, 
    df: pd.DataFrame,
    max_rows: int = 10000,
    timeout: int = 30
) -> tuple[bool, str, dict[str, any] | pd.DataFrame | None]:
    """
    Exécute du code SQL ou Python sur un DataFrame avec gestion des erreurs et des performances.
    
    Args:
        code: Code SQL ou Python à exécuter
        code_type: 'sql' ou 'python'
        df: DataFrame source pour l'exécution
        max_rows: Nombre maximum de lignes à retourner (pour SQL)
        timeout: Délai d'expiration en secondes pour l'exécution
        
    Returns:
        tuple: (succès: bool, message: str, résultat: DataFrame/dict ou None)
        
    Exemples:
    ```python
    # Exemple avec SQL
    df = pd.DataFrame({'nom': ['Alice', 'Bob'], 'age': [25, 30]})
    success, msg, result = execute_code("SELECT * FROM df WHERE age > 25", 'sql', df)
    print(success)  # True
    
    # Exemple avec Python
    code = """
    result = df[df['age'] > 25].copy()
    result['categorie'] = pd.cut(
        result['age'], 
        bins=[0, 30, 100],
        labels=['jeune', 'adulte']
    )
    """
    success, msg, result = execute_code(code, 'python', df)
    print(success)  # True
    ```
    """
    if not code or not isinstance(code, str) or not code.strip():
        return False, "Le code ne peut pas être vide.", None
        
    if df is None or df.empty:
        return False, "Le DataFrame source est vide.", None
    
    code_type = code_type.lower()
    if code_type not in ('sql', 'python'):
        return False, f"Type de code non pris en charge: {code_type}. Utilisez 'sql' ou 'python'.", None
    
    # Journalisation de l'exécution
    exec_id = f"{code_type}_{int(time.time())}"
    st.session_state.setdefault('execution_logs', {})[exec_id] = {
        'code_type': code_type,
        'code': code,
        'timestamp': time.time(),
        'success': False
    }
    
    try:
        if code_type == 'sql':
            # Division des requêtes multiples
            queries = split_sql_queries(code)
            
            if not queries:
                return False, "Aucune requête valide trouvée.", None
                
            results = {}
            start_time = time.time()
            
            for i, query in enumerate(queries, 1):
                # Vérification du timeout
                if time.time() - start_time > timeout:
                    return False, f"Délai d'exécution dépassé ({timeout}s) à la requête {i}/{len(queries)}.", None
                
                success, message, result = execute_sql_query(query, df, max_rows)
                if not success:
                    return False, f"Erreur dans la requête {i}/{len(queries)}: {message}", None
                    
                results[f"requete_{i}"] = {
                    'query': query,
                    'result': result,
                    'message': message
                }
            
            # Mise à jour du journal d'exécution
            exec_time = time.time() - start_time
            st.session_state['execution_logs'][exec_id].update({
                'success': True,
                'execution_time': round(exec_time, 2),
                'num_queries': len(queries),
                'result_columns': [list(r['result'].columns) for r in results.values() if hasattr(r['result'], 'columns')]
            })
            
            # Si une seule requête, on retourne directement le résultat
            if len(results) == 1:
                return True, results["requete_1"]['message'], results["requete_1"]['result']
            # Sinon on retourne un dictionnaire avec tous les résultats
            else:
                return True, f"{len(queries)} requêtes exécutées avec succès en {exec_time:.2f}s.", results
                
        elif code_type == 'python':
            start_time = time.time()
            
            # Création d'un espace de noms sécurisé pour l'exécution
            safe_globals = {
                'pd': pd,
                'np': np,
                'px': px,
                'go': go,
                'time': time,
                'datetime': datetime,
                'timedelta': timedelta
            }
            
            local_vars = {
                'df': df.copy(),
                'result': None
            }
            
            # Code de préfixe pour l'importation des bibliothèques
            prefix = """
# Importations standards
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import time
from datetime import datetime, timedelta

# Initialisation du résultat
result = None
"""
            # Exécution du code Python avec gestion du timeout
            try:
                # Exécution dans un thread séparé pour le timeout
                from concurrent.futures import ThreadPoolExecutor, TimeoutError as ThreadTimeoutError
                
                def execute():
                    exec(prefix + code, safe_globals, local_vars)
                    return local_vars.get('result')
                
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(execute)
                    result = future.result(timeout=timeout)
                    
            except ThreadTimeoutError:
                return False, f"Délai d'exécution dépassé ({timeout}s). Le code Python est trop long.", None
                
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                
                # Messages d'erreur plus conviviaux
                if 'NameError' in error_type:
                    error_msg = f"Erreur de nom: {error_msg}"
                elif 'TypeError' in error_type:
                    error_msg = f"Erreur de type: {error_msg}"
                elif 'KeyError' in error_type:
                    error_msg = f"Clé non trouvée: {error_msg}"
                    
                return False, f"Erreur Python: {error_msg}", None
            
            # Calcul du temps d'exécution
            exec_time = time.time() - start_time
            
            # Vérification du résultat
            result = local_vars.get('result')
            if result is not None:
                # Si le résultat est un DataFrame, on le nettoie
                if isinstance(result, pd.DataFrame):
                    result = clean_dataframe_columns(result)
                    
                    # Journalisation des performances
                    st.session_state['execution_logs'][exec_id].update({
                        'success': True,
                        'execution_time': round(exec_time, 2),
                        'result_type': 'dataframe',
                        'result_shape': result.shape,
                        'result_columns': list(result.columns) if hasattr(result, 'columns') else []
                    })
                    
                    return True, f"Code exécuté avec succès en {exec_time:.2f}s. Résultat: {result.shape[0]} lignes x {result.shape[1]} colonnes.", result
                else:
                    # Autres types de résultats
                    result_type = type(result).__name__
                    st.session_state['execution_logs'][exec_id].update({
                        'success': True,
                        'execution_time': round(exec_time, 2),
                        'result_type': result_type,
                        'result_value': str(result)[:500]  # Limiter la taille pour éviter les problèmes de sérialisation
                    })
                    return True, f"Code exécuté avec succès en {exec_time:.2f}s. Type de résultat: {result_type}", result
            else:
                st.session_state['execution_logs'][exec_id].update({
                    'success': True,
                    'execution_time': round(exec_time, 2),
                    'result_type': 'none'
                })
                return True, "Code exécuté avec succès (pas de résultat retourné).", None
                
    except Exception as e:
        # Erreur inattendue
        error_type = type(e).__name__
        error_msg = str(e)
        
        # Journalisation de l'erreur
        st.session_state['execution_logs'][exec_id].update({
            'error_type': error_type,
            'error_message': error_msg,
            'traceback': traceback.format_exc()
        })
        
        return False, f"Erreur inattendue: {error_type} - {error_msg}", None

def generate_query_code(query: str, query_type: str, df_columns: list) -> str:
    """
    Génère du code SQL ou Python à partir d'une description en langage naturel.
    
    Args:
        query: Description en langage naturel de la requête
        query_type: 'sql' ou 'python'
        df_columns: Liste des colonnes disponibles dans le DataFrame
        
    Returns:
        str: Le code généré
    """
    try:
        columns_str = ", ".join(df_columns)
        prompt = f"""
        Je veux effectuer l'analyse suivante sur un DataFrame pandas :
        "{query}"

        Colonnes disponibles : {columns_str}

        Génère uniquement le code {query_type.upper()} nécessaire, sans explications supplémentaires.
        Pour SQL, utilise 'df' comme nom de table.
        Pour Python, stocke le résultat dans une variable 'result'.
        """

        if query_type.lower() == 'sql':
            # Génération d'une requête SQL basique si l'IA échoue
            return f"""-- Requête générée pour : {query}
SELECT * 
FROM df 
WHERE {df_columns[0]} IS NOT NULL 
LIMIT 10;"""
        else:  # Python
            # Génération d'un code Python basique si l'IA échoue
            if len(df_columns) >= 2:
                return f"""# {query}
result = df[['{df_columns[0]}', '{df_columns[1]}']].head()"""
            else:
                return f"""# {query}
result = df[['{df_columns[0]}']].head()"""
                
    except Exception as e:
        st.error(f"Erreur lors de la génération du code : {str(e)}")
        # En cas d'erreur, on retourne une requête simple mais valide
        if query_type.lower() == 'sql':
            return "-- Requête par défaut\nSELECT * FROM df LIMIT 10;"
        else:
            # Retourne un code Python minimal qui fonctionnera avec n'importe quel DataFrame
            return "# Code par défaut\nresult = df.head()"
            return f"# {query}\nresult = df.head()"

# ============================================
# 3. Barre latérale
# ============================================

def render_sidebar():
    """Affiche la barre latérale avec la navigation et les contrôles principaux."""
    with st.sidebar:
        # En-tête avec logo et titre
        col1, col2 = st.columns([1, 3])
        with col1:
            st.image("https://via.placeholder.com/60", width=60)  # Remplacer par votre logo
        with col2:
            st.markdown("# Analyser IA")
            st.caption("Analyse de données assistée par IA")
        
        st.markdown("---")
        
        # Menu de navigation
        with st.expander("🔍 Navigation", expanded=st.session_state.ui_state['sidebar_expanded']):
            steps = ["1. Contexte", "2. Chargement", "3. Nettoyage", "4. Analyse", "5. Rapport"]
            for i, step in enumerate(steps):
                # Mise en forme de l'étape actuelle
                if i == st.session_state.step:
                    st.markdown(f"**➡️ {step}**")
                # Étapes terminées
                elif i < st.session_state.step:
                    st.markdown(f"✅ ~~{step}~~")
                # Étapes à venir
                else:
                    st.markdown(f"⏳ {step}")
                
                # Ajout d'un séparateur sauf pour le dernier élément
                if i < len(steps) - 1:
                    st.markdown("---")
        
        st.markdown("---")
        
        # Section d'aide et d'information
        with st.expander("ℹ️ Aide et informations"):
            st.markdown("""
            **Comment utiliser :**
            1. Définissez le contexte de votre analyse
            2. Chargez vos données
            3. Nettoyez si nécessaire
            4. Explorez avec les outils d'analyse
            5. Générez votre rapport
            """)
        
        # Boutons d'action
        if st.button("🔄 Recommencer l'analyse", 
                    use_container_width=True, 
                    help="Réinitialise complètement l'application"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
            
        # Pied de page
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; font-size: 0.8em; color: #666;">
            <p>Analyser IA v1.0.0</p>
            <p>© 2025 Tous droits réservés</p>
        </div>
        """, unsafe_allow_html=True)

def export_to_colab():
    """Exporte les données actuelles vers Google Colab."""
    if 'df' not in st.session_state or st.session_state.df is None:
        st.warning("Aucune donnée à exporter vers Colab.")
        return
    
    try:
        # Obtenir la date et l'heure actuelles pour le commentaire
        import datetime
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Créer la structure du notebook Colab
        notebook_content = {
            "cells": [
                {
                    "cell_type": "markdown",
                    "metadata": {"id": "imports"},
                    "source": [
                        "# Analyse avancée avec Google Colab\n",
                        "*Ce notebook a été généré automatiquement depuis Analyser IA*\n\n",
                        "## Configuration initiale"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {"id": "install-deps"},
                    "source": [
                        "# Installation des dépendances\n",
                        "!pip install pandas numpy matplotlib seaborn plotly"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {"id": "imports"},
                    "source": [
                        "import pandas as pd\n",
                        "import numpy as np\n",
                        "import matplotlib.pyplot as plt\n",
                        "import seaborn as sns\n",
                        "import plotly.express as px\n",
                        "from google.colab import files\n\n",
                        "# Configuration des styles\n",
                        "plt.style.use('seaborn')\n",
                        "sns.set_theme(style=\"whitegrid\")\n",
                        "%matplotlib inline"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {"id": "load-data"},
                    "source": [
                        "# Téléchargement des données\n",
                        f"# Données exportées depuis Analyser IA le {timestamp}\n\n",
                        "# Chargement des données\n",
                        "import io\n",
                        f"df = pd.DataFrame({st.session_state.df.to_dict('list')})\n\n",
                        "# Aperçu des données\n",
                        "print('Aperçu des données :')\n",
                        "display(df.head())\n\n",
                        "# Informations sur les données\n",
                        "print('\\nInformations sur les données :')\n",
                        "df.info()"
                    ]
                },
                {
                    "cell_type": "markdown",
                    "metadata": {"id": "analysis-section"},
                    "source": [
                        "## Analyse des données\n",
                        "Ajoutez vos cellules d'analyse ici"
                    ]
                }
            ],
            "metadata": {
                "colab": {
                    "provenance": [],
                    "toc_visible": True
                },
                "kernelspec": {
                    "name": "python3",
                    "display_name": "Python 3"
                },
                "language_info": {
                    "name": "python"
                }
            },
            "nbformat": 4,
            "nbformat_minor": 0
        }
        
        # Convertir en JSON
        import json
        notebook_json = json.dumps(notebook_content, indent=2, ensure_ascii=False)
        
        # Afficher les instructions
        st.markdown("### Exporter vers Google Colab")
        st.markdown("1. Téléchargez le notebook ci-dessous")
        st.markdown("2. Allez sur [Google Colab](https://colab.research.google.com/)")
        st.markdown("3. Faites Fichier > Importer un notebook > Choisissez le fichier téléchargé")
        
        # Bouton de téléchargement
        st.download_button(
            label="📥 Télécharger le notebook Colab",
            data=notebook_json,
            file_name="analyse_avancee.ipynb",
            mime="application/x-ipynb+json"
        )
        
        # Lien pour ouvrir directement dans Colab
        st.markdown("---")
        st.markdown("Ou ouvrez directement dans Colab (nécessite un compte Google) :")
        st.markdown(
            """
            <a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb" target="_blank">
                <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Ouvrir dans Colab">
            </a>
            """,
            unsafe_allow_html=True
        )
        
    except Exception as e:
        st.error(f"Une erreur est survenue lors de la préparation de l'export Colab : {str(e)}")
        st.exception(e)

def render_sidebar():
    """Affiche la barre latérale avec la navigation et les contrôles principaux."""
    with st.sidebar:
        # En-tête avec logo et titre
        col1, col2 = st.columns([1, 3])
        with col1:
            st.image("https://via.placeholder.com/60", width=60)  # Remplacer par votre logo
        with col2:
            st.markdown("# Analyser IA")
            st.caption("Analyse de données assistée par IA")
        
        st.markdown("---")
        
        # Menu de navigation
        with st.expander("🔍 Navigation", expanded=st.session_state.get('ui_state', {}).get('sidebar_expanded', True)):
            steps = ["1. Contexte", "2. Chargement", "3. Nettoyage", "4. Analyse", "5. Rapport"]
            for i, step in enumerate(steps):
                # Mise en forme de l'étape actuelle
                if i == st.session_state.get('step', 0):
                    st.markdown(f"**➡️ {step}**")
                # Étapes terminées
                elif i < st.session_state.get('step', 0):
                    st.markdown(f"✅ ~~{step}~~")
                # Étapes à venir
                else:
                    st.markdown(f"⏳ {step}")
                
                # Ajout d'un séparateur sauf pour le dernier élément
                if i < len(steps) - 1:
                    st.markdown("---")
        
        st.markdown("---")
        
        # Section d'aide et d'information
        with st.expander("ℹ️ Aide et informations"):
            st.markdown("""
            **Comment utiliser :**
            1. Définissez le contexte de votre analyse
            2. Chargez vos données
            3. Nettoyez si nécessaire
            4. Explorez avec les outils d'analyse
            5. Générez votre rapport
            """)
        
        # Boutons d'action
        if st.button("🔄 Recommencer l'analyse", 
                    use_container_width=True, 
                    help="Réinitialise complètement l'application"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
            
        # Export vers Colab
        if 'df' in st.session_state and st.session_state.df is not None:
            with st.expander("🚀 Exporter vers Colab", expanded=False):
                st.markdown("Exportez vos données vers Google Colab pour des analyses avancées avec GPU/TPU :")
                if st.button("📥 Préparer l'export Colab", use_container_width=True):
                    export_to_colab()
        
        # Pied de page
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; font-size: 0.8em; color: #666;">
            <p>Analyser IA v1.0.0</p>
            <p>Développé avec ❤️ par Sidoine YEBADOKPO</p>
            <p>© 2025 Tous droits réservés</p>
        </div>
        """, unsafe_allow_html=True)

# ============================================
# 4. Écrans de l'application
# ============================================

def render_context_step():
    with st.container():
        st.subheader("🎯 Contexte et Objectifs de l'Analyse")
        
        # Section pour les informations de base
        col1, col2 = st.columns(2)
        with col1:
            project_name = st.text_input("Nom du projet", 
                                      value=st.session_state.get('project_name', ''),
                                      help="Donnez un nom à votre projet d'analyse")
            
        with col2:
            industry = st.selectbox(
                "Secteur d'activité",
                options=["Sélectionner...", "Commerce de détail", "Santé", "Finance", "Éducation", 
                         "Technologie", "Manufacture", "Services", "Autre"],
                index=0 if not st.session_state.get('industry') else 
                     ["Sélectionner...", "Commerce de détail", "Santé", "Finance", "Éducation", 
                     "Technologie", "Manufacture", "Services", "Autre"].index(st.session_state.get('industry', 'Sélectionner...')),
                key="industry_select"
            )
        
        # Description détaillée du contexte et des objectifs
        context_objectif = st.text_area(
            "Décrivez en détail le contexte de votre analyse et vos objectifs :",
            placeholder="Ex: Analyse des ventes trimestrielles 2023. Objectifs: 1) Identifier les tendances mensuelles, 2) Comprendre les facteurs influençant les ventes, 3) Prédire les ventes pour le prochain trimestre.",
            height=200,
            value=st.session_state.get('context_objectif', '')
        )
        
        # Section pour les hypothèses et contraintes
        with st.expander("Hypothèses et contraintes (optionnel)"):
            hypotheses = st.text_area(
                "Hypothèses de travail :",
                placeholder="Ex: Les tendances passées sont représentatives des tendances futures. Les données sont complètes et exactes.",
                height=100,
                value=st.session_state.get('hypotheses', '')
            )
            
            constraints = st.text_area(
                "Contraintes connues :",
                placeholder="Ex: Données manquantes pour certains mois. Limitation des données à la région Europe.",
                height=100,
                value=st.session_state.get('constraints', '')
            )
        
        # Boutons de navigation
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("Valider et continuer", type="primary", use_container_width=True):
                if not context_objectif.strip():
                    st.warning("Veuillez fournir une description du contexte et des objectifs.")
                else:
                    # Sauvegarde des informations dans la session
                    st.session_state["project_name"] = project_name
                    st.session_state["industry"] = industry if industry != "Sélectionner..." else ""
                    st.session_state["context_objectif"] = context_objectif
                    st.session_state["hypotheses"] = hypotheses
                    st.session_state["constraints"] = constraints
                    
                    # Génération de suggestions d'analyse basées sur le contexte
                    with st.spinner("Préparation des suggestions d'analyse..."):
                        # Génération des suggestions avec l'IA
                        # Récupérer les noms de colonnes du DataFrame si disponible
                        df_columns = []
                        if 'df' in st.session_state and st.session_state.df is not None:
                            df_columns = list(st.session_state.df.columns)
                        
                        prompt = f"""
                        En tant qu'expert en analyse de données, génère 10 suggestions d'analyses pertinentes 
                        basées sur le contexte suivant :
                        
                        Projet: {project_name}
                        Secteur: {industry}
                        Objectifs: {context_objectif}
                        
                        Pour chaque suggestion, fournis :
                        1. Un titre court et descriptif
                        2. Les variables à utiliser (si des colonnes sont disponibles)
                        3. Le type d'analyse recommandé (statistique, visualisation, etc.)
                        4. La méthodologie à suivre
                        
                        Format de sortie attendu pour chaque suggestion :
                        - **Titre** : [Titre de l'analyse]
                          **Variables** : [liste des variables]
                          **Type** : [type d'analyse]
                          **Méthodologie** : [description détaillée de la méthode à suivre]
                        
                        Colonnes disponibles : {', '.join(df_columns) if df_columns else 'Aucune donnée chargée'}
                        """
                        
                        try:
                            response = call_gemini_api(prompt)
                            # Nettoyer et formater la réponse
                            if response:
                                # Traitement des suggestions avec le nouveau format
                                suggestions = []
                                current_suggestion = {}
                                
                                lines = [line.strip() for line in response.split('\n') if line.strip()]
                                
                                for line in lines:
                                    if line.startswith('- **Titre** :'):
                                        if current_suggestion:  # Sauvegarder la suggestion précédente
                                            suggestions.append(current_suggestion)
                                        current_suggestion = {'title': line.replace('- **Titre** :', '').strip()}
                                    elif line.startswith('**Variables** :') and current_suggestion:
                                        current_suggestion['variables'] = line.replace('**Variables** :', '').strip()
                                    elif line.startswith('**Type** :') and current_suggestion:
                                        current_suggestion['type'] = line.replace('**Type** :', '').strip()
                                    elif line.startswith('**Méthodologie** :') and current_suggestion:
                                        current_suggestion['methodology'] = line.replace('**Méthodologie** :', '').strip()
                                    elif current_suggestion and 'methodology' in current_suggestion:
                                        # Ajouter des lignes supplémentaires à la méthodologie
                                        current_suggestion['methodology'] += '\n' + line
                                
                                # Ajouter la dernière suggestion si elle existe
                                if current_suggestion:
                                    suggestions.append(current_suggestion)
                                
                                # Limiter à 10 suggestions et filtrer les entrées vides
                                st.session_state.analysis_suggestions = [s for s in suggestions[:10] if isinstance(s, dict) and s.get('title')]
                                
                                if st.session_state.analysis_suggestions:
                                    st.toast("Suggestions d'analyse générées avec succès !")
                                else:
                                    st.warning("Le format des suggestions n'est pas reconnu. Utilisation du format texte.")
                                    # Fallback: utiliser le texte brut si le format structuré échoue
                                    st.session_state.analysis_suggestions = [s.strip() for s in response.split('\n') 
                                                                           if s.strip() and len(s.strip()) > 10][:10]
                            else:
                                st.warning("Aucune suggestion n'a pu être générée.")
                                st.session_state.analysis_suggestions = []
                            
                        except Exception as e:
                            st.error(f"Erreur lors de la génération des suggestions : {str(e)}")
                            st.exception(e)  # Afficher plus de détails sur l'erreur
                            st.session_state.analysis_suggestions = []
                    
                        st.session_state["step"] = 1
                        st.rerun()
        
        with col2:
            if st.button("Passer cette étape", use_container_width=True):
                st.session_state["step"] = 1
                st.rerun()
                
        # Aperçu des informations saisies
        if project_name or context_objectif:
            with col3:
                with st.expander("Aperçu du contexte"):
                    st.caption("Voici comment ces informations seront utilisées :")
                    if project_name:
                        st.markdown(f"**Projet :** {project_name}")
                    if industry and industry != "Sélectionner...":
                        st.markdown(f"**Secteur :** {industry}")
                    if context_objectif:
                        st.markdown("**Objectifs :**")
                        st.caption(context_objectif[:200] + ("..." if len(context_objectif) > 200 else ""))

def render_join_interface():
    """Affiche l'interface de jointure de tables."""
    st.subheader("🔗 Jointure de tables")
    
    if st.session_state.df_clean is None:
        st.warning("Veuvez d'abord charger et nettoyer vos données principales.")
        return
        
    # Section pour charger une deuxième table
    st.markdown("### Charger une deuxième table")
    
    # Options de source pour la deuxième table (similaire à render_loading_step)
    source_choice = st.radio(
        "Source de la deuxième table",
        ["Fichier local", "URL (CSV/Excel)", "Exemple de jeu de données"],
        horizontal=True
    )
    
    uploaded = None
    data_url = None
    example_choice = None
    
    with st.form("load_secondary_data_form"):
        if source_choice == "Fichier local":
            uploaded = st.file_uploader(
                "📂 Charger un deuxième fichier",
                type=["csv", "xlsx", "xls", "json", "parquet"],
                key="secondary_uploader"
            )
        elif source_choice == "URL (CSV/Excel)":
            data_url = st.text_input("URL du deuxième fichier")
        else:  # Exemple de jeu de données
            example_datasets = {
                'Iris': 'iris',
                'Titanic': 'titanic',
                'Diamants': 'diamonds'
            }
            example_choice = st.selectbox(
                "Sélectionnez un exemple de jeu de données",
                options=list(example_datasets.keys())
            )
            
        if st.form_submit_button("Charger la deuxième table"):
            try:
                df_secondary = None
                
                if uploaded is not None:
                    # Chargement du fichier téléversé
                    if uploaded.name.endswith('.csv'):
                        df_secondary = pd.read_csv(uploaded)
                    elif uploaded.name.endswith(('.xlsx', '.xls')):
                        df_secondary = pd.read_excel(uploaded)
                    elif uploaded.name.endswith('.json'):
                        df_secondary = pd.read_json(uploaded, lines=True)
                    elif uploaded.name.endswith('.parquet'):
                        df_secondary = pd.read_parquet(uploaded, engine='pyarrow')
                        
                elif data_url:
                    # Chargement depuis URL
                    if data_url.endswith('.csv'):
                        df_secondary = pd.read_csv(data_url)
                    elif data_url.endswith(('.xlsx', '.xls')):
                        df_secondary = pd.read_excel(data_url)
                    elif data_url.endswith('.json'):
                        df_secondary = pd.read_json(data_url, lines=True)
                    else:
                        df_secondary = pd.read_csv(data_url)  # Essayer CSV par défaut
                        
                elif example_choice:
                    # Chargement d'un exemple
                    dataset_name = example_datasets[example_choice]
                    url = f"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/{dataset_name}.csv"
                    df_secondary = pd.read_csv(url)
                
                if df_secondary is not None:
                    st.session_state.df_secondary = df_secondary
                    st.success(f"Deuxième table chargée avec succès ! {df_secondary.shape[0]} lignes et {df_secondary.shape[1]} colonnes.")
                    
                    # Afficher un aperçu
                    st.dataframe(df_secondary.head())
                    
                    # Détection automatique des colonnes communes pour la jointure
                    common_columns = list(set(st.session_state.df_clean.columns) & set(df_secondary.columns))
                    if common_columns:
                        st.session_state.join_columns = common_columns
                        st.session_state.join_type = 'inner'
                        st.info(f"Colonnes communes détectées : {', '.join(common_columns)}")
                else:
                    st.warning("Aucune donnée n'a pu être chargée.")
                    
            except Exception as e:
                st.error(f"Erreur lors du chargement de la deuxième table : {str(e)}")
    
    # Section pour configurer la jointure
    if st.session_state.df_secondary is not None:
        st.markdown("### Configurer la jointure")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Sélection des colonnes de jointure
            all_columns = list(set(st.session_state.df_clean.columns) | set(st.session_state.df_secondary.columns))
            st.session_state.join_columns = st.multiselect(
                "Colonnes de jointure",
                options=all_columns,
                default=st.session_state.get('join_columns', []),
                help="Sélectionnez les colonnes communes pour la jointure"
            )
        
        with col2:
            # Type de jointure
            st.session_state.join_type = st.selectbox(
                "Type de jointure",
                ['inner', 'left', 'right', 'outer'],
                index=['inner', 'left', 'right', 'outer'].index(st.session_state.get('join_type', 'inner')),
                help="Type de jointure à effectuer"
            )
        
        # Bouton pour effectuer la jointure
        if st.button("🔗 Effectuer la jointure", type="primary"):
            if not st.session_state.join_columns:
                st.error("Veuvez sélectionner au moins une colonne de jointure.")
            else:
                with st.spinner("Jointure des tables en cours..."):
                    joined_df = join_dataframes(
                        st.session_state.df_clean,
                        st.session_state.df_secondary,
                        st.session_state.join_columns,
                        st.session_state.join_type
                    )
                    
                    if joined_df is not None:
                        st.session_state.df_joined = joined_df
                        st.session_state.df_clean = joined_df  # Remplacer les données principales par le résultat de la jointure
                        st.success(f"Jointure réussie ! {joined_df.shape[0]} lignes et {joined_df.shape[1]} colonnes.")
                        
                        # Afficher un aperçu du résultat
                        st.dataframe(joined_df.head())
                        
                        # Mettre à jour l'état
                        st.session_state.data_loaded = True
                        st.session_state.data_cleaned = True
                        st.rerun()

def render_loading_step():
    """Affiche l'interface de chargement des données (étape 1)."""
    st.header("1️⃣ Chargement des données")
    
    # Afficher le contexte et les objectifs
    with st.expander("📋 Voir le contexte et les objectifs"):
        st.markdown(f"**Contexte et Objectifs :** {st.session_state.get('context_objectif', 'Non défini')}")

    # Sélection de la source
    source_choice = st.radio(
        "Source des données",
        ["Fichier local", "URL (CSV/Excel)", "Google Sheets", "Base de données", "Exemple de jeu de données"],
        horizontal=True
    )

    uploaded = None
    data_url = None
    gs_url = None
    sheet_name_input = None
    db_connection_string = None
    example_choice = None
    
    # Définir les exemples de jeux de données
    example_datasets = {
        'Iris': 'iris',
        'Titanic': 'titanic',
        'Diamants': 'diamonds',
        'Tips': 'tips',
        'MPG': 'mpg'
    }

    with st.form("load_data_form"):
        if source_choice == "Fichier local":
            uploaded = st.file_uploader(
                "📂 Charger un fichier (CSV / Excel / JSON / Parquet)",
                type=["csv", "xlsx", "xls", "json", "parquet"],
                help="Taille maximale : 200 Mo"
            )
        elif source_choice == "URL (CSV/Excel)":
            data_url = st.text_input("Insérez l'URL du fichier CSV / Excel / JSON")
        elif source_choice == "Google Sheets":
            gs_url = st.text_input("Lien ou ID Google Sheets")
            sheet_name_input = st.text_input("Nom de l'onglet (optionnel)") or 0
        elif source_choice == "Base de données":
            db_connection_string = st.text_input("Chaîne de connexion à la base de données", type="password")
            query = st.text_area("Requête SQL pour extraire les données")
        elif source_choice == "Exemple de jeu de données":
            example_choice = st.selectbox(
                "Sélectionnez un exemple de jeu de données",
                options=list(example_datasets.keys())
            )

        submit_col1, submit_col2 = st.columns([1, 1])
        with submit_col1:
            submit_button = st.form_submit_button("Charger les données")
        
        if submit_button:
            try:
                if uploaded is not None:
                    # Chargement du fichier téléversé
                    try:
                        # Réinitialiser la position du fichier
                        uploaded.seek(0)
                        
                        # Chargement selon le type de fichier
                        if uploaded.name.endswith('.csv'):
                            df = pd.read_csv(uploaded)
                        elif uploaded.name.endswith(('.xlsx', '.xls')):
                            df = pd.read_excel(uploaded)
                        elif uploaded.name.endswith('.json'):
                            df = pd.read_json(uploaded, lines=True)
                        elif uploaded.name.endswith('.parquet'):
                            df = pd.read_parquet(uploaded, engine='pyarrow')
                        
                        st.session_state.df_raw = df
                        st.session_state.df_clean = df.copy()
                        st.session_state.data_loaded = True
                        st.success(f"Données chargées avec succès ! {df.shape[0]} lignes et {df.shape[1]} colonnes.")
                        
                        # Afficher un aperçu des données
                        st.dataframe(df.head())
                        
                        # Passer à l'étape de nettoyage
                        st.session_state.step = 2
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors du chargement du fichier : {str(e)}")
                        st.error("Détails techniques : " + traceback.format_exc())
                
                elif data_url and source_choice == "URL (CSV/Excel)":
                    # Chargement depuis une URL
                    try:
                        if data_url.endswith('.csv'):
                            df = pd.read_csv(data_url)
                        elif data_url.endswith(('.xlsx', '.xls')):
                            df = pd.read_excel(data_url)
                        elif data_url.endswith('.json'):
                            df = pd.read_json(data_url, lines=True)
                        else:
                            # Essayer de charger en tant que CSV par défaut
                            df = pd.read_csv(data_url)
                            
                        st.session_state.df_raw = df
                        st.session_state.df_clean = df.copy()
                        st.session_state.data_loaded = True
                        st.success(f"Données chargées depuis l'URL avec succès ! {df.shape[0]} lignes et {df.shape[1]} colonnes.")
                        
                        # Afficher un aperçu des données
                        st.dataframe(df.head())
                        
                        # Passer à l'étape de nettoyage
                        st.session_state.step = 2
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors du chargement depuis l'URL : {str(e)}")
                        st.error("Détails techniques : " + traceback.format_exc())
                        
                elif example_choice and source_choice == "Exemple de jeu de données":
                    # Chargement d'un exemple de jeu de données
                    try:
                        dataset_name = example_datasets[example_choice]
                        if 'example_datasets' in assets and dataset_name in assets['example_datasets']:
                            df = assets['example_datasets'][dataset_name].copy()
                        else:
                            # Téléchargement depuis une URL si pas dans le cache
                            url = f"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/{dataset_name}.csv"
                            df = pd.read_csv(url)
                        
                        st.session_state.df_raw = df
                        st.session_state.df_clean = df.copy()
                        st.session_state.data_loaded = True
                        st.success(f"Jeu de données '{example_choice}' chargé avec succès ! {df.shape[0]} lignes et {df.shape[1]} colonnes.")
                        
                        # Afficher un aperçu des données
                        st.dataframe(df.head())
                        
                        # Passer à l'étape de nettoyage
                        st.session_state.step = 2
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors du chargement de l'exemple : {str(e)}")
                        st.error("Détails techniques : " + traceback.format_exc())
                else:
                    st.warning("Veuillez sélectionner un fichier, une URL ou un exemple de jeu de données.")
                    
            except Exception as e:
                st.error("Une erreur inattendue est survenue : " + str(e))
                st.error("Détails techniques : " + traceback.format_exc())

    # Aperçu rapide si des données sont chargées
    if st.session_state.df_raw is not None:
        tab1, tab2, tab3 = st.tabs(["Données brutes", "Résumé des variables", "Jointure de tables"])
        
        with tab1:
            st.subheader("Aperçu des données brutes")
            st.dataframe(st.session_state.df_raw.head())
        
        with tab2:
            st.subheader("Résumé des variables")
            st.dataframe(pd.DataFrame({
                'Variable': st.session_state.df_raw.columns,
                'Type': st.session_state.df_raw.dtypes.astype(str).values,
                'Valeurs manquantes': st.session_state.df_raw.isna().sum().values,
                'Valeurs uniques': st.session_state.df_raw.nunique().values,
                'Exemple': st.session_state.df_raw.iloc[0].values if len(st.session_state.df_raw) > 0 else [None] * len(st.session_state.df_raw.columns)
            }), use_container_width=True)
            
            # Visualisation rapide
            st.subheader("Visualisation rapide")
            numeric_cols = st.session_state.df_raw.select_dtypes(include=['number']).columns.tolist()
            if numeric_cols:
                selected_col = st.selectbox("Sélectionnez une colonne numérique", numeric_cols)
        
        with tab3:
            render_join_interface()
            st.plotly_chart(histogram(st.session_state.df_raw, selected_col), use_container_width=True)

def render_cleaning_step():
    st.title("🔧 Nettoyage des données")
    
    if 'df_clean' not in st.session_state or st.session_state.df_clean is None:
        st.warning("Veuillez d'abord charger des données dans l'étape précédente.")
        return
    
    st.markdown("""
    ## Nettoyage des données
    
    Dans cette section, vous pouvez nettoyer vos données en appliquant différentes transformations.
    """)
    
    # Section de sélection des colonnes à conserver
    st.markdown("### Sélection des colonnes à conserver")
    
    # Vérifier si des données sont disponibles
    if st.session_state.df_clean is not None and not st.session_state.df_clean.empty:
        # Calculer le pourcentage de valeurs manquantes par colonne
        missing_percent = (st.session_state.df_clean.isnull().sum() / len(st.session_state.df_clean)) * 100
        
        # Créer un DataFrame pour l'affichage
        columns_info = []
        for col in st.session_state.df_clean.columns:
            col_info = {
                'Colonne': col,
                'Type': str(st.session_state.df_clean[col].dtype),
                'Valeurs uniques': st.session_state.df_clean[col].nunique(),
                '% Valeurs manquantes': round(missing_percent[col], 2)
            }
            columns_info.append(col_info)
        
        # Afficher le tableau des colonnes avec des cases à cocher
        df_columns_info = pd.DataFrame(columns_info)
        
        # Ajouter une colonne de sélection
        df_columns_info['Conserver'] = True  # Par défaut, toutes les colonnes sont sélectionnées
        
        # Afficher le tableau avec des cases à cocher
        edited_df = st.data_editor(
            df_columns_info,
            column_config={
                "Conserver": st.column_config.CheckboxColumn(
                    "Conserver",
                    help="Décochez pour exclure cette colonne de l'analyse",
                    default=True,
                )
            },
            hide_index=True,
            use_container_width=True,
            key="columns_selector"
        )
        
        # Appliquer les modifications
        if st.button("Appliquer la sélection des colonnes", type="primary"):
            try:
                # Récupérer les colonnes sélectionnées
                selected_columns = edited_df[edited_df['Conserver']]['Colonne'].tolist()
                
                # Si aucune colonne n'est sélectionnée, garder toutes les colonnes
                if not selected_columns:
                    selected_columns = st.session_state.df_clean.columns.tolist()
                
                # Filtrer le DataFrame pour ne garder que les colonnes sélectionnées
                st.session_state.df_clean = st.session_state.df_clean[selected_columns]
                
                # Supprimer les colonnes avec 100% de valeurs manquantes
                cols_to_drop = st.session_state.df_clean.columns[st.session_state.df_clean.isnull().all()].tolist()
                if cols_to_drop:
                    st.session_state.df_clean = st.session_state.df_clean.drop(columns=cols_to_drop)
                    st.warning(f"Les colonnes suivantes ont été supprimées car elles étaient vides: {', '.join(cols_to_drop)}")
                
                st.success(f"{len(selected_columns)} colonnes ont été conservées pour l'analyse.")
                
                # Afficher un aperçu des données
                st.subheader("Aperçu des données après sélection")
                st.dataframe(st.session_state.df_clean.head(), use_container_width=True)
                
            except Exception as e:
                st.error(f"Une erreur s'est produite lors de l'application des modifications: {e}")
                st.exception(e)
    
    st.markdown("---")  # Ligne de séparation
    st.markdown("### Autres options de nettoyage")

    # Configuration avancée
    with st.expander("⚙️ Configuration avancée", expanded=False):
        st.markdown("### Paramètres de nettoyage")

        # Options de gestion des valeurs manquantes
        st.markdown("#### Valeurs manquantes")
        missing_threshold = st.slider(
            "Seuil de suppression des colonnes avec trop de valeurs manquantes (%)",
            min_value=0,
            max_value=100,
            value=30,
            help="Supprime les colonnes avec plus de X% de valeurs manquantes"
        )

        # Options de conversion de type
        st.markdown("#### Conversion de type")
        st.checkbox(
            "Convertir automatiquement les colonnes numériques stockées comme texte",
            value=True,
            key="auto_convert_numeric"
        )

        # Options de normalisation
        st.markdown("#### Normalisation")
        st.checkbox(
            "Normaliser les colonnes catégorielles (trim, lowercase)",
            value=True,
            key="normalize_categorical"
        )

    # Aperçu avant/après
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Données brutes")
        st.dataframe(st.session_state.df_raw.head())

    with col2:
        st.subheader("Données nettoyées")
        st.dataframe(st.session_state.df_clean.head())

    # Détection automatique des problèmes
    st.subheader("🔍 Problèmes détectés")
    
    # 1. Valeurs manquantes
    missing_cols = st.session_state.df_clean.columns[st.session_state.df_clean.isna().any()].tolist()
    if missing_cols:
        with st.expander("🔍 Valeurs manquantes détectées", expanded=True):
            st.write(f"Colonnes avec valeurs manquantes: {', '.join(missing_cols)}")

            for col in missing_cols:
                missing_pct = st.session_state.df_clean[col].isna().mean() * 100
                st.write(f"- **{col}**: {missing_pct:.1f}% de valeurs manquantes")

                # Suggestions de nettoyage
                col1, col2 = st.columns([3, 1])
                with col1:
                    action = st.selectbox(
                        f"Action pour '{col}':",
                        ["Ne rien faire", "Supprimer les lignes", "Remplacer par la moyenne/médiane",
                         "Remplir avec une valeur", "Remplir avec la valeur précédente/suivante"],
                        key=f"missing_{col}"
                    )
                with col2:
                    if action == "Remplir avec une valeur":
                        fill_value = st.text_input("Valeur", key=f"fill_{col}")
                    elif action == "Remplacer par la moyenne/médiane":
                        method = st.radio("Méthode", ["Moyenne", "Médiane"], key=f"method_{col}", horizontal=True)

    # 2. Colonnes dupliquées
    duplicated_cols = st.session_state.df_clean.T.duplicated().sum()
    if duplicated_cols > 0:
        with st.expander(f"⚠️ {duplicated_cols} colonnes dupliquées détectées"):
            st.warning("Des colonnes dupliquées ont été détectées. Vous devriez les supprimer.")
            if st.button("Supprimer les colonnes dupliquées"):
                st.session_state.df_clean = st.session_state.df_clean.T.drop_duplicates().T
                st.rerun()

    # 3. Valeurs aberrantes
    with st.expander("📊 Détection des valeurs aberrantes", expanded=False):
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
        if numeric_cols:
            selected_col = st.selectbox("Sélectionnez une colonne numérique", numeric_cols)
            st.plotly_chart(boxplot(st.session_state.df_clean, selected_col), use_container_width=True)

            # Options de traitement des valeurs aberrantes
            col1, col2 = st.columns(2)
            with col1:
                outlier_method = st.selectbox(
                    "Méthode de traitement",
                    ["Ne rien faire", "Supprimer les valeurs aberrantes", "Remplacer par la médiane",
                     "Winsorization (écrêtage)"],
                    key=f"outlier_{selected_col}"
                )
            with col2:
                if outlier_method == "Winsorization (écrêtage)":
                    quantile = st.slider("Quantile pour l'écrêtage", 0.01, 0.1, 0.05, key=f"quantile_{selected_col}")

    # 4. Incohérences de format
    with st.expander("🔤 Incohérences de format", expanded=False):
        date_cols = st.session_state.df_clean.select_dtypes(include=['datetime64']).columns.tolist()
        if date_cols:
            st.write("Colonnes de date détectées:", ", ".join(date_cols))
        else:
            st.warning("Aucune colonne de date détectée automatiquement.")

        # Détection des colonnes qui pourraient être des dates (version plus robuste)
        potential_date_cols = []
        for col in st.session_state.df_clean.select_dtypes(include=['object']).columns:
            try:
                # Vérifier si la colonne contient des dates dans un format commun
                sample = st.session_state.df_clean[col].dropna().astype(str).sample(min(10, len(st.session_state.df_clean)))
                date_matches = sample.str.contains(
                    r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}|\d{4}[-/]\d{1,2}[-/]\d{1,2}'
                )
                if date_matches.any():
                    potential_date_cols.append(col)
            except Exception as e:
                st.warning(f"Impossible de vérifier la colonne {col} pour des dates: {str(e)}")

        if potential_date_cols:
            st.write("Colonnes qui pourraient être des dates:", ", ".join(potential_date_cols))
            for col in potential_date_cols:
                col1, col2 = st.columns([2, 1])
                with col1:
                    date_format = st.text_input(
                        f"Format de date pour '{col}' (ex: %d/%m/%Y, %Y-%m-%d, %m/%d/%Y, etc.)",
                        value="%d/%m/%Y"
                    )
                with col2:
                    st.write("<div style='margin-top: 1.5rem;'></div>", unsafe_allow_html=True)
                    if st.button(f"Convertir '{col}' en date"):
                        try:
                            # Essayer de convertir avec le format spécifié
                            st.session_state.df_clean[col] = pd.to_datetime(
                                st.session_state.df_clean[col], 
                                format=date_format,
                                errors='coerce'  # Convertit les erreurs en NaT au lieu de lever une exception
                            )
                            
                            # Vérifier si la conversion a réussi pour au moins certaines valeurs
                            if st.session_state.df_clean[col].notna().any():
                                st.success(f"Colonne '{col}' convertie en date avec succès!")
                                st.rerun()
                            else:
                                st.error("Aucune date valide trouvée avec ce format. Essayez un format différent.")
                        except Exception as e:
                            st.error(f"Erreur lors de la conversion: {str(e)}")
                            st.warning("Essayez un format différent ou vérifiez les données.")

    # Boutons de navigation
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        if st.button("← Retour au chargement", use_container_width=True):
            st.session_state.step = 1
            st.rerun()
    with col2:
        if st.button("Réinitialiser le nettoyage", use_container_width=True):
            st.session_state.df_clean = st.session_state.df_raw.copy()
            st.rerun()
    with col3:
        if st.button("Valider le nettoyage →", type="primary", use_container_width=True):
            # Appliquer les étapes de nettoyage sélectionnées
            st.session_state.step = 3  # Passe à l'étape d'analyse
            st.rerun()

def render_analysis_step():
    """Affiche l'interface d'analyse des données (étape 3)."""
    st.header("3️⃣ Analyse des données")

    if st.session_state.df_clean is None:
        st.warning("Aucune donnée nettoyée disponible. Revenez à l'étape 2.")
        if st.button("← Retour au nettoyage"):
            st.session_state.step = 2
            st.rerun()
    else:
        # Bouton de téléchargement Excel
        from analyser_ia.app.utils.helpers import get_excel_download_link
        
        # Générer un nom de fichier avec horodatage
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"donnees_analyse_{timestamp}.xlsx"
        
        # Afficher le bouton de téléchargement
        st.markdown("### Téléchargement des données")
        st.markdown("Téléchargez les données nettoyées au format Excel :")
        st.markdown(
            get_excel_download_link(
                st.session_state.df_clean,
                filename=filename,
                button_text="📊 Télécharger les données Excel"
            ),
            unsafe_allow_html=True
        )
        st.markdown("---")  # Séparateur visuel
        # Panneau de configuration
        with st.expander("⚙️ Configuration de l'analyse", expanded=False):
            st.markdown("### Paramètres d'analyse")

            # Configuration des analyses
            st.markdown("#### Types d'analyses à effectuer")
            analysis_types = st.multiselect(
                "Sélectionnez les types d'analyses à effectuer",
                ["Statistiques descriptives", "Corrélations", "Clustering", "Analyse temporelle",
                 "Analyse de tendances", "Modélisation prédictive"],
                default=["Statistiques descriptives", "Corrélations"],
                key="selected_analysis_types"
            )

            # Paramètres de l'IA
            st.markdown("#### Paramètres IA")
            col1, col2 = st.columns(2)

            with col1:
                st.selectbox(
                    "Modèle d'IA",
                    ["GPT-4", "GPT-3.5", "Claude", "Gemini"],
                    index=0,
                    key="ai_model"
                )

            with col2:
                st.slider(
                    "Niveau de détail",
                    min_value=1,
                    max_value=5,
                    value=3,
                    help="Niveau de détail des analyses générées",
                    key="detail_level"
                )

            # Paramètres d'export
            st.markdown("#### Options d'export")
            export_col1, export_col2 = st.columns(2)

            with export_col1:
                st.checkbox(
                    "Inclure les données brutes",
                    value=True,
                    key="include_raw_data_export"
                )

                st.checkbox(
                    "Générer un sommaire",
                    value=True,
                    key="generate_summary"
                )

            with export_col2:
                st.checkbox(
                    "Inclure les graphiques",
                    value=True,
                    key="include_charts"
                )

                st.checkbox(
                    "Inclure le code source",
                    value=False,
                    key="include_source_code"
                )

            # Paramètres de sécurité
            st.markdown("#### Paramètres de sécurité")
            security_col1, security_col2 = st.columns(2)

            with security_col1:
                st.checkbox(
                    "Validation manuelle requise",
                    value=True,
                    help="Nécessite une validation manuelle avant l'exécution des requêtes",
                    key="require_manual_approval"
                )

            with security_col2:
                st.checkbox(
                    "Limiter les résultats",
                    value=True,
                    help="Limite le nombre de lignes retournées par les requêtes",
                    key="limit_query_results"
                )

            # Bouton de sauvegarde de la configuration
            if st.button("💾 Enregistrer la configuration", key="save_config_btn"):
                st.session_state.config_saved = True
                st.success("Configuration enregistrée avec succès !")

        # Section pour les requêtes en langage naturel
        with st.expander("💬 Requête en langage naturel", expanded=True):
            st.markdown("""
            <style>
            .stTextArea [data-baseweb="textarea"] {
                min-height: 100px;
            }
            </style>
            """, unsafe_allow_html=True)

            # Zone de texte pour la description
            user_query = st.text_area(
                "Décrivez votre requête ou analyse souhaitée :",
                placeholder="Exemple : 'Trouve les 10 produits les plus vendus'",
                key="user_query_input"
            )

            # Définir le type de requête par défaut
            query_type = "Python"
            
            # Boutons d'action
            col1, col2 = st.columns([1, 2])
            with col1:
                generate_btn = st.button(
                    "🔄 Générer le code",
                    key="generate_code_btn_natural",
                    help="Génère le code Python à partir de votre description"
                )
                
            with col2:
                execute_btn = st.button(
                    "▶️ Exécuter",
                    key="execute_code_btn_natural",
                    disabled=not st.session_state.get('generated_code', False),
                    help="Exécute le code généré"
                )

            # Génération du code
            if generate_btn and user_query.strip():
                with st.spinner("Génération du code en cours..."):
                    try:
                        # Récupérer les colonnes du DataFrame
                        df_columns = st.session_state.df_clean.columns.tolist()

                        # Générer le code
                        generated_code = generate_code_from_natural_language(
                            user_query,
                            query_type.lower(),
                            df_columns
                        )

                        if generated_code:
                            st.session_state.generated_code = generated_code
                            st.session_state.show_generated_code = True
                            st.success("Code généré avec succès !")
                        else:
                            st.warning("Impossible de générer le code. Veuillez reformuler votre demande.")

                    except Exception as e:
                        st.error(f"Erreur lors de la génération du code : {str(e)}")
                        st.exception(e)

            # Affichage du code généré
            if st.session_state.get('show_generated_code', False) and 'generated_code' in st.session_state:
                st.markdown("### Code généré")
                st.code(st.session_state.generated_code, language=query_type.lower())

                # Bouton pour copier le code
                st.download_button(
                    label="📋 Copier le code",
                    data=st.session_state.generated_code,
                    file_name=f"generated_code.{query_type.lower()}",
                    mime="text/plain"
                )

            # Exécution du code
            if execute_btn and st.session_state.get('generated_code'):
                with st.spinner("Exécution en cours..."):
                    try:
                        if query_type == "SQL":
                            # Exécuter la requête SQL
                            result = sqldf(st.session_state.generated_code, {'df': st.session_state.df_clean})
                        else:
                            # Exécuter le code Python
                            local_vars = {'df': st.session_state.df_clean}
                            exec(st.session_state.generated_code, globals(), local_vars)
                            result = local_vars.get('result', local_vars.get('df', None))

                        if result is not None:
                            st.session_state.last_query_result = result
                            st.success("Exécution réussie !")
                            
                            # Ajouter un séparateur visuel
                            st.markdown("---")
                            
                            # Afficher les résultats selon leur type
                            if hasattr(result, 'head') and hasattr(result, 'to_csv'):
                                # Si c'est un DataFrame ou similaire
                                st.markdown("### 📊 Résultats de l'analyse")
                                
                                # Afficher un aperçu des données
                                st.dataframe(result.head(100))  # Limiter à 100 lignes
                                
                            elif isinstance(result, (dict, list, tuple, set)):
                                # Pour les types de collection standards
                                st.markdown("### 📋 Résultat de l'exécution")
                                st.json(result)  # Affiche le résultat brut de manière formatée
                                
                            else:
                                # Pour tous les autres types (nombres, chaînes, objets personnalisés, etc.)
                                st.markdown("### 📋 Résultat de l'exécution")
                                st.write("Type de résultat :", type(result).__name__)
                                st.write(result)
                            
                            # Section d'interprétation automatique
                            try:
                                st.markdown("---")
                                st.markdown("### 📝 Interprétation des résultats")
                                
                                # Convertir le résultat en DataFrame pour l'analyse si nécessaire
                                if hasattr(result, 'head') and hasattr(result, 'to_csv'):
                                    df_to_analyze = result
                                elif isinstance(result, dict):
                                    # Essayer de convertir le dict en DataFrame
                                    try:
                                        df_to_analyze = pd.DataFrame([result] if result else {})
                                    except:
                                        df_to_analyze = pd.DataFrame({'Valeur': [str(result)]})
                                elif isinstance(result, (list, tuple, set)) and result:
                                    # Essayer de convertir la liste en DataFrame
                                    try:
                                        df_to_analyze = pd.DataFrame(result)
                                    except:
                                        df_to_analyze = pd.DataFrame({'Valeurs': [str(x) for x in result]})
                                else:
                                    # Pour les types simples ou inconnus
                                    df_to_analyze = pd.DataFrame({'Résultat': [str(result)]})
                                
                                # Générer et afficher l'interprétation
                                interpretation = generate_interpretation(df_to_analyze)
                                st.markdown(interpretation)
                                
                            except Exception as e:
                                st.warning("Impossible de générer une interprétation automatique des résultats.")
                                st.error(f"Erreur: {str(e)}")
                            
                            # Section d'exportation
                            st.markdown("---")
                            st.markdown("### 💾 Exporter les résultats")
                            
                            # Créer des colonnes pour les boutons d'exportation
                            col1, col2, col3 = st.columns(3)
                            
                            # Fonction pour convertir n'importe quel résultat en DataFrame
                            def convert_to_exportable(data):
                                try:
                                    if hasattr(data, 'to_frame'):
                                        return data.to_frame()
                                    elif isinstance(data, pd.DataFrame):
                                        return data
                                    elif isinstance(data, (dict, list, tuple, set)):
                                        return pd.DataFrame(data) if data else pd.DataFrame()
                                    else:
                                        # Pour les types simples (nombres, chaînes, etc.)
                                        return pd.DataFrame({'Résultat': [data]})
                                except Exception as e:
                                    st.error(f"Erreur de conversion des données: {str(e)}")
                                    return None
                            
                            # Convertir le résultat en DataFrame pour l'export
                            export_df = convert_to_exportable(result)
                            
                            # Colonne CSV
                            with col1:
                                try:
                                    if export_df is not None and not export_df.empty:
                                        csv = export_df.to_csv(index=False, encoding='utf-8-sig')
                                        st.download_button(
                                            label="💾 CSV",
                                            data=csv,
                                            file_name="resultats_analyse.csv",
                                            mime="text/csv",
                                            help="Télécharger au format CSV (UTF-8 avec BOM)"
                                        )
                                    else:
                                        st.info("CSV: Aucune donnée à exporter")
                                except Exception as e:
                                    st.warning("Export CSV indisponible")
                                    st.error(f"Erreur: {str(e)}")
                            
                            # Colonne Excel
                            with col2:
                                try:
                                    if export_df is not None and not export_df.empty:
                                        excel_buffer = io.BytesIO()
                                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                            export_df.to_excel(writer, index=False, sheet_name='Résultats')
                                        
                                        st.download_button(
                                            label="📊 Excel",
                                            data=excel_buffer.getvalue(),
                                            file_name="resultats_analyse.xlsx",
                                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                            help="Télécharger au format Excel"
                                        )
                                    else:
                                        st.info("Excel: Aucune donnée à exporter")
                                except Exception as e:
                                    st.warning("Export Excel indisponible")
                                    st.error(f"Erreur: {str(e)}")
                            
                            # Colonne JSON
                            with col3:
                                try:
                                    if export_df is not None and not export_df.empty:
                                        # Essayer d'abord avec to_json si disponible
                                        if hasattr(export_df, 'to_json'):
                                            json_data = export_df.to_json(orient='records', force_ascii=False, indent=2)
                                        else:
                                            # Sinon convertir en dict puis en JSON
                                            json_data = json.dumps(export_df.to_dict(orient='records') 
                                                                if hasattr(export_df, 'to_dict') 
                                                                else export_df, 
                                                              indent=2, 
                                                              ensure_ascii=False,
                                                              default=str)
                                        
                                        st.download_button(
                                            label="🔤 JSON",
                                            data=json_data,
                                            file_name="resultats_analyse.json",
                                            mime="application/json",
                                            help="Télécharger au format JSON"
                                        )
                                    else:
                                        # Pour les petits objets non-DataFrame
                                        try:
                                            json_data = json.dumps(result, indent=2, ensure_ascii=False, default=str)
                                            st.download_button(
                                                label="🔤 JSON",
                                                data=json_data,
                                                file_name="resultat_export.json",
                                                mime="application/json"
                                            )
                                        except:
                                            st.info("JSON: Aucune donnée à exporter")
                                except Exception as e:
                                    st.warning("Export JSON indisponible")
                                    st.error(f"Erreur: {str(e)}")

                            # Vérifier et initialiser custom_queries si nécessaire
                            if 'custom_queries' not in st.session_state:
                                st.session_state.custom_queries = []
                                
                            # Vérifier que custom_queries est bien une liste
                            if not isinstance(st.session_state.custom_queries, list):
                                st.warning("Réinitialisation de la liste des requêtes personnalisées")
                                st.session_state.custom_queries = []
                            
                            # Ajouter aux requêtes personnalisées
                            try:
                                st.session_state.custom_queries.append({
                                    'type': query_type,
                                    'description': user_query if 'user_query' in locals() else 'Sans description',
                                    'code': st.session_state.get('generated_code', ''),
                                    'result': result.to_dict('records') if hasattr(result, 'to_dict') else str(result),
                                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                })
                            except Exception as e:
                                st.error(f"Erreur lors de l'enregistrement de la requête : {str(e)}")
                                st.exception(e)

                    except Exception as e:
                        st.error(f"Erreur lors de l'exécution du code : {str(e)}")
                        st.exception(e)

        # Section pour les analyses statistiques
        st.markdown("## 📊 Analyse descriptive des données")
        
        # Sélection des colonnes
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()

        # Onglets pour les différents types de variables
        tab1, tab2, tab3 = st.tabs([
            "Variables numériques", 
            "Variables catégorielles",
            "Analyses avancées"
        ])

        with tab1:
            if numeric_cols:
                selected_num_cols = st.multiselect(
                    "Sélectionnez les variables numériques",
                    numeric_cols,
                    default=numeric_cols[:3]
                )

                if selected_num_cols:
                    st.markdown("### Statistiques descriptives")
                    
                    # Afficher le tableau des statistiques
                    stats_df = st.session_state.df_clean[selected_num_cols].describe().T
                    st.dataframe(stats_df)
                    
                    # Pour chaque variable sélectionnée
                    for col in selected_num_cols:
                        # Créer un conteneur pour chaque variable
                        var_container = st.container()
                        with var_container:
                            # Calculer les statistiques détaillées
                            desc = st.session_state.df_clean[col].describe()
                            skewness = st.session_state.df_clean[col].skew()
                            
                            # Calculer les valeurs aberrantes
                            q1 = desc['25%']
                            q3 = desc['75%']
                            iqr = q3 - q1
                            lower_bound = q1 - 1.5 * iqr
                            upper_bound = q3 + 1.5 * iqr
                            outliers = st.session_state.df_clean[
                                (st.session_state.df_clean[col] < lower_bound) | 
                                (st.session_state.df_clean[col] > upper_bound)
                            ]
                            
                            # Afficher les métriques clés
                            st.markdown("#### Métriques clés")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Moyenne", f"{desc['mean']:.2f}")
                                st.metric("Médiane", f"{desc['50%']:.2f}")
                            with col2:
                                st.metric("Écart-type", f"{desc['std']:.2f}")
                                st.metric("Min / Max", f"{desc['min']:.2f} / {desc['max']:.2f}")
                            with col3:
                                st.metric("Asymétrie", f"{skewness:.2f}")
                                st.metric("Valeurs aberrantes", f"{len(outliers)}")
                            
                            # Interprétation automatique
                            st.markdown("#### Interprétation")
                            
                            # Décrire la distribution
                            if abs(skewness) > 1:
                                skew_text = "fortement asymétrique"
                            elif abs(skewness) > 0.5:
                                skew_text = "modérément asymétrique"
                            else:
                                skew_text = "approximativement symétrique"
                            
                            skew_direction = "vers la droite" if skewness > 0 else "vers la gauche" if skewness < 0 else ""
                            
                            # Afficher l'interprétation de base
                            st.markdown(f"- La distribution est **{skew_text}** {skew_direction}.")
                            st.markdown(f"- L'écart entre la moyenne ({desc['mean']:.2f}) et la médiane ({desc['50%']:.2f}) suggère une distribution {'' if abs(desc['mean'] - desc['50%']) < 0.1 * desc['std'] else 'non '}symétrique.")
                            
                            if len(outliers) > 0:
                                st.warning(f"- **Attention** : {len(outliers)} valeurs aberrantes détectées en dehors de l'intervalle [{lower_bound:.2f}, {upper_bound:.2f}].")
                            
                            # Bouton pour une analyse plus détaillée avec l'IA
                            if st.button(f"Analyse détaillée pour {col}"):
                                with st.spinner("Génération de l'analyse..."):
                                    context = f"Analyse statistique détaillée de la variable {col}"
                                    data_desc = (
                                        f"- Type: Numérique\n"
                                        f"- Nombre d'observations: {int(desc['count'])}\n"
                                        f"- Moyenne: {desc['mean']:.2f}\n"
                                        f"- Écart-type: {desc['std']:.2f}\n"
                                        f"- Minimum: {desc['min']:.2f}\n"
                                        f"- 25e percentile: {desc['25%']:.2f}\n"
                                        f"- Médiane: {desc['50%']:.2f}\n"
                                        f"- 75e percentile: {desc['75%']:.2f}\n"
                                        f"- Maximum: {desc['max']:.2f}\n"
                                        f"- Coefficient d'asymétrie: {skewness:.2f}\n"
                                        f"- Valeurs aberrantes: {len(outliers)} (en dehors de [{lower_bound:.2f}, {upper_bound:.2f}])"
                                    )
                                    
                                    interpretation = generate_ai_interpretation(
                                        context=context,
                                        data_description=data_desc,
                                        chart_type="descriptive_stats"
                                    )
                                    
                                    if interpretation:
                                        st.markdown("#### Analyse détaillée")
                                        st.markdown(interpretation)
                        
                        # Générer et afficher l'interprétation
                        if 'context' not in locals() or context is None:
                            context = f"Analyse statistique des variables numériques"
                        if 'data_desc' not in locals() or data_desc is None:
                            data_desc = "\n".join([
                                f"- {col}: {st.session_state.df_clean[col].describe().to_dict()}" 
                                for col in selected_num_cols
                            ])
                            
                        interpretation = generate_ai_interpretation(
                            context=context,
                            data_description=data_desc,
                            chart_type="table"
                        )
                        
                        if interpretation:
                            st.markdown("### Interprétation des statistiques")
                            st.markdown(interpretation)

                        # Section pour les analyses croisées
                        if len(selected_num_cols) > 1:
                            st.markdown("### 🔍 Analyses croisées")
                            cross_col1, cross_col2 = st.columns(2)
                            
                            # Incrémenter le compteur de widgets pour des clés uniques
                            if 'widget_counter' not in st.session_state:
                                st.session_state.widget_counter = 0
                            st.session_state.widget_counter += 1
                            
                            # Créer des clés uniques pour les widgets
                            widget_suffix = f"_{st.session_state.widget_counter}"
                            
                            with cross_col1:
                                x_var = st.selectbox(
                                    "Variable X", 
                                    selected_num_cols, 
                                    key=f"x_var{widget_suffix}"
                                )
                            with cross_col2:
                                # Filtrer les variables pour éviter de sélectionner la même variable pour X et Y
                                y_options = [c for c in selected_num_cols if c != x_var]
                                y_var = st.selectbox(
                                    "Variable Y", 
                                    y_options,
                                    key=f"y_var{widget_suffix}"
                                )
                            
                            # Scatter plot pour l'analyse croisée
                            scatter_fig = scatter_plot(
                                st.session_state.df_clean,
                                x_col=x_var,
                                y_col=y_var,
                                title=f"Relation entre {x_var} et {y_var}"
                            )
                            st.plotly_chart(
                                scatter_fig, 
                                use_container_width=True, 
                                key=f"scatter_{x_var}_{y_var}{widget_suffix}"
                            )
                            
                            # Calcul de la corrélation
                            correlation = st.session_state.df_clean[[x_var, y_var]].corr().iloc[0,1]
                            st.metric(
                                "Coefficient de corrélation", 
                                f"{correlation:.2f}"
                            )
                            
                            # Bouton d'interprétation avec une clé unique
                            if st.button(
                                "🔍 Interpréter la relation", 
                                key=f"btn_corr_{x_var}_{y_var}{widget_suffix}",
                                type="secondary"
                            ):
                                with st.spinner("Analyse de la relation..."):
                                    context = f"Relation entre {x_var} et {y_var}"
                                    data_desc = (
                                        f"Le coefficient de corrélation entre {x_var} et {y_var} est de {correlation:.2f}. "
                                        f"Cela indique une corrélation {'positive' if correlation > 0 else 'négative' if correlation < 0 else 'nulle'}. "
                                        f"La force de la relation est {'forte' if abs(correlation) > 0.7 else 'modérée' if abs(correlation) > 0.3 else 'faible'}."
                                    )
                                    interpretation = generate_ai_interpretation(
                                        context=context,
                                        data_description=data_desc,
                                        chart_type="scatter"
                                    )
                                    if interpretation:
                                        st.markdown("#### Interprétation de la relation")
                                        st.markdown(interpretation)
                                                # Visualisations individuelles
                        st.markdown("### 📊 Analyses univariées")
                        
                        # Incrémenter le compteur de widgets pour des clés uniques
                        if 'widget_counter' not in st.session_state:
                            st.session_state.widget_counter = 0
                            
                        for idx, col in enumerate(selected_num_cols):
                            # Incrémenter le compteur pour chaque variable
                            st.session_state.widget_counter += 1
                            widget_suffix = f"_{st.session_state.widget_counter}"
                            
                            # Créer une clé unique pour le toggle de la section
                            section_key = f"section_{col}{widget_suffix}"
                            
                            # Gérer l'état d'expansion avec une variable de session
                            if section_key not in st.session_state:
                                st.session_state[section_key] = idx < 2  # Par défaut, étendre les 2 premières sections
                                
                            # Créer un conteneur pour la section
                            section_container = st.container()
                            
                            # Bouton pour basculer l'affichage
                            if st.button(f"📊 Afficher/Masquer l'analyse de : {col}",
                                      key=f"btn_section_{col}{widget_suffix}"):
                                st.session_state[section_key] = not st.session_state[section_key]
                            
                            # Afficher le contenu conditionnellement
                            if st.session_state[section_key]:
                                with section_container:
                                    # Créer un conteneur pour la ligne de visualisations
                                    viz_container = st.container()
                                    col1, col2 = viz_container.columns(2)
                                
                                # Afficher les graphiques avec interprétation
                                with col1:
                                    hist_fig = histogram(st.session_state.df_clean, col)
                                    st.plotly_chart(hist_fig, use_container_width=True, 
                                                 key=f"hist_{col}{widget_suffix}")
                                    
                                    # Créer une clé unique pour le toggle de l'interprétation
                                    hist_expander_key = f"hist_expander_{col}{widget_suffix}"
                                    
                                    # Bouton pour afficher/masquer l'interprétation de l'histogramme
                                    if hist_expander_key not in st.session_state:
                                        st.session_state[hist_expander_key] = False
                                        
                                    if st.button(f"📊 Interpréter l'histogramme", 
                                               key=f"btn_hist_{col}{widget_suffix}"):
                                        st.session_state[hist_expander_key] = not st.session_state[hist_expander_key]
                                    
                                    # Afficher l'interprétation dans un conteneur conditionnel
                                    if st.session_state.get(hist_expander_key, False):
                                        st.markdown("#### 🔍 Interprétation de l'histogramme")
                                        with st.spinner("Génération de l'interprétation..."):
                                            context = f"Histogramme montrant la distribution de la variable: {col}"
                                            data_desc = (
                                                f"Distribution des valeurs de {col} avec {st.session_state.df_clean[col].nunique()} valeurs uniques. "
                                                f"La plage de valeurs va de {st.session_state.df_clean[col].min()} à {st.session_state.df_clean[col].max()}."
                                            )
                                            interpretation = generate_ai_interpretation(
                                                context=context,
                                                data_description=data_desc,
                                                chart_type="histogram"
                                            )
                                            if interpretation:
                                                st.markdown(interpretation)
                                
                                with col2:
                                    box_fig = boxplot(st.session_state.df_clean, col)
                                    st.plotly_chart(box_fig, use_container_width=True, 
                                                 key=f"box_{col}{widget_suffix}")
                                    
                                    # Créer une clé unique pour le toggle du boxplot
                                    box_expander_key = f"box_expander_{col}{widget_suffix}"
                                    
                                    # Bouton pour afficher/masquer l'interprétation du boxplot
                                    if box_expander_key not in st.session_state:
                                        st.session_state[box_expander_key] = False
                                        
                                    if st.button(f"📦 Interpréter le boxplot", 
                                               key=f"btn_box_{col}{widget_suffix}"):
                                        st.session_state[box_expander_key] = not st.session_state[box_expander_key]
                                    
                                    # Afficher l'interprétation dans un conteneur conditionnel
                                    if st.session_state.get(box_expander_key, False):
                                        st.markdown("#### 🔍 Interprétation du boxplot")
                                        with st.spinner("Génération de l'interprétation..."):
                                            q1 = st.session_state.df_clean[col].quantile(0.25)
                                            q3 = st.session_state.df_clean[col].quantile(0.75)
                                            iqr = q3 - q1
                                            lower_bound = q1 - 1.5 * iqr
                                            upper_bound = q3 + 1.5 * iqr
                                            outliers = st.session_state.df_clean[
                                                (st.session_state.df_clean[col] < lower_bound) | 
                                                (st.session_state.df_clean[col] > upper_bound)
                                            ]
                                            
                                            context = f"Boxplot montrant la distribution statistique de la variable: {col}"
                                            data_desc = (
                                                f"La boîte à moustaches montre la distribution des valeurs avec la médiane à {st.session_state.df_clean[col].median():.2f}. "
                                                f"L'intervalle interquartile (IQR) va de {q1:.2f} à {q3:.2f}. "
                                                f"{'Aucune valeur aberrante détectée.' if len(outliers) == 0 else f'Valeurs aberrantes potentielles: {len(outliers)} points en dehors de la plage [{lower_bound:.2f}, {upper_bound:.2f}]'}"
                                            )
                                            interpretation = generate_ai_interpretation(
                                                context=context,
                                                data_description=data_desc,
                                                chart_type="boxplot"
                                            )
                                            if interpretation:
                                                st.markdown(interpretation)
                            
                            # Stocker les métriques pour l'interprétation globale
                            if 'analysis_metrics' not in st.session_state:
                                st.session_state.analysis_metrics = {}
                                
                            st.session_state.analysis_metrics[col] = {
                                'type': 'numérique',
                                'valeurs_uniques': st.session_state.df_clean[col].nunique(),
                                'valeurs_manquantes': int(st.session_state.df_clean[col].isna().sum()),
                                'moyenne': float(st.session_state.df_clean[col].mean()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'ecart_type': float(st.session_state.df_clean[col].std()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'min': float(st.session_state.df_clean[col].min()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'max': float(st.session_state.df_clean[col].max()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'mediane': float(st.session_state.df_clean[col].median()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None
                            }
                else:
                    st.warning("Aucune variable numérique trouvée dans les données.")

            with tab2:
                if categorical_cols:
                    selected_cat_cols = st.multiselect(
                        "Sélectionnez les variables catégorielles",
                        categorical_cols,
                        default=categorical_cols[:3] if len(categorical_cols) > 3 else categorical_cols
                    )

                    if selected_cat_cols:
                        for col in selected_cat_cols:
                            st.markdown(f"#### Analyse de {col}")
                            # Tableau de fréquences avec interprétation
                            freq_table = st.session_state.df_clean[col].value_counts().reset_index()
                            freq_table.columns = [col, 'Fréquence']
                            
                            # Afficher le tableau de fréquences
                            st.markdown("##### Tableau de fréquences")
                            st.dataframe(freq_table)
                            
                            # Préparer le contexte pour l'interprétation
                            context = f"Tableau de fréquences pour la variable catégorielle: {col}"
                            data_desc = f"Nombre de catégories: {len(freq_table)}\n"
                            data_desc += f"Valeurs manquantes: {st.session_state.df_clean[col].isna().sum()}\n"
                            data_desc += f"Catégorie la plus fréquente: {freq_table.iloc[0][col]} ({freq_table.iloc[0]['Fréquence']} occurrences)"
                            
                            # Stocker les informations catégorielles pour l'interprétation globale
                            if 'categorical_metrics' not in st.session_state:
                                st.session_state.categorical_metrics = {}
                                
                            st.session_state.categorical_metrics[col] = {
                                'nb_categories': len(freq_table),
                                'categorie_principale': freq_table.iloc[0][col],
                                'freq_categorie_principale': int(freq_table.iloc[0]['Fréquence']),
                                'total': int(freq_table['Fréquence'].sum())
                            }
                            
                            # Visualisation avec interprétation
                            st.markdown("##### Répartition des catégories")
                            try:
                                # Utilisation directe de plotly.express
                                import plotly.express as px
                                fig = px.pie(freq_table, names=col, values='Fréquence', 
                                           title=f"Répartition de {col}")
                                st.plotly_chart(fig, use_container_width=True)
                            except Exception as e:
                                st.error(f"Erreur lors de la création du graphique: {str(e)}")
                                # Solution de secours avec go.Figure
                                import plotly.graph_objects as go
                                fig = go.Figure(data=[go.Pie(labels=freq_table[col], 
                                                          values=freq_table['Fréquence'],
                                                          name=col)])
                                fig.update_layout(title=f"Répartition de {col}")
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # Ajouter les données de répartition pour l'analyse globale
                            if 'categorical_distributions' not in st.session_state:
                                st.session_state.categorical_distributions = {}
                                
                            st.session_state.categorical_distributions[col] = {
                                'categories': freq_table[col].astype(str).tolist(),
                                'frequences': freq_table['Fréquence'].astype(int).tolist()
                            }
                else:
                    st.warning("Aucune variable catégorielle trouvée dans les données.")
                    
            # Onglet des analyses avancées
            with tab3:
                st.markdown("### Analyses statistiques avancées")
                
                # Sélection du type d'analyse
                analysis_type = st.selectbox(
                    "Type d'analyse",
                    [
                        "Sélectionner une analyse...",
                        "Test de normalité (Shapiro-Wilk)",
                        "Test T pour échantillon unique",
                        "Test T pour échantillons appariés",
                        "Test T pour échantillons indépendants",
                        "ANOVA à un facteur",
                        "Test du chi-carré d'indépendance",
                        "Analyse de corrélation",
                        "Régression linéaire simple",
                        "Régression linéaire multiple"
                    ]
                )
                
                if analysis_type != "Sélectionner une analyse...":
                    st.markdown(f"### {analysis_type}")
                    
                    # Test de normalité
                    if "normalité" in analysis_type.lower():
                        if len(numeric_cols) > 0:
                            selected_var = st.selectbox("Sélectionnez une variable numérique", numeric_cols)
                            if st.button("Exécuter le test de normalité"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[selected_var].dropna()
                                    stat, p_value = stats.shapiro(data)
                                    
                                    st.markdown("#### Résultats du test de normalité de Shapiro-Wilk")
                                    st.metric("Statistique de test", f"{stat:.4f}")
                                    st.metric("Valeur p", f"{p_value:.4f}")
                                    
                                    # Interprétation
                                    alpha = 0.05
                                    if p_value > alpha:
                                        st.success(f"La variable {selected_var} suit une distribution normale (p = {p_value:.4f} > {alpha}).")
                                    else:
                                        st.warning(f"La variable {selected_var} ne suit pas une distribution normale (p = {p_value:.4f} ≤ {alpha}).")
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test de normalité : {str(e)}")
                        else:
                            st.warning("Aucune variable numérique disponible pour le test de normalité.")
                    
                    # Test T pour échantillon unique
                    elif "échantillon unique" in analysis_type.lower():
                        if len(numeric_cols) > 0:
                            selected_var = st.selectbox("Sélectionnez une variable numérique", numeric_cols)
                            test_value = st.number_input("Valeur de test (moyenne hypothétique)", 
                                                       value=st.session_state.df_clean[selected_var].mean())
                            
                            if st.button("Exécuter le test T"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[selected_var].dropna()
                                    t_stat, p_value = stats.ttest_1samp(data, test_value)
                                    
                                    st.markdown("#### Résultats du test T pour échantillon unique")
                                    st.metric("Valeur de test", f"{test_value:.4f}")
                                    st.metric("Moyenne observée", f"{data.mean():.4f}")
                                    st.metric("Statistique T", f"{t_stat:.4f}")
                                    st.metric("Valeur p (bilatéral)", f"{p_value:.4f}")
                                    
                                    # Interprétation
                                    alpha = 0.05
                                    if p_value < alpha:
                                        st.success(f"La moyenne de {selected_var} est significativement différente de {test_value:.2f} (p = {p_value:.4f} < {alpha}).")
                                    else:
                                        st.warning(f"Aucune preuve pour rejeter l'hypothèse nulle : la moyenne de {selected_var} n'est pas significativement différente de {test_value:.2f} (p = {p_value:.4f} ≥ {alpha}).")
                                    
                                    # Ajouter aux résultats pour le rapport
                                    if 'advanced_analyses' not in st.session_state:
                                        st.session_state.advanced_analyses = {}
                                        
                                    st.session_state.advanced_analyses['ttest_1samp'] = {
                                        'type': 'Test T pour échantillon unique',
                                        'variable': selected_var,
                                        'valeur_test': float(test_value),
                                        'moyenne_observée': float(data.mean()),
                                        'statistique_T': float(t_stat),
                                        'valeur_p': float(p_value),
                                        'significatif': p_value < alpha,
                                        'interpretation': f"Différence significative" if p_value < alpha else "Pas de différence significative"
                                    }
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test T : {str(e)}")
                        else:
                            st.warning("Aucune variable numérique disponible pour le test T.")
                            
                    # Test T pour échantillons appariés
                    elif "appariés" in analysis_type.lower():
                        if len(numeric_cols) >= 2:
                            st.markdown("### Test T pour échantillons appariés")
                            st.info("Ce test compare les moyennes de deux variables mesurées sur les mêmes individus.")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                var1 = st.selectbox("Première mesure", numeric_cols, key="paired_var1")
                            with col2:
                                var2 = st.selectbox("Deuxième mesure", [col for col in numeric_cols if col != var1], key="paired_var2")
                            
                            if st.button("Exécuter le test T apparié"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[[var1, var2]].dropna()
                                    
                                    if len(data) < 2:
                                        st.error("Pas assez de données appariées pour effectuer le test.")
                                    else:
                                        t_stat, p_value = stats.ttest_rel(data[var1], data[var2])
                                        
                                        # Calcul des moyennes et écarts-types
                                        mean1, mean2 = data[var1].mean(), data[var2].mean()
                                        std1, std2 = data[var1].std(), data[var2].std()
                                        
                                        # Affichage des résultats
                                        st.markdown("#### Résultats du test T apparié")
                                        
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.metric(f"Moyenne {var1}", f"{mean1:.4f}")
                                            st.metric(f"Écart-type {var1}", f"{std1:.4f}")
                                        with col2:
                                            st.metric(f"Moyenne {var2}", f"{mean2:.4f}")
                                            st.metric(f"Écart-type {var2}", f"{std2:.4f}")
                                        
                                        st.metric("Statistique T", f"{t_stat:.4f}")
                                        st.metric("Valeur p (bilatéral)", f"{p_value:.4f}")
                                        
                                        # Interprétation
                                        alpha = 0.05
                                        if p_value < alpha:
                                            st.success(f"Il existe une différence significative entre les moyennes de {var1} et {var2} (p = {p_value:.4f} < {alpha}).")
                                        else:
                                            st.warning(f"Aucune différence significative n'a été détectée entre les moyennes de {var1} et {var2} (p = {p_value:.4f} ≥ {alpha}).")
                                        
                                        # Visualisation
                                        st.markdown("#### Visualisation des données")
                                        fig = px.scatter(
                                            data.melt(var_name='Variable', value_name='Valeur'),
                                            x='Variable',
                                            y='Valeur',
                                            color='Variable',
                                            title=f"Comparaison des distributions de {var1} et {var2}",
                                            box=True,
                                            points="all"
                                        )
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Ajouter aux résultats pour le rapport
                                        if 'advanced_analyses' not in st.session_state:
                                            st.session_state.advanced_analyses = {}
                                            
                                        st.session_state.advanced_analyses['ttest_paired'] = {
                                            'type': 'Test T pour échantillons appariés',
                                            'variables': [var1, var2],
                                            'moyennes': [float(mean1), float(mean2)],
                                            'ecarts_types': [float(std1), float(std2)],
                                            'statistique_T': float(t_stat),
                                            'valeur_p': float(p_value),
                                            'significatif': p_value < alpha,
                                            'interpretation': f"Différence significative entre {var1} et {var2}" if p_value < alpha \
                                                else f"Pas de différence significative entre {var1} et {var2}"
                                        }
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test T apparié : {str(e)}")
                        else:
                            st.warning("Au moins deux variables numériques sont nécessaires pour le test T apparié.")
                            
                    # Test T pour échantillons indépendants
                    elif "indépendants" in analysis_type.lower():
                        st.markdown("### Test T pour échantillons indépendants")
                        st.info("Ce test compare les moyennes de deux groupes indépendants.")
                        
                        # Sélection des variables
                        numeric_var = st.selectbox("Variable numérique à comparer", numeric_cols)
                        
                        # Trouver les variables catégorielles avec exactement 2 catégories
                        cat_cols = []
                        for col in st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns:
                            if st.session_state.df_clean[col].nunique() == 2:
                                cat_cols.append(col)
                        
                        if not cat_cols:
                            st.warning("Aucune variable catégorielle avec exactement deux catégories trouvée.")
                        else:
                            group_var = st.selectbox("Variable de groupement (binaire)", cat_cols)
                            
                            if st.button("Exécuter le test T indépendant"):
                                try:
                                    from scipy import stats
                                    
                                    # Préparer les données
                                    data = st.session_state.df_clean[[numeric_var, group_var]].dropna()
                                    groups = data[group_var].unique()
                                    
                                    if len(groups) != 2:
                                        st.error(f"La variable de groupement doit avoir exactement 2 catégories (trouvées : {len(groups)}).")
                                    else:
                                        group1 = data[data[group_var] == groups[0]][numeric_var]
                                        group2 = data[data[group_var] == groups[1]][numeric_var]
                                        
                                        # Vérifier l'égalité des variances
                                        _, p_levene = stats.levene(group1, group2)
                                        equal_var = p_levene > 0.05
                                        
                                        # Exécuter le test T
                                        t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=equal_var)
                                        
                                        # Calcul des statistiques descriptives
                                        stats_group1 = {
                                            'moyenne': group1.mean(),
                                            'ecart_type': group1.std(),
                                            'taille': len(group1)
                                        }
                                        stats_group2 = {
                                            'moyenne': group2.mean(),
                                            'ecart_type': group2.std(),
                                            'taille': len(group2)
                                        }
                                        
                                        # Affichage des résultats
                                        st.markdown("#### Résultats du test T indépendant")
                                        st.write(f"**Variable numérique** : {numeric_var}")
                                        st.write(f"**Variable de groupement** : {group_var}")
                                        
                                        # Tableau des statistiques descriptives
                                        st.markdown("##### Statistiques descriptives")
                                        stats_df = pd.DataFrame({
                                            'Groupe': [str(groups[0]), str(groups[1])],
                                            'Moyenne': [stats_group1['moyenne'], stats_group2['moyenne']],
                                            'Écart-type': [stats_group1['ecart_type'], stats_group2['ecart_type']],
                                            'Effectif': [stats_group1['taille'], stats_group2['taille']]
                                        })
                                        st.dataframe(stats_df)
                                        
                                        # Résultats du test
                                        st.markdown("##### Résultats du test")
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.metric("Statistique T", f"{t_stat:.4f}")
                                        with col2:
                                            st.metric("Valeur p (bilatéral)", f"{p_value:.4f}")
                                        
                                        st.info(f"Test d'égalité des variances (Levene) : p = {p_levene:.4f} - Hypothèse d'égalité des variances {'acceptée' if equal_var else 'rejetée'}")
                                        
                                        # Interprétation
                                        alpha = 0.05
                                        if p_value < alpha:
                                            st.success(f"Il existe une différence significative entre les moyennes des deux groupes (p = {p_value:.4f} < {alpha}).")
                                        else:
                                            st.warning(f"Aucune différence significative n'a été détectée entre les moyennes des deux groupes (p = {p_value:.4f} ≥ {alpha}).")
                                        
                                        # Visualisation
                                        st.markdown("#### Visualisation des données")
                                        fig = px.box(
                                            data,
                                            x=group_var,
                                            y=numeric_var,
                                            color=group_var,
                                            title=f"Distribution de {numeric_var} par {group_var}",
                                            points="all"
                                        )
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Ajouter aux résultats pour le rapport
                                        if 'advanced_analyses' not in st.session_state:
                                            st.session_state.advanced_analyses = {}
                                            
                                        st.session_state.advanced_analyses['ttest_ind'] = {
                                            'type': 'Test T pour échantillons indépendants',
                                            'variable_numerique': numeric_var,
                                            'variable_groupement': group_var,
                                            'groupes': [str(g) for g in groups],
                                            'moyennes': [float(stats_group1['moyenne']), float(stats_group2['moyenne'])],
                                            'ecarts_types': [float(stats_group1['ecart_type']), float(stats_group2['ecart_type'])],
                                            'tailles': [stats_group1['taille'], stats_group2['taille']],
                                            'statistique_T': float(t_stat),
                                            'valeur_p': float(p_value),
                                            'valeur_p_levene': float(p_levene),
                                            'variances_egales': equal_var,
                                            'significatif': p_value < alpha,
                                            'interpretation': f"Différence significative entre les groupes {groups[0]} et {groups[1]}" if p_value < alpha \
                                                else f"Pas de différence significative entre les groupes {groups[0]} et {groups[1]}"
                                        }
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test T indépendant : {str(e)}")
                    
                    # Analyse de corrélation
                    elif "corrélation" in analysis_type.lower():
                        if len(numeric_cols) >= 2:
                            selected_vars = st.multiselect(
                                "Sélectionnez deux variables numériques",
                                numeric_cols,
                                default=numeric_cols[:2],
                                max_selections=2
                            )
                            
                            if len(selected_vars) == 2 and st.button("Calculer la corrélation"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[selected_vars].dropna()
                                    
                                    # Calcul de la corrélation de Pearson
                                    pearson_corr, pearson_p = stats.pearsonr(data[selected_vars[0]], data[selected_vars[1]])
                                    
                                    # Calcul de la corrélation de Spearman
                                    spearman_corr, spearman_p = stats.spearmanr(data[selected_vars[0]], data[selected_vars[1]])
                                    
                                    st.markdown("#### Analyse de corrélation")
                                    
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric("Corrélation de Pearson", f"{pearson_corr:.4f}")
                                        st.metric("Valeur p (Pearson)", f"{pearson_p:.4f}")
                                    with col2:
                                        st.metric("Corrélation de Spearman", f"{spearman_corr:.4f}")
                                        st.metric("Valeur p (Spearman)", f"{spearman_p:.4f}")
                                    
                                    # Interprétation
                                    def interpret_correlation(coef):
                                        abs_coef = abs(coef)
                                        if abs_coef >= 0.8:
                                            return "forte"
                                        elif abs_coef >= 0.5:
                                            return "modérée"
                                        elif abs_coef >= 0.3:
                                            return "faible"
                                        else:
                                            return "nulle ou très faible"
                                    
                                    direction = "positive" if pearson_corr > 0 else "négative" if pearson_corr < 0 else "nulle"
                                    
                                    st.markdown("#### Interprétation")
                                    st.markdown(f"- **Corrélation de Pearson** : {interpret_correlation(pearson_corr).capitalize()} et {direction} (r = {pearson_corr:.3f})")
                                    
                                    if pearson_p < 0.05:
                                        st.success(f"La corrélation est statistiquement significative (p = {pearson_p:.4f} < 0.05).")
                                    else:
                                        st.warning(f"La corrélation n'est pas statistiquement significative (p = {pearson_p:.4f} ≥ 0.05).")
                                    
                                    # Nuage de points
                                    import plotly.express as px
                                    fig = px.scatter(
                                        data, 
                                        x=selected_vars[0], 
                                        y=selected_vars[1],
                                        trendline="ols",
                                        title=f"Nuage de points : {selected_vars[0]} vs {selected_vars[1]}"
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                except Exception as e:
                                    st.error(f"Erreur lors du calcul de la corrélation : {str(e)}")
                        else:
                            st.warning("Au moins deux variables numériques sont nécessaires pour l'analyse de corrélation.")
                    
                    # Régressions
                    elif "régression" in analysis_type.lower():
                        if len(numeric_cols) >= 2:
                            target_var = st.selectbox("Variable cible (Y)", numeric_cols)
                            feature_vars = st.multiselect(
                                "Variables explicatives (X)",
                                [col for col in numeric_cols if col != target_var],
                                default=[col for col in numeric_cols[:1] if col != target_var]
                            )
                            
                            if feature_vars and st.button("Exécuter la régression"):
                                try:
                                    import statsmodels.api as sm
                                    from sklearn.preprocessing import StandardScaler
                                    
                                    # Préparation des données
                                    data = st.session_state.df_clean[[target_var] + feature_vars].dropna()
                                    X = data[feature_vars]
                                    y = data[target_var]
                                    
                                    # Standardisation des variables
                                    scaler = StandardScaler()
                                    X_scaled = scaler.fit_transform(X)
                                    X_scaled = sm.add_constant(X_scaled)  # Ajout de la constante
                                    
                                    # Modèle de régression
                                    model = sm.OLS(y, X_scaled).fit()
                                    
                                    # Affichage des résultats
                                    st.markdown("#### Résumé du modèle de régression")
                                    st.markdown(f"**Variable cible** : {target_var}")
                                    st.markdown(f"**Variables explicatives** : {', '.join(feature_vars)}")
                                    st.markdown(f"**Nombre d'observations** : {len(data)}")
                                    
                                    # Métriques du modèle
                                    st.markdown("##### Métriques du modèle")
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("R²", f"{model.rsquared:.4f}")
                                    with col2:
                                        st.metric("R² ajusté", f"{model.rsquared_adj:.4f}")
                                    with col3:
                                        st.metric("F-statistique", f"{model.fvalue:.2f}")
                                    
                                    # Coefficients
                                    st.markdown("##### Coefficients du modèle")
                                    coef_df = model.summary2().tables[1]
                                    coef_df.index = ['Constante'] + feature_vars
                                    st.dataframe(coef_df)
                                    
                                    # Interprétation
                                    st.markdown("#### Interprétation")
                                    interpretation = []
                                    
                                    # Qualité du modèle
                                    if model.rsquared_adj > 0.7:
                                        interpretation.append(f"- Le modèle explique une grande partie de la variance de la variable cible (R² ajusté = {model.rsquared_adj:.3f}).")
                                    elif model.rsquared_adj > 0.3:
                                        interpretation.append(f"- Le modèle explique une partie modérée de la variance de la variable cible (R² ajusté = {model.rsquared_adj:.3f}).")
                                    else:
                                        interpretation.append(f"- Le modèle explique une faible partie de la variance de la variable cible (R² ajusté = {model.rsquared_adj:.3f}).")
                                    
                                    # Significativité globale
                                    if model.f_pvalue < 0.05:
                                        interpretation.append("- Le modèle est globalement significatif (p < 0.05).")
                                    else:
                                        interpretation.append("- Le modèle n'est pas globalement significatif (p ≥ 0.05).")
                                    
                                    # Coefficients significatifs
                                    significant_vars = []
                                    for var, pval in zip(['Constante'] + feature_vars, model.pvalues):
                                        if pval < 0.05:
                                            coef = model.params[var] if var == 'Constante' else model.params[var]
                                            direction = "positivement" if coef > 0 else "négativement"
                                            interpretation.append(f"- La variable **{var}** a un effet significatif {direction} sur la variable cible (p = {pval:.4f}).")
                                            significant_vars.append(var)
                                    
                                    if not significant_vars:
                                        interpretation.append("- Aucune variable n'a d'effet significatif sur la variable cible (tous les p-values ≥ 0.05).")
                                    
                                    st.markdown("\n".join(interpretation))
                                    
                                    # Graphique des résidus
                                    st.markdown("##### Analyse des résidus")
                                    fig = px.scatter(
                                        x=model.fittedvalues,
                                        y=model.resid,
                                        labels={'x': 'Valeurs prédites', 'y': 'Résidus'},
                                        title='Graphique des résidus vs valeurs prédites'
                                    )
                                    fig.add_hline(y=0, line_dash="dash", line_color="red")
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                except Exception as e:
                                    st.error(f"Erreur lors de l'exécution de la régression : {str(e)}")
                        else:
                            st.warning("Au moins deux variables numériques sont nécessaires pour la régression.")
                    
                    # Message pour les analyses non implémentées
                    else:
                        st.info(f"L'analyse '{analysis_type}' n'est pas encore implémentée. Elle sera disponible dans une prochaine mise à jour.")
                        
                        # Exemple de structure pour les futures implémentations
                        if "ANOVA" in analysis_type:
                            st.markdown("### ANOVA à un facteur")
                            
                            # Vérifier les prérequis
                            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
                            cat_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            if len(numeric_cols) < 1 or len(cat_cols) < 1:
                                st.warning("L'ANOVA nécessite au moins une variable numérique et une variable catégorielle.")
                            else:
                                # Sélection des variables
                                numeric_var = st.selectbox("Sélectionnez la variable numérique (variable réponse)", numeric_cols)
                                cat_var = st.selectbox("Sélectionnez la variable catégorielle (facteur)", cat_cols)
                                
                                # Vérifier le nombre de groupes
                                unique_groups = st.session_state.df_clean[cat_var].nunique()
                                if unique_groups < 2:
                                    st.error(f"La variable catégorielle doit avoir au moins 2 groupes (actuellement {unique_groups}).")
                                else:
                                    if st.button("Exécuter l'ANOVA", key="run_anova"):
                                        try:
                                            # Préparer les données
                                            groups = []
                                            for group in st.session_state.df_clean[cat_var].unique():
                                                groups.append(st.session_state.df_clean[st.session_state.df_clean[cat_var] == group][numeric_var].dropna())
                                            
                                            # Exécuter le test ANOVA
                                            f_val, p_val = stats.f_oneway(*groups)
                                            
                                            # Afficher les résultats
                                            st.markdown("#### Résultats de l'ANOVA")
                                            st.write(f"Variable numérique : **{numeric_var}**")
                                            st.write(f"Variable catégorielle : **{cat_var}** (groupes: {', '.join(map(str, st.session_state.df_clean[cat_var].unique()))})")
                                            
                                            col1, col2 = st.columns(2)
                                            with col1:
                                                st.metric("Statistique F", f"{f_val:.4f}")
                                            with col2:
                                                st.metric("Valeur p", f"{p_val:.4f}")
                                            
                                            # Interprétation
                                            alpha = 0.05
                                            if p_val < alpha:
                                                st.success("Il existe des différences statistiquement significatives entre les moyennes des groupes (p < 0.05).")
                                            else:
                                                st.info("Aucune différence statistiquement significative n'a été détectée entre les moyennes des groupes (p ≥ 0.05).")
                                            
                                            # Visualisation
                                            st.markdown("#### Visualisation des données")
                                            fig = px.box(
                                                st.session_state.df_clean, 
                                                x=cat_var, 
                                                y=numeric_var,
                                                title=f"Distribution de {numeric_var} par {cat_var}",
                                                color=cat_var
                                            )
                                            st.plotly_chart(fig, use_container_width=True)
                                            
                                            # Ajouter aux résultats pour le rapport
                                            if 'advanced_analyses' not in st.session_state:
                                                st.session_state.advanced_analyses = {}
                                            
                                            st.session_state.advanced_analyses['anova'] = {
                                                'type': 'ANOVA à un facteur',
                                                'variables': {
                                                    'numerique': numeric_var,
                                                    'categorielle': cat_var
                                                },
                                                'resultats': {
                                                    'statistique_F': float(f_val),
                                                    'valeur_p': float(p_val),
                                                    'significatif': p_val < alpha
                                                },
                                                'interpretation': "Différences significatives" if p_val < alpha else "Pas de différence significative"
                                            }
                                            
                                        except Exception as e:
                                            st.error(f"Erreur lors de l'exécution de l'ANOVA : {str(e)}")
                        elif "chi-carré" in analysis_type.lower():
                            st.markdown("### Test du chi-carré d'indépendance")
                            
                            # Trouver les variables catégorielles
                            cat_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            if len(cat_cols) < 2:
                                st.warning("Au moins deux variables catégorielles sont nécessaires pour le test du chi-carré.")
                            else:
                                # Sélection des variables
                                col1, col2 = st.columns(2)
                                with col1:
                                    var1 = st.selectbox("Première variable catégorielle", cat_cols, key="chi2_var1")
                                with col2:
                                    var2 = st.selectbox("Deuxième variable catégorielle", 
                                                      [col for col in cat_cols if col != var1], 
                                                      key="chi2_var2")
                                
                                # Options du test
                                with st.expander("Options avancées"):
                                    correction = st.checkbox("Appliquer la correction de Yates", value=True, 
                                                         help="Correction de continuité qui doit être appliquée quand les effectifs sont faibles.")
                                
                                if st.button("Exécuter le test du chi-carré"):
                                    try:
                                        from scipy import stats
                                        import numpy as np
                                        
                                        # Créer un tableau de contingence
                                        contingency_table = pd.crosstab(
                                            st.session_state.df_clean[var1], 
                                            st.session_state.df_clean[var2]
                                        )
                                        
                                        # Vérifier les effectifs théoriques
                                        chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table, correction=correction)
                                        
                                        # Calcul du V de Cramer (mesure d'effet)
                                        n = contingency_table.sum().sum()
                                        phi2 = chi2 / n
                                        r, k = contingency_table.shape
                                        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    
                                        rcorr = r - ((r-1)**2)/(n-1)
                                        kcorr = k - ((k-1)**2)/(n-1)
                                        cramers_v = np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))
                                        
                                        # Affichage des résultats
                                        st.markdown("#### Résultats du test du chi-carré")
                                        st.write(f"**Variables analysées** : {var1} et {var2}")
                                        
                                        # Tableau de contingence
                                        st.markdown("##### Tableau de contingence")
                                        st.dataframe(contingency_table)
                                        
                                        # Statistiques du test
                                        st.markdown("##### Statistiques du test")
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("Khi-deux", f"{chi2:.4f}")
                                        with col2:
                                            st.metric("Degrés de liberté", dof)
                                        with col3:
                                            st.metric("Valeur p", f"{p_value:.4f}")
                                        
                                        # Mesure d'effet
                                        st.markdown("##### Mesure d'effet (V de Cramer)")
                                        st.metric("V de Cramer", f"{cramers_v:.4f}")
                                        
                                        # Interprétation du V de Cramer
                                        interpretation_v = "nulle"
                                        if cramers_v >= 0.5:
                                            interpretation_v = "forte"
                                        elif cramers_v >= 0.3:
                                            interpretation_v = "modérée"
                                        elif cramers_v >= 0.1:
                                            interpretation_v = "faible"
                                            
                                        # Interprétation
                                        alpha = 0.05
                                        if p_value < alpha:
                                            st.success(f"Il existe une association statistiquement significative entre {var1} et {var2} (p = {p_value:.4f} < {alpha}).")
                                            st.info(f"L'association est de force {interpretation_v} (V de Cramer = {cramers_v:.3f}).")
                                        else:
                                            st.warning(f"Aucune association significative n'a été détectée entre {var1} et {var2} (p = {p_value:.4f} ≥ {alpha}).")
                                        
                                        # Visualisation
                                        st.markdown("#### Visualisation")
                                        
                                        # Heatmap des fréquences relatives par ligne
                                        fig = px.imshow(
                                            contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100,
                                            labels=dict(x=var2, y=var1, color="%")
                                        )
                                        fig.update_layout(
                                            title=f"Pourcentages en ligne de {var1} par {var2}",
                                            xaxis_title=var2,
                                            yaxis_title=var1
                                        )
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Ajouter aux résultats pour le rapport
                                        if 'advanced_analyses' not in st.session_state:
                                            st.session_state.advanced_analyses = {}
                                            
                                        st.session_state.advanced_analyses['chi2'] = {
                                            'type': "Test du Khi-deux d'indépendance",
                                            'variables': [var1, var2],
                                            'tableau_contingence': contingency_table.to_dict(),
                                            'khi_deux': float(chi2),
                                            'ddl': int(dof),
                                            'valeur_p': float(p_value),
                                            'v_cramer': float(cramers_v),
                                            'significatif': p_value < alpha,
                                            'interpretation': f"Association significative ({'forte' if cramers_v >= 0.5 else 'modérée' if cramers_v >= 0.3 else 'faible'})" if p_value < alpha \
                                                else "Pas d'association significative"
                                        }
                                        
                                    except Exception as e:
                                        st.error(f"Erreur lors du test du chi-carré : {str(e)}")

        # Section pour les corrélations
        with st.expander("📈 Analyse des corrélations", expanded=False):
            st.markdown("### Matrice de corrélation")
            
            # Initialiser les métriques de corrélation
            st.session_state.correlation_metrics = {
                'variables_numeriques': numeric_cols,
                'nb_variables': len(numeric_cols) if numeric_cols else 0
            }

            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()

            if len(numeric_cols) > 1:
                try:
                    # Calculer la matrice de corrélation
                    corr_matrix = st.session_state.df_clean[numeric_cols].corr()

                    # Afficher la heatmap
                    st.plotly_chart(correlation_heatmap(corr_matrix), use_container_width=True)

                    # Interprétation des corrélations
                    st.markdown("### Interprétation des corrélations")
                    strong_corrs = corr_matrix.unstack().sort_values(ascending=False)
                    strong_corrs = strong_corrs[strong_corrs < 1.0]  # Exclure l'auto-corrélation
                    strong_corrs = strong_corrs[(strong_corrs > 0.7) | (strong_corrs < -0.7)]

                    if not strong_corrs.empty:
                        st.dataframe(strong_corrs.reset_index().rename(columns={'level_0': 'Variable 1', 'level_1': 'Variable 2', 0: 'Corrélation'}))
                        
                        # Interprétation IA des corrélations
                        context = "Matrice de corrélation entre les variables numériques"
                        data_desc = f"Variables analysées: {', '.join(numeric_cols)}\n"
                        data_desc += f"Nombre total d'observations: {len(st.session_state.df_clean)}\n"
                        data_desc += "\nCorrélations fortes détectées:\n"
                        
                        # Ajouter les corrélations fortes à la description
                        for idx, (pair, value) in enumerate(strong_corrs.items(), 1):
                            data_desc += f"{idx}. {pair[0]} & {pair[1]}: {value:.2f}\n"
                        
                        # Générer l'interprétation IA
                        interpretation = generate_ai_interpretation(
                            context=context,
                            data_description=data_desc,
                            chart_type="correlation_matrix"
                        )
                        
                        if interpretation:
                            st.markdown("### Interprétation des corrélations")
                            st.markdown(interpretation)
                    else:
                        st.info("Aucune corrélation forte (>0.7 ou <-0.7) n'a été détectée.")

                except Exception as e:
                    st.error(f"Erreur lors du calcul des corrélations: {str(e)}")
            else:
                st.warning("Au moins deux variables numériques sont nécessaires pour calculer les corrélations.")

        # Section pour les analyses avancées
        with st.expander("🤖 Analyses avancées", expanded=False):
            st.markdown("### Analyses avancées et modélisation")

            analysis_type = st.selectbox(
                "Type d'analyse avancée",
                ["Sélectionnez...", "Clustering", "Classification", "Régression", "Séries temporelles"],
                key="advanced_analysis_type"
            )

            if analysis_type != "Sélectionnez...":
                if analysis_type in ["Classification", "Régression"]:
                    # Sélection des variables
                    numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
                    categorical_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()

                    if not numeric_cols:
                        st.warning("Aucune variable numérique disponible pour l'analyse.")
                    else:
                        target_col = st.selectbox(
                            "Sélectionnez la variable cible",
                            numeric_cols + categorical_cols,
                            key="target_col"
                        )

                        # Sélection des variables explicatives
                        available_features = [col for col in numeric_cols + categorical_cols if col != target_col]
                        default_features = [col for col in numeric_cols[:3] if col in available_features]
                        
                        feature_cols = st.multiselect(
                            "Sélectionnez les variables explicatives",
                            options=available_features,
                            default=default_features[:min(3, len(default_features))],
                            key=f"feature_cols_{analysis_type}_{target_col}"
                        )

                        if st.button(f"Lancer l'analyse {analysis_type.lower()}"):
                            with st.spinner(f"Exécution de l'analyse {analysis_type.lower()}..."):
                                try:
                                    # Préparation des données
                                    X = st.session_state.df_clean[feature_cols]
                                    y = st.session_state.df_clean[target_col]

                                    # Conversion des variables catégorielles
                                    X = pd.get_dummies(X)

                                    # Division des données
                                    from sklearn.model_selection import train_test_split
                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                                    # Sélection du modèle
                                    if analysis_type == "Classification":
                                        from sklearn.ensemble import RandomForestClassifier
                                        model = RandomForestClassifier(random_state=42)
                                    else:  # Régression
                                        from sklearn.ensemble import RandomForestRegressor
                                        model = RandomForestRegressor(random_state=42)

                                    # Entraînement du modèle
                                    model.fit(X_train, y_train)

                                    # Évaluation
                                    from sklearn.metrics import accuracy_score, r2_score

                                    if analysis_type == "Classification":
                                        y_pred = model.predict(X_test)
                                        score = accuracy_score(y_test, y_pred)
                                        st.success(f"Précision du modèle: {score:.2f}")
                                    else:
                                        y_pred = model.predict(X_test)
                                        score = r2_score(y_test, y_pred)
                                        st.success(f"Coefficient de détermination (R²): {score:.2f}")

                                    # Importance des variables
                                    st.subheader("Importance des variables")
                                    feature_importance = pd.DataFrame({
                                        'Variable': X.columns,
                                        'Importance': model.feature_importances_
                                    }).sort_values('Importance', ascending=False)

                                    st.plotly_chart(px.bar(feature_importance, x='Variable', y='Importance'), use_container_width=True)

                                    # Préparation des données pour l'interprétation par Gemini
                                    top_features = feature_importance.head(5).to_dict('records')
                                    
                                    # Construction du prompt pour Gemini
                                    prompt = f"""
                                    Tu es un expert en analyse de données. Analyse les résultats suivants d'une analyse de {analysis_type.lower()}:
                                    
                                    Variables les plus importantes:
                                    """
                                    
                                    for i, feat in enumerate(top_features, 1):
                                        prompt += f"{i}. {feat['Variable']} (importance: {feat['Importance']:.3f})\n"
                                    
                                    prompt += f"\nScore du modèle: {score:.2f}\n"
                                    prompt += "\nDonne une interprétation claire et concise de ces résultats en français, en mettant en avant les points clés et les implications pratiques. Inclus 2-3 recommandations d'actions concrètes."
                                    
                                    try:
                                        # Appel à l'API Gemini avec le modèle par défaut
                                        interpretation = call_gemini_api(prompt)
                                        
                                    except Exception as e:
                                        st.warning(f"Impossible de contacter l'API Gemini: {str(e)}")
                                        # Interprétation de secours
                                        interpretation = f"""
                                        **Résultats de l'analyse de {analysis_type.lower()}**
                                        
                                        **Variables les plus importantes :**
                                        """
                                        for i, feat in enumerate(top_features, 1):
                                            interpretation += f"{i}. {feat['Variable']} (importance: {feat['Importance']:.3f})\n"
                                        
                                        interpretation += f"\n**Score du modèle :** {score:.2f}\n"
                                        interpretation += """
                                        
                                        **Recommandations :**
                                        - Les variables avec une importance élevée ont plus d'influence sur la prédiction
                                        - Explorez les relations entre ces variables et la cible
                                        - Envisagez d'ajouter plus de données ou d'autres variables pertinentes
                                        """
                                    
                                    # Affichage des résultats
                                    st.markdown("### 📊 Interprétation des résultats")
                                    st.markdown(interpretation)
                                    
                                    # Sauvegarde des résultats
                                    st.session_state.custom_analysis_results[f"{analysis_type}_{target_col}"] = {
                                        'model': model,
                                        'features': feature_cols,
                                        'target': target_col,
                                        'score': score,
                                        'importance': feature_importance.to_dict('records')
                                    }

                                except Exception as e:
                                    st.error(f"Erreur lors de l'analyse: {str(e)}")
                                    st.exception(e)

                elif analysis_type == "Clustering":
                    numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()

                    if not numeric_cols:
                        st.warning("Aucune variable numérique disponible pour le clustering.")
                    else:
                        selected_cols = st.multiselect(
                            "Sélectionnez les variables pour le clustering",
                            numeric_cols,
                            default=numeric_cols[:3],
                            key="clustering_cols"
                        )

                        n_clusters = st.slider("Nombre de clusters", 2, 10, 3, key="n_clusters")

                        if st.button("Exécuter le clustering"):
                            with st.spinner("Exécution du clustering..."):
                                try:
                                    from sklearn.cluster import KMeans
                                    from sklearn.preprocessing import StandardScaler

                                    # Préparation des données
                                    X = st.session_state.df_clean[selected_cols]
                                    X = StandardScaler().fit_transform(X)

                                    # Clustering
                                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                                    clusters = kmeans.fit_predict(X)

                                    # Ajout des clusters au DataFrame
                                    st.session_state.df_clean['Cluster'] = clusters

                                    # Visualisation
                                    st.subheader("Visualisation des clusters")

                                    # Réduction de dimension pour la visualisation
                                    from sklearn.decomposition import PCA
                                    pca = PCA(n_components=2)
                                    X_pca = pca.fit_transform(X)

                                    # Création d'un DataFrame pour la visualisation
                                    viz_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
                                    viz_df['Cluster'] = clusters

                                    # Affichage
                                    st.plotly_chart(px.scatter(
                                        viz_df, x='PC1', y='PC2', color='Cluster',
                                        title="Projection des clusters (PCA)"
                                    ), use_container_width=True)

                                    # Sauvegarde des résultats
                                    st.session_state.custom_analysis_results['clustering'] = {
                                        'model': kmeans,
                                        'features': selected_cols,
                                        'n_clusters': n_clusters,
                                        'clusters': clusters.tolist()
                                    }

                                    st.success("Clustering terminé avec succès!")

                                except Exception as e:
                                    st.error(f"Erreur lors du clustering: {str(e)}")
                                    st.exception(e)

                elif analysis_type == "Séries temporelles":
                    date_cols = st.session_state.df_clean.select_dtypes(include=['datetime64']).columns.tolist()

                    if not date_cols:
                        st.warning("Aucune colonne de date détectée dans les données.")
                    else:
                        date_col = st.selectbox(
                            "Sélectionnez la colonne de date",
                            date_cols,
                            key="ts_date_col"
                        )

                        numeric_cols = [col for col in st.session_state.df_clean.select_dtypes(include=['number']).columns if col != date_col]

                        if not numeric_cols:
                            st.warning("Aucune variable numérique disponible pour l'analyse des séries temporelles.")
                        else:
                            value_col = st.selectbox(
                                "Sélectionnez la variable à analyser",
                                numeric_cols,
                                key="ts_value_col"
                            )

                            if st.button("Analyser la série temporelle"):
                                with st.spinner("Analyse de la série temporelle..."):
                                    try:
                                        # Préparation des données
                                        ts_data = st.session_state.df_clean[[date_col, value_col]].dropna()
                                        ts_data = ts_data.set_index(date_col).sort_index()

                                        # Visualisation
                                        st.subheader("Visualisation de la série temporelle")
                                        st.plotly_chart(px.line(
                                            ts_data, x=ts_data.index, y=value_col,
                                            title=f"Évolution de {value_col} au fil du temps"
                                        ), use_container_width=True)

                                        # Décomposition de la série temporelle
                                        from statsmodels.tsa.seasonal import seasonal_decompose

                                        st.subheader("Décomposition de la série temporelle")
                                        decomposition = seasonal_decompose(ts_data[value_col], model='additive', period=12)
                                        decomposition.plot()
                                        st.pyplot()

                                        # Sauvegarde des résultats
                                        st.session_state.custom_analysis_results['time_series'] = {
                                            'date_col': date_col,
                                            'value_col': value_col,
                                            'data': ts_data.reset_index().to_dict('records')
                                        }

                                        st.success("Analyse de la série temporelle terminée avec succès!")

                                    except Exception as e:
                                        st.error(f"Erreur lors de l'analyse de la série temporelle: {str(e)}")
                                        st.exception(e)

        # Section pour les analyses avancées avec requêtes en langage naturel
        st.markdown("---")
        st.markdown("## 🔍 Analyse avancée")
        
        # Section des suggestions d'analyse
        with st.expander("💡 Suggestions d'analyse rapide", expanded=True):
            st.markdown("### Analyses suggérées")
            st.caption("Sélectionnez une suggestion pour générer automatiquement le code d'analyse correspondant.")
            
            # Détection des types de colonnes
            df = st.session_state.df_clean
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
            date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
            
            # Générer les suggestions basées sur les données disponibles
            suggestions = generate_analysis_suggestions(numeric_cols, cat_cols, date_cols, max_suggestions=8)
            
            # Afficher les suggestions sous forme de cartes
            if suggestions:
                # Créer un espace pour afficher les détails de la suggestion sélectionnée
                selected_suggestion = None
                
                # Afficher les cartes de suggestions
                cols = st.columns(2)
                for i, suggestion in enumerate(suggestions):
                    with cols[i % 2]:
                        with st.container(border=True):
                            col1, col2 = st.columns([1, 8])
                            with col1:
                                st.markdown(f"## {suggestion['title'].split(' ')[0]}")  # Afficher uniquement l'emoji
                            with col2:
                                st.markdown(f"**{suggestion['title']}**")
                                
                            st.caption(suggestion['description'])
                            
                            # Bouton pour utiliser la suggestion
                            if st.button("Utiliser cette analyse", 
                                       key=f"suggest_btn_{i}",
                                       use_container_width=True,
                                       type="primary"):
                                # Mettre à jour la requête et le type
                                query_key = f"natural_language_query_{suggestion['code_type'].lower()}"
                                st.session_state[query_key] = suggestion['query']
                                st.session_state.query_type = suggestion['code_type']
                                st.session_state.show_generated_code = True
                                st.rerun()
                            
                            # Bouton pour voir plus de détails
                            if st.button("ℹ️ En savoir plus", 
                                       key=f"detail_btn_{i}",
                                       use_container_width=True):
                                selected_suggestion = suggestion
                
                # Afficher les détails de la suggestion sélectionnée
                if selected_suggestion:
                    st.markdown("---")
                    st.markdown(f"### 🔍 Détails de l'analyse")
                    
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown("#### 📝 Description")
                        st.info(selected_suggestion['description'])
                        
                        st.markdown("#### 📊 Type d'analyse")
                        st.code(selected_suggestion['code_type'], language='python')
                        
                    with col2:
                        st.markdown("#### 🔍 Variables impliquées")
                        if 'variables' in selected_suggestion:
                            if isinstance(selected_suggestion['variables'], list):
                                for var in selected_suggestion['variables']:
                                    st.markdown(f"- `{var}`")
                        
                        st.markdown("#### 📋 Requête générée")
                        st.code(selected_suggestion['query'], language='python')
                    
                    # Bouton pour utiliser cette suggestion
                    if st.button("✅ Utiliser cette analyse", 
                               key="use_selected_suggestion",
                               use_container_width=True,
                               type="primary"):
                        query_key = f"natural_language_query_{selected_suggestion['code_type'].lower()}"
                        st.session_state[query_key] = selected_suggestion['query']
                        st.session_state.query_type = selected_suggestion['code_type']
                        st.session_state.show_generated_code = True
                        st.rerun()
            
            else:
                st.info("⚠️ Pas assez de données pour générer des suggestions d'analyse pertinentes.")
                st.markdown("""
                Pour obtenir des suggestions d'analyse plus pertinentes :
                - Assurez-vous que vos données contiennent des colonnes numériques et/ou catégorielles
                - Vérifiez que les types de données sont correctement détectés
                - Utilisez l'étape de nettoyage pour corriger les problèmes de données
                """)
                
            # Ajouter des suggestions basées sur les objectifs de l'analyse
            if 'analysis_goals' in st.session_state and st.session_state.analysis_goals:
                st.markdown("---")
                st.markdown("### 🎯 Suggestions basées sur vos objectifs")
                st.caption("Ces suggestions sont générées spécifiquement en fonction des objectifs que vous avez définis.")
                
                # Générer des suggestions basées sur les objectifs de l'utilisateur
                goal_suggestions = generate_goal_based_suggestions(
                    st.session_state.analysis_goals,
                    numeric_cols,
                    cat_cols,
                    date_cols,
                    max_suggestions=3
                )
                
                if goal_suggestions:
                    # Afficher les suggestions basées sur les objectifs
                    goal_cols = st.columns(min(3, len(goal_suggestions)))
                    for i, suggestion in enumerate(goal_suggestions):
                        with goal_cols[i % len(goal_cols)]:
                            with st.container(border=True):
                                col1, col2 = st.columns([1, 4])
                                with col1:
                                    st.markdown(f"## {suggestion['title'].split(' ')[0]}")
                                with col2:
                                    st.markdown(f"**{suggestion['title']}**")
                                
                                st.caption(suggestion['description'])
                                
                                if st.button("Utiliser cette analyse", 
                                           key=f"goal_btn_{i}",
                                           use_container_width=True,
                                           type="secondary"):
                                    query_key = f"natural_language_query_{suggestion['code_type'].lower()}"
                                    st.session_state[query_key] = suggestion['query']
                                    st.session_state.query_type = suggestion['code_type']
                                    st.session_state.show_generated_code = True
                                    st.rerun()
                else:
                    st.info("Aucune suggestion spécifique n'a pu être générée à partir de vos objectifs.")
                    st.markdown("""
                    Pour obtenir des suggestions plus pertinentes, vous pouvez :
                    - Être plus précis dans vos objectifs d'analyse
                    - Mentionner des variables spécifiques que vous souhaitez analyser
                    - Décrire le type d'analyse que vous souhaitez effectuer
                    """)
        
        st.markdown("---")
        
        # Détection automatique des types de variables pour les suggestions
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
        cat_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
        date_cols = st.session_state.df_clean.select_dtypes(include=['datetime64']).columns.tolist()
        
        # Sélection du type de requête
        query_type = st.radio("Type de requête :", ["SQL", "Python"], horizontal=True, key="query_type")
        
        # Zone de saisie de la requête en langage naturel
        query = st.text_area(
            f"Décrivez en langage naturel ce que vous souhaitez faire ({query_type}):",
            key=f"natural_language_query_{query_type.lower()}",
            height=100,
            placeholder="Ex: Afficher la moyenne des ventes par catégorie et par mois",
            value=st.session_state.get(f"natural_language_query_{query_type.lower()}", "")
        )
        # Bouton pour générer le code
        if st.button("Générer le code", key="generate_code_btn_sql"):
            if not query.strip():
                st.warning("Veuillez entrer une description de ce que vous souhaitez faire.")
            else:
                with st.spinner("Génération du code en cours..."):
                    try:
                        # Générer le code en fonction du type sélectionné
                        df_columns = st.session_state.df_clean.columns.tolist()
                        generated_code = generate_code_from_natural_language(
                            query,
                            'sql' if query_type == "SQL" else 'python',
                            df_columns
                        )
                        
                        # Stocker le code généré dans la session
                        st.session_state.generated_code = generated_code
                        st.session_state.show_generated_code = True
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la génération du code : {str(e)}")
        
        # Afficher le code généré s'il existe
        if hasattr(st.session_state, 'generated_code') and st.session_state.generated_code:
            st.markdown("### Code généré :")
            st.code(st.session_state.generated_code, language='python' if query_type == "Python" else 'sql')
            
            # Bouton pour exécuter le code
            if st.button("Exécuter le code", key="execute_code_btn"):
                with st.spinner("Exécution en cours..."):
                    try:
                        # Exécuter le code généré
                        if query_type == "SQL":
                            success, message, result = execute_sql_query(
                                st.session_state.generated_code,
                                st.session_state.df_clean
                            )
                        else:  # Python
                            # Créer un espace de noms pour l'exécution du code
                            local_vars = {'df': st.session_state.df_clean, 'st': st, 'plt': plt, 'px': px}
                            global_vars = {}
                            
                            # Exécuter le code Python
                            exec(st.session_state.generated_code, global_vars, local_vars)
                            
                            # Récupérer le résultat si une variable 'result' a été définie
                            result = local_vars.get('result', None)
                            success = result is not None
                            message = "Exécution réussie" if success else "Aucun résultat à afficher"
                        
                        # Afficher le résultat
                        if success and result is not None:
                            if hasattr(result, 'head') and hasattr(result, 'to_csv'):  # C'est un DataFrame
                                st.dataframe(result.head(100))
                                
                                # Boutons d'export
                                csv = result.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    "Télécharger en CSV",
                                    csv,
                                    "resultat_analyse.csv",
                                    "text/csv",
                                    key='download-csv'
                                )
                                
                                # Générer une interprétation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("🔍 Interprétation des résultats"):
                                    st.write(interpretation)
                            
                            elif isinstance(result, (dict, list)):  # Résultat structuré
                                st.json(result)
                                
                                # Générer une interprétation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("🔍 Interprétation des résultats"):
                                    st.write(interpretation)
                            
                            # Vérifier si un graphique a été affiché (via st.pyplot ou st.plotly_chart)
                            if 'plt' in locals() and plt.gcf().get_axes():
                                st.pyplot(plt.gcf())
                        
                        if not success:
                            st.warning(message)
                            
                    except Exception as e:
                        st.error(f"Erreur lors de l'exécution du code : {str(e)}")
                        st.exception(e)
        
        # Affichage des suggestions basées sur le contexte
        st.markdown("### 💡 Suggestions de requêtes basées sur votre contexte")
        
        # Zone de saisie de la requête en langage naturel
        query = st.text_area(
            f"Décrivez en langage naturel ce que vous souhaitez faire ({query_type}):",
            key="natural_language_query",
            height=100,
            placeholder="Ex: Afficher la moyenne des ventes par catégorie et par mois"
        )
        
        # Bouton pour générer le code
        if st.button("Générer le code", key="generate_code_btn_python"):
            if not query.strip():
                st.warning("Veuillez entrer une description de ce que vous souhaitez faire.")
            else:
                with st.spinner("Génération du code en cours..."):
                    try:
                        # Générer le code en fonction du type sélectionné
                        df_columns = st.session_state.df_clean.columns.tolist()
                        generated_code = generate_code_from_natural_language(
                            query,
                            'sql' if query_type == "SQL" else 'python',
                            df_columns
                        )
                        
                        # Stocker le code généré dans la session
                        st.session_state.generated_code = generated_code
                        st.session_state.show_generated_code = True
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la génération du code : {str(e)}")
        
        # Afficher le code généré s'il existe
        if hasattr(st.session_state, 'generated_code') and st.session_state.generated_code:
            st.markdown("### Code généré :")
            st.code(st.session_state.generated_code, language='python' if query_type == "Python" else 'sql')
            
            # Bouton pour exécuter le code
            if st.button("Exécuter le code", key="execute_code_btn"):
                with st.spinner("Exécution en cours..."):
                    try:
                        # Exécuter le code généré
                        if query_type == "SQL":
                            success, message, result = execute_sql_query(
                                st.session_state.generated_code,
                                st.session_state.df_clean
                            )
                        else:  # Python
                            # Créer un espace de noms pour l'exécution du code
                            local_vars = {'df': st.session_state.df_clean, 'st': st, 'plt': plt, 'px': px}
                            global_vars = {}
                            
                            # Exécuter le code Python
                            exec(st.session_state.generated_code, global_vars, local_vars)
                            
                            # Récupérer le résultat si une variable 'result' a été définie
                            result = local_vars.get('result', None)
                            success = result is not None
                            message = "Exécution réussie" if success else "Aucun résultat à afficher"
                        
                        # Afficher le résultat
                        if success and result is not None:
                            if hasattr(result, 'head') and hasattr(result, 'to_csv'):  # C'est un DataFrame
                                st.dataframe(result.head(100))
                                
                                # Boutons d'export
                                csv = result.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    "Télécharger en CSV",
                                    csv,
                                    "resultat_analyse.csv",
                                    "text/csv",
                                    key='download-csv'
                                )
                                
                                # Générer une interprétation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("🔍 Interprétation des résultats"):
                                    st.write(interpretation)
                            
                            elif isinstance(result, (dict, list)):  # Résultat structuré
                                st.json(result)
                                
                                # Générer une interprétation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("🔍 Interprétation des résultats"):
                                    st.write(interpretation)
                            
                            # Vérifier si un graphique a été affiché (via st.pyplot ou st.plotly_chart)
                            if 'plt' in locals() and plt.gcf().get_axes():
                                st.pyplot(plt.gcf())
                        
                        if not success:
                            st.warning(message)
                            
                    except Exception as e:
                        st.error(f"Erreur lors de l'exécution du code : {str(e)}")
                        st.exception(e)
                st.markdown("#### 🔄 Analyse des relations entre variables numériques et catégorielles")
                
                # Sélection des variables pour l'analyse croisée
                num_col = st.selectbox("Sélectionnez une variable numérique", numeric_cols, key="num_col_cross")
                cat_col = st.selectbox("Sélectionnez une variable catégorielle", cat_cols, key="cat_col_cross")
                
                if st.button("Analyser la relation", key="analyze_relation_btn"):
                    with st.spinner("Analyse en cours..."):
                        try:
                            # Création d'une figure avec plusieurs sous-graphiques
                            import plotly.subplots as sp
                            from plotly import graph_objects as go
                            
                            # Création de la figure avec 2 lignes et 2 colonnes
                            fig = sp.make_subplots(
                                rows=2, cols=2,
                                subplot_titles=(
                                    f'Distribution de {num_col} par {cat_col}',
                                    f'Boîtes à moustaches',
                                    f'Statistiques descriptives',
                                    f'Test statistique ANOVA'
                                ),
                                vertical_spacing=0.15,
                                specs=[[{"type": "histogram"}, {"type": "box"}],
                                      [{"colspan": 2, "type": "table"}, None]]
                            )
                            
                            # 1. Histogramme groupé
                            hist_data = []
                            for category in st.session_state.df_clean[cat_col].unique():
                                hist_data.append(go.Histogram(
                                    x=st.session_state.df_clean[st.session_state.df_clean[cat_col] == category][num_col],
                                    name=str(category),
                                    opacity=0.7
                                ))
                            
                            for trace in hist_data:
                                fig.add_trace(trace, row=1, col=1)
                            
                            # 2. Boîtes à moustaches
                            box_data = []
                            for category in st.session_state.df_clean[cat_col].unique():
                                box_data.append(go.Box(
                                    y=st.session_state.df_clean[st.session_state.df_clean[cat_col] == category][num_col],
                                    name=str(category)
                                ))
                            
                            for trace in box_data:
                                fig.add_trace(trace, row=1, col=2)
                            
                            # 3. Tableau des statistiques descriptives
                            stats_df = st.session_state.df_clean.groupby(cat_col)[num_col].describe().T
                            
                            fig.add_trace(
                                go.Table(
                                    header=dict(
                                        values=['Statistique'] + [str(x) for x in stats_df.columns],
                                        font=dict(size=10),
                                        align="left"
                                    ),
                                    cells=dict(
                                        values=[stats_df.index] + [stats_df[col] for col in stats_df.columns],
                                        align = "left")
                                ),
                                row=2, col=1
                            )
                            
                            # 4. Test ANOVA
                            from scipy import stats
                            
                            # Préparation des données pour l'ANOVA
                            groups = [st.session_state.df_clean[st.session_state.df_clean[cat_col] == category][num_col] 
                                     for category in st.session_state.df_clean[cat_col].unique()]
                            
                            # Vérification des conditions d'application de l'ANOVA
                            try:
                                # Vérification de la normalité avec Shapiro-Wilk
                                normality = True
                                for group in groups:
                                    if len(group) > 3 and len(group) < 5000:  # Shapiro est fiable pour des échantillons jusqu'à 5000
                                        _, p_value = stats.shapiro(group)
                                        if p_value < 0.05:
                                            normality = False
                                            break
                            except Exception as e:
                                st.warning(f"Erreur lors du test de normalité : {str(e)}")
                                normality = False  # En cas d'erreur, on suppose la non-normalité
                            
                            if len(groups) >= 2:
                                if normality and len(groups) == 2:
                                    # Test t pour 2 groupes
                                    t_stat, p_value = stats.ttest_ind(*groups, equal_var=False)
                                    test_name = "Test t de Student (2 échantillons indépendants)"
                                    test_result = f"t = {t_stat:.3f}, p-value = {p_value:.4f}"
                                elif len(groups) > 2 and normality:
                                    # ANOVA pour plus de 2 groupes
                                    f_stat, p_value = stats.f_oneway(*groups)
                                    test_name = "Analyse de la variance (ANOVA)"
                                    test_result = f"F = {f_stat:.3f}, p-value = {p_value:.4f}"
                                else:
                                    # Test non paramétrique de Kruskal-Wallis
                                    h_stat, p_value = stats.kruskal(*groups)
                                    test_name = "Test de Kruskal-Wallis (non paramétrique)"
                                    test_result = f"H = {h_stat:.3f}, p-value = {p_value:.4f}"
                                
                                # Interprétation du test
                                interpretation = ""
                                if p_value < 0.05:
                                    interpretation = f"<span style='color:green'>Différence statistiquement significative entre les groupes (p < 0.05)</span>"
                                else:
                                    interpretation = f"<span style='color:orange'>Aucune différence statistiquement significative détectée entre les groupes (p ≥ 0.05)</span>"
                                
                                # Ajout des résultats du test
                                test_results = [
                                    ["Test utilisé", test_name],
                                    ["Résultat", test_result],
                                    ["Interprétation", interpretation]
                                ]
                                
                                fig.add_trace(
                                    go.Table(
                                        header=dict(
                                            values=['Métrique', 'Valeur'],
                                            font=dict(size=10),
                                            align="left"
                                        ),
                                        cells=dict(
                                            values=[[x[0] for x in test_results], 
                                                   [x[1] for x in test_results]],
                                            align = "left",
                                            height=25
                                        )
                                    ),
                                    row=2, col=2
                                )
                            
                            # Mise en page finale
                            fig.update_layout(
                                height=900,
                                showlegend=True,
                                title_text=f"Analyse croisée : {num_col} par {cat_col}",
                                margin=dict(t=100, b=50, l=50, r=50)
                            )
                            
                            # Affichage de la figure
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # Génération d'une interprétation automatique
                            interpretation_prompt = f"""
                            Je vais analyser la relation entre la variable numérique '{num_col}' et la variable catégorielle '{cat_col}'. 
                            Voici un aperçu des données :
                            {st.session_state.df_clean[[num_col, cat_col]].describe().to_string()}
                            
                            Voici les résultats du test statistique : {test_name}
                            Résultat : {test_result}
                            
                            Peux-tu fournir une interprétation claire et concise de ces résultats en français, en expliquant ce que cela signifie pour un utilisateur non technique ?
                            """
                            
                            interpretation = call_gemini_api(interpretation_prompt)
                            
                            with st.expander("📝 Interprétation des résultats", expanded=True):
                                st.markdown(interpretation)
                            
                            # Sauvegarde de l'analyse
                            if 'cross_analyses' not in st.session_state:
                                st.session_state.cross_analyses = []
                                
                            st.session_state.cross_analyses.append({
                                'num_var': num_col,
                                'cat_var': cat_col,
                                'interpretation': interpretation,
                                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            })
                            
                            st.success("Analyse croisée terminée avec succès !")
                            
                        except Exception as e:
                            st.error(f"Une erreur est survenue lors de l'analyse croisée : {str(e)}")
                            st.exception(e)
            
        # Section pour les analyses numériques
        elif analysis_type == "Numérique vs Numérique" and len(numeric_cols) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                num_col1 = st.selectbox("Première variable numérique", numeric_cols, key="num_col1")
            with col2:
                num_col2 = st.selectbox("Deuxième variable numérique", 
                                     [col for col in numeric_cols if col != num_col1], 
                                     key="num_col2")
            
            if st.button("Analyser la corrélation", key="analyze_correlation_btn"):
                with st.spinner("Analyse en cours..."):
                    try:
                        # Création d'une figure avec plusieurs sous-graphiques
                        import plotly.subplots as sp
                        from plotly import graph_objects as go
                        import numpy as np
                        
                        # Création de la figure avec 2x2 sous-graphiques
                        fig = sp.make_subplots(
                            rows=2, cols=2,
                            subplot_titles=(
                                f'Nuage de points {num_col1} vs {num_col2}',
                                f'Distribution de {num_col1}',
                                f'Distribution de {num_col2}',
                                'Matrice de corrélation'
                            ),
                            vertical_spacing=0.15
                        )
                        
                        # 1. Nuage de points
                        fig.add_trace(
                            go.Scatter(
                                x=st.session_state.df_clean[num_col1],
                                y=st.session_state.df_clean[num_col2],
                                mode='markers',
                                opacity=0.6,
                                name='Données',
                                showlegend=False
                            ),
                            row=1, col=1
                        )
                        
                        # 2. Distribution de la première variable
                        fig.add_trace(
                            go.Histogram(
                                x=st.session_state.df_clean[num_col1],
                                name=num_col1,
                                showlegend=False
                            ),
                            row=1, col=2
                        )
                        
                        # 3. Distribution de la deuxième variable
                        fig.add_trace(
                            go.Histogram(
                                x=st.session_state.df_clean[num_col2],
                                name=num_col2,
                                showlegend=False
                            ),
                            row=2, col=1
                        )
                        
                        # 4. Matrice de corrélation
                        corr = st.session_state.df_clean[[num_col1, num_col2]].corr().values
                        
                        fig.add_trace(
                            go.Heatmap(
                                z=corr,
                                x=[num_col1, num_col2],
                                y=[num_col1, num_col2],
                                colorscale='Viridis',
                                showscale=True,
                                zmin=-1,
                                zmax=1
                            ),
                            row=2, col=2
                        )
                        
                        # Mise en page finale
                        fig.update_layout(
                            height=800,
                            title_text=f"Analyse de corrélation : {num_col1} vs {num_col2}",
                            margin=dict(t=100, b=50, l=50, r=50)
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Calcul des statistiques de corrélation
                        from scipy import stats
                        
                        # Corrélation de Pearson
                        pearson_corr, pearson_p = stats.pearsonr(
                            st.session_state.df_clean[num_col1].dropna(),
                            st.session_state.df_clean[num_col2].dropna()
                        )
                        
                        # Corrélation de Spearman (non linéaire)
                        spearman_corr, spearman_p = stats.spearmanr(
                            st.session_state.df_clean[num_col1].dropna(),
                            st.session_state.df_clean[num_col2].dropna()
                        )
                        
                        # Interprétation des résultats
                        interpretation = f"""
                        ## 📊 Analyse de corrélation
                        
                        ### Corrélation de Pearson (linéaire):
                        - Coefficient: {pearson_corr:.3f}
                        - P-valeur: {pearson_p:.4f}
                        
                        ### Corrélation de Spearman (monotone):
                        - Coefficient: {spearman_corr:.3f}
                        - P-valeur: {spearman_p:.4f}
                        
                        ### Interprétation :
                        """
                        
                        # Ajout d'une interprétation basée sur la force de la corrélation
                        abs_pearson = abs(pearson_corr)
                        if abs_pearson > 0.7:
                            interpretation += "Corrélation forte "
                        elif abs_pearson > 0.3:
                            interpretation += "Corrélation modérée "
                        else:
                            interpretation += "Corrélation faible "
                            
                        interpretation += f"entre {num_col1} et {num_col2}."
                        
                        if pearson_p < 0.05:
                            interpretation += " Cette relation est statistiquement significative (p < 0.05)."
                        else:
                            interpretation += " Cette relation n'est pas statistiquement significative (p ≥ 0.05)."
                        
                        st.markdown(interpretation)
                        
                        # Sauvegarde de l'analyse
                        if 'correlation_analyses' not in st.session_state:
                            st.session_state.correlation_analyses = []
                            
                        st.session_state.correlation_analyses.append({
                            'var1': num_col1,
                            'var2': num_col2,
                            'pearson_corr': pearson_corr,
                            'spearman_corr': spearman_corr,
                            'interpretation': interpretation,
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        
                        st.success("Analyse de corrélation terminée avec succès !")
                        
                    except Exception as e:
                        st.error(f"Une erreur est survenue lors de l'analyse de corrélation : {str(e)}")
                        st.exception(e)
        
        # Section pour les analyses catégorielles
        elif analysis_type == "Catégorielle vs Catégorielle" and len(cat_cols) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                cat_col1 = st.selectbox("Première variable catégorielle", cat_cols, key="cat_col1")
            with col2:
                cat_col2 = st.selectbox("Deuxième variable catégorielle", 
                                     [col for col in cat_cols if col != cat_col1], 
                                     key="cat_col2")
            
            if st.button("Analyser l'association", key="analyze_association_btn"):
                with st.spinner("Analyse en cours..."):
                    try:
                        # Création d'un tableau de contingence
                        contingency_table = pd.crosstab(
                            st.session_state.df_clean[cat_col1],
                            st.session_state.df_clean[cat_col2],
                            margins=True
                        )
                        
                        # Calcul du khi-deux
                        from scipy.stats import chi2_contingency
                        chi2, p, dof, expected = chi2_contingency(
                            pd.crosstab(st.session_state.df_clean[cat_col1], st.session_state.df_clean[cat_col2])
                        )
                        
                        # Création de la figure
                        import plotly.graph_objects as go
                        from plotly.subplots import make_subplots
                        
                        fig = make_subplots(
                            rows=2, cols=2,
                            subplot_titles=(
                                f'Tableau de contingence',
                                f'Heatmap des effectifs',
                                f'Pourcentages en ligne',
                                f'Pourcentages en colonne'
                            ),
                            specs=[[{"type": "table"}, {"type": "heatmap"}],
                                 [{"type": "heatmap"}, {"type": "heatmap"}]]
                        )
                        
                        # 1. Tableau de contingence
                        fig.add_trace(
                            go.Table(
                                header=dict(
                                    values=[cat_col1] + contingency_table.columns.tolist(),
                                    font=dict(size=10),
                                    align="left"
                                ),
                                cells=dict(
                                    values=[contingency_table.index] + [contingency_table[col] for col in contingency_table.columns],
                                    align = "left"
                                )
                            ),
                            row=1, col=1
                        )
                        
                        # 2. Heatmap des effectifs
                        fig.add_trace(
                            go.Heatmap(
                                z=contingency_table.values,
                                x=contingency_table.columns,
                                y=contingency_table.index,
                                text=contingency_table.values,
                                texttemplate="%{text}",
                                colorscale='Viridis'
                            ),
                            row=1, col=2
                        )
                        
                        # 3. Pourcentages en ligne
                        row_pct = contingency_table.div(contingency_table["All"], axis=0) * 100
                        fig.add_trace(
                            go.Heatmap(
                                z=row_pct.values,
                                x=row_pct.columns,
                                y=row_pct.index,
                                text=row_pct.round(1).astype(str) + "%",
                                texttemplate="%{text}",
                                colorscale='Blues'
                            ),
                            row=2, col=1
                        )
                        
                        # 4. Pourcentages en colonne
                        col_pct = contingency_table.div(contingency_table.loc["All"], axis=1) * 100
                        fig.add_trace(
                            go.Heatmap(
                                z=col_pct.values,
                                x=col_pct.columns,
                                y=col_pct.index,
                                text=col_pct.round(1).astype(str) + "%",
                                texttemplate="%{text}",
                                colorscale='Greens'
                            ),
                            row=2, col=2
                        )
                        
                        # Mise en page finale
                        fig.update_layout(
                            height=1000,
                            title_text=f"Analyse d'association : {cat_col1} vs {cat_col2}",
                            margin=dict(t=100, b=50, l=50, r=50)
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Interprétation des résultats
                        interpretation = f"""
                        ## 📊 Analyse d'association entre variables catégorielles
                        
                        ### Test du Khi-deux d'indépendance :
                        - Khi-deux = {chi2:.3f}
                        - Degrés de liberté = {dof}
                        - P-valeur = {p:.4f}
                        
                        ### Interprétation :
                        """
                        
                        if p < 0.05:
                            interpretation += f"Il existe une association statistiquement significative entre {cat_col1} et {cat_col2} (p < 0.05)."
                        else:
                            interpretation += f"Aucune association statistiquement significative n'a été détectée entre {cat_col1} et {cat_col2} (p ≥ 0.05)."
                        
                        st.markdown(interpretation)
                        
                        # Sauvegarde de l'analyse
                        if 'association_analyses' not in st.session_state:
                            st.session_state.association_analyses = []
                            
                        st.session_state.association_analyses.append({
                            'var1': cat_col1,
                            'var2': cat_col2,
                            'chi2': chi2,
                            'p_value': p,
                            'dof': dof,
                            'interpretation': interpretation,
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        
                        st.success("Analyse d'association terminée avec succès !")
                        
                    except Exception as e:
                        st.error(f"Une erreur est survenue lors de l'analyse d'association : {str(e)}")
                        st.exception(e)
        
        # Section pour les requêtes personnalisées avec IA
        st.markdown("---")
        st.markdown("## 🔍 Requêtes personnalisées avancées")
        
        # Informations sur les données disponibles
        st.caption(f"📊 Données disponibles : {len(st.session_state.df_clean)} lignes, {len(st.session_state.df_clean.columns)} colonnes")
        
        # Aperçu rapide des colonnes
        col1, col2 = st.columns(2)
        with col1:
            if st.button("📋 Afficher la structure des données", key="show_data_structure"):
                st.session_state.show_data_structure = not st.session_state.get('show_data_structure', False)
        
        if st.session_state.get('show_data_structure', False):
            st.dataframe(pd.DataFrame({
                'Colonne': st.session_state.df_clean.columns,
                'Type': st.session_state.df_clean.dtypes.astype(str).values,
                'Valeurs uniques': [st.session_state.df_clean[col].nunique() for col in st.session_state.df_clean.columns],
                'Valeurs manquantes': st.session_state.df_clean.isnull().sum().values
            }), use_container_width=True, height=300)
        
        # Sélection du type de requête avec des onglets
        query_type = st.radio(
            "Type de requête :",
            ["SQL", "Python"],
            horizontal=True,
            key="query_type_selector"
        )
        
        # Exemples de requêtes en fonction du contexte
        if 'context_objectif' in st.session_state and st.session_state.context_objectif:
            with st.expander("💡 Suggestions de requêtes basées sur votre contexte"):
                st.caption("Voici quelques exemples de requêtes qui pourraient être utiles :")
                if query_type == "SQL":
                    st.code("""-- Exemple 1: Aperçu des données
SELECT * FROM df LIMIT 5;

-- Exemple 2: Statistiques descriptives
SELECT 
    AVG(prix) as prix_moyen,
    MIN(prix) as prix_min,
    MAX(prix) as prix_max,
    COUNT(*) as nb_elements
FROM df;

-- Exemple 3: Regroupement et agrégation
SELECT 
    categorie,
    COUNT(*) as nb_produits,
    AVG(prix) as prix_moyen
FROM df
GROUP BY categorie
ORDER BY prix_moyen DESC;""", language='sql')
                else:
                    st.code("""# Exemple 1: Aperçu des données
df.head()

# Exemple 2: Statistiques descriptives
df.describe()

# Exemple 3: Graphique de distribution
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='prix', bins=30)
plt.title('Distribution des prix')
plt.show()""", language='python')
        
        # Saisie de la requête en langage naturel avec assistance
        natural_query = st.text_area(
            f"Décrivez en langage naturel ce que vous souhaitez faire ({query_type}):",
            placeholder=f"Ex: Afficher les 10 premières lignes avec les colonnes 'prix' et 'surface' triées par prix décroissant",
            height=100,
            value=st.session_state.get('natural_language_query', ''),
            key=f"natural_query_{query_type}",
            help="Décrivez votre besoin en langage naturel, l'IA se chargera de générer le code approprié."
        )
        
        # Vérifier si on doit déclencher une exécution automatique
        auto_execute = st.session_state.pop('auto_execute_analysis', False)
        
        # Options avancées
        with st.expander("⚙️ Options avancées"):
            st.checkbox(
                "Afficher les explications du code généré",
                value=st.session_state.get('show_code_explanations', True),
                key='show_code_explanations',
                help="Affiche des explications détaillées sur le code généré"
            )
            
            st.checkbox(
                "Exécuter automatiquement après génération",
                value=st.session_state.get('auto_execute_code', False),
                key='auto_execute_code',
                help="Exécute automatiquement le code après sa génération"
            )
        
        # Boutons d'action
        col1, col2 = st.columns([1, 3])
        with col1:
            generate_btn = st.button("✨ Générer le code", 
                                   key=f"generate_{query_type}_btn",
                                   use_container_width=True)
        
        # Bouton pour effacer
        with col2:
            if st.button("🗑️ Effacer", 
                        key=f"clear_query_btn",
                        use_container_width=True):
                st.session_state.pop('generated_code', None)
                st.session_state.pop('last_execution', None)
                st.rerun()
        
        # Génération du code
        if generate_btn:
            if not natural_query.strip():
                st.warning("Veuillez décrire ce que vous souhaitez faire avant de générer le code.")
            else:
                with st.spinner("🧠 Génération du code en cours..."):
                    try:
                        # Génération du code à partir du langage naturel
                        df_columns = st.session_state.df_clean.columns.tolist()
                        
                        # Ajout du contexte utilisateur pour améliorer la pertinence
                        context_info = ""
                        if 'context_objectif' in st.session_state and st.session_state.context_objectif:
                            context_info = f"\nContexte du projet : {st.session_state.context_objectif}\n"
                        
                        # Génération du code avec le contexte
                        generated_code = generate_code_from_natural_language(
                            query=f"{context_info}\n{natural_query}",
                            query_type=query_type.lower(),
                            df_columns=df_columns
                        )
                        
                        # Détection du type d'analyse
                        analysis_type = detect_analysis_type(natural_query)
                        
                        # Mise à jour de l'interface avec le code généré
                        st.session_state.generated_code = generated_code
                        st.session_state.show_generated_code = True
                        st.session_state.code_type = query_type.lower()
                        st.session_state.current_analysis_type = analysis_type
                        
                        # Exécution automatique si activée ou si déclenchée par une suggestion
                        if st.session_state.get('auto_execute_code', False) or auto_execute:
                            st.session_state.execute_generated_code = True
                            
                            # Pour les analyses de série temporelle, on active automatiquement l'onglet
                            if analysis_type == 'time_series':
                                st.session_state.selected_analysis = 'time_series'
                        
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la génération du code : {str(e)}")
                        st.exception(e)  # Affiche plus de détails sur l'erreur
        
        # Affichage du code généré et options d'exécution
        if st.session_state.get('show_generated_code', False) and st.session_state.generated_code:
            st.markdown("---")
            st.markdown("#### Code généré")
            st.code(st.session_state.generated_code, language=st.session_state.get('code_type', 'python'))
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("🔄 Exécuter le code", key="execute_generated_code_btn"):
                    try:
                        # Exécution du code généré
                        success, message, result = execute_code(
                            code=st.session_state.generated_code,
                            code_type=st.session_state.code_type,
                            df=st.session_state.df_clean
                        )
                        
                        if success:
                            st.session_state.last_execution = {
                                'success': True,
                                'message': message,
                                'result': result,
                                'code': st.session_state.generated_code,
                                'code_type': st.session_state.code_type,
                                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            }
                            st.success(message)
                            
                            # Affichage du résultat
                            if result is not None:
                                if isinstance(result, pd.DataFrame):
                                    st.dataframe(result)
                                    
                                    # Bouton d'export
                                    csv = result.to_csv(index=False).encode('utf-8')
                                    st.download_button(
                                        label="💾 Exporter les résultats (CSV)",
                                        data=csv,
                                        file_name=f"resultat_requete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        mime="text/csv"
                                    )
                                else:
                                    st.write(result)
                        else:
                            st.error(f"Erreur lors de l'exécution : {message}")
                            
                    except Exception as e:
                        st.error(f"Erreur lors de l'exécution du code : {str(e)}")
            
            with col2:
                if st.button("✏️ Modifier le code", key="edit_code_btn"):
                    st.session_state.editing_code = not st.session_state.get('editing_code', False)
                    st.rerun()
            
            # Section d'édition manuelle du code
            if st.session_state.get('editing_code', False):
                edited_code = st.text_area(
                    "Modifiez le code si nécessaire :",
                    value=st.session_state.generated_code,
                    height=200,
                    key="code_editor"
                )
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("💾 Enregistrer et exécuter", key="save_execute_btn", type="primary"):
                        st.session_state.generated_code = edited_code
                        st.session_state.editing_code = False
                        st.session_state.execute_generated_code = True
                        st.rerun()
                    
                    if st.button("💾 Enregistrer seulement", key="save_code_btn"):
                        st.session_state.generated_code = edited_code
                        st.session_state.editing_code = False
                        st.rerun()
                
                with col2:
                    if st.button("❌ Annuler", key="cancel_edit_btn"):
                        st.session_state.editing_code = False
                        st.rerun()
                
                st.markdown("---")
            
            # Affichage des résultats de l'exécution
            if st.session_state.get('last_execution') and st.session_state.last_execution.get('success'):
                st.markdown("### 📊 Résultats de l'analyse")
                
                # Affichage des résultats en fonction du type d'analyse
                if st.session_state.get('current_analysis_type') == 'time_series':
                    st.success("Analyse des séries temporelles terminée avec succès!")
                    
                    # Ajout d'un bouton pour voir les détails de l'analyse
                    if st.button("📈 Voir l'analyse détaillée", key="view_time_series_btn"):
                        st.session_state.selected_analysis = 'time_series'
                        st.rerun()
                
                # Affichage générique des résultats
                elif 'result' in st.session_state.last_execution and st.session_state.last_execution['result'] is not None:
                    result = st.session_state.last_execution['result']
                    if isinstance(result, pd.DataFrame):
                        st.dataframe(result)
                        
                        # Bouton d'export CSV
                        csv = result.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="💾 Exporter les résultats (CSV)",
                            data=csv,
                            file_name=f"resultat_analyse_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.write(result)
        
        # Affichage des résultats de la dernière exécution
        if 'last_execution' in st.session_state and st.session_state.last_execution:
            st.markdown("---")
            st.markdown("### 📜 Dernière exécution")
            exec_data = st.session_state.last_execution
            st.caption(f"Exécuté le {exec_data['timestamp']}")
            st.code(exec_data['code'], language=exec_data['code_type'])
            
            if exec_data['success'] and exec_data['result'] is not None:
                if isinstance(exec_data['result'], pd.DataFrame):
                    st.dataframe(exec_data['result'].head())
                    st.caption(f"Aperçu des données ({len(exec_data['result'])} lignes au total)")
                else:
                    st.write(exec_data['result'])
            
            if not exec_data['success']:
                st.error(exec_data['message'])
        
        # Section pour les requêtes manuelles (SQL et Python)
        with st.expander("🔧 Requêtes manuelles", expanded=False):
            st.markdown("### Exécuter des requêtes manuelles")
            
            # Onglets pour SQL et Python
            sql_tab, python_tab = st.tabs(["🔷 SQL", "🐍 Python"])

            with sql_tab:
                st.markdown("#### Requête SQL")
                st.info("Utilisez 'df' comme nom de table dans vos requêtes SQL.")
                sql_query = st.text_area(
                    "Entrez votre requête SQL :",
                    height=150,
                    key="sql_query_input"
                )

                if st.button("Exécuter la requête SQL", key="run_sql_btn"):
                    try:
                        result = sqldf(sql_query, {'df': st.session_state.df_clean})
                        st.session_state.sql_queries[sql_query] = result
                        st.success(f"Requête exécutée avec succès. {len(result)} lignes retournées.")

                        # Afficher les résultats
                        st.dataframe(result)


                        # Bouton pour sauvegarder les résultats
                        csv = result.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="💾 Exporter les résultats (CSV)",
                            data=csv,
                            file_name=f"resultat_requete_{len(st.session_state.sql_queries)}.csv",
                            mime="text/csv"
                        )

                    except Exception as e:
                        st.error(f"Erreur lors de l'exécution de la requête : {str(e)}")

            with python_tab:
                st.markdown("#### Code Python")
                st.info("Utilisez 'df' pour accéder à votre DataFrame. Stockez le résultat dans 'result'.")
                python_code = st.text_area(
                    "Entrez votre code Python :",
                    height=200,
                    key="python_code_input"
                )

                if st.button("Exécuter le code Python", key="run_python_btn"):
                    try:
                        # Exécution sécurisée du code
                        success, message, result = execute_code(
                            code=python_code,
                            code_type='python',
                            df=st.session_state.df_clean
                        )
                        
                        if success:
                            st.session_state.python_queries[python_code] = result
                            st.success(message)
                            
                            # Afficher le résultat
                            if result is not None:
                                if isinstance(result, pd.DataFrame):
                                    st.dataframe(result)
                                    
                                    # Bouton pour sauvegarder les résultats
                                    csv = result.to_csv(index=False).encode('utf-8')
                                    st.download_button(
                                        label="💾 Exporter les résultats (CSV)",
                                        data=csv,
                                        file_name=f"resultat_python_{len(st.session_state.python_queries)}.csv",
                                        mime="text/csv"
                                    )
                                else:
                                    st.write(result)
                        else:
                            st.error(message)

                    except Exception as e:
                        st.error(f"Erreur lors de l'exécution du code : {str(e)}")

        # Section pour la génération du rapport
        with st.expander("📑 Génération du rapport", expanded=False):
            st.markdown("### Options du rapport")

            col1, col2 = st.columns(2)

            with col1:
                # Options d'export
                export_format = st.selectbox(
                    "Format du rapport",
                    ["HTML", "PDF", "Excel"],
                    index=0,
                    key="export_format"
                )

                # Options d'inclusion
                st.markdown("**Éléments à inclure :**")
                include_summary = st.checkbox("Résumé exécutif", value=True, key="include_summary")
                include_descriptive = st.checkbox("Statistiques descriptives", value=True, key="include_descriptive")
                include_correlations = st.checkbox("Matrice de corrélation", value=True, key="include_correlations")
                include_queries = st.checkbox("Requêtes personnalisées", value=True, key="include_queries")
                include_advanced = st.checkbox("Analyses avancées", value=True, key="include_advanced")

            with col2:
                # Options de personnalisation
                st.markdown("**Personnalisation :**")

                primary_color = st.color_picker(
                    "Couleur principale",
                    "#4e73df",
                    key="report_primary_color"
                )

                secondary_color = st.color_picker(
                    "Couleur secondaire",
                    "#858796",
                    key="report_secondary_color"
                )

                font_family = st.selectbox(
                    "Police de caractères",
                    ["Arial, sans-serif", "Times New Roman, serif", "Courier New, monospace", "Georgia, serif"],
                    index=0,
                    key="report_font_family"
                )

                include_raw_data = st.checkbox(
                    "Inclure les données brutes",
                    value=st.session_state.get('include_raw_data', True),
                    key="include_raw_data"
                )

            if st.button("", key="generate_full_report_btn"):
                with st.spinner("Préparation du rapport..."):
                    try:
                        # Vérifier que df_clean est disponible et non vide
                        if 'df_clean' not in st.session_state or st.session_state.df_clean is None:
                            raise ValueError("Aucune donnée nettoyée disponible. Veuillez d'abord charger et nettoyer vos données.")
                            
                        if st.session_state.df_clean.empty:
                            raise ValueError("Le jeu de données nettoyé est vide. Veuillez vérifier vos données d'entrée.")
                        
                        # Préparer les données pour le rapport
                        try:
                            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
                            categorical_cols = st.session_state.df_clean.select_dtypes(
                                include=['object', 'category', 'bool']
                            ).columns.tolist()
                            
                            report_data = {
                                'metadata': {
                                    'title': 'Rapport d\'analyse avancée',
                                    'author': AUTHOR_INFO['name'],
                                    'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                    'dataset_info': {
                                        'shape': st.session_state.df_clean.shape,
                                        'columns': st.session_state.df_clean.columns.tolist(),
                                        'numeric_columns': numeric_cols,
                                        'categorical_columns': categorical_cols
                                    }
                                },
                                'sections': {
                                    'summary': include_summary,
                                    'descriptive_stats': include_descriptive,
                                    'correlation_matrix': include_correlations and len(numeric_cols) > 1,
                                    'custom_queries': include_queries and bool(st.session_state.get('custom_queries')),
                                    'advanced_analyses': include_advanced
                                },
                                'style': {
                                    'primary_color': primary_color,
                                    'secondary_color': secondary_color,
                                    'font_family': font_family
                                },
                                'include_raw_data': include_raw_data,
                                # Ajout explicite des données nécessaires pour le rapport
                                'df_clean': st.session_state.df_clean,
                                'context': {
                                    'description': st.session_state.get('analysis_context', 'Aucun contexte fourni'),
                                    'objectives': st.session_state.get('analysis_objectives', 'Non définis'),
                                    'suggested_queries': st.session_state.get('suggested_queries', [])
                                }
                            }
                            
                        except Exception as e:
                            st.error(f"Erreur lors de la préparation des données du rapport: {str(e)}")
                            st.stop()

                        # Créer le répertoire des rapports s'il n'existe pas
                        base_reports_dir = Path("D:/Dev/Analyser/reports")
                        base_reports_dir.mkdir(parents=True, exist_ok=True)

                        # Nom de base du fichier
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        base_filename = f"rapport_analyse_avancee_{timestamp}"
                        output_path = str(base_reports_dir / base_filename)

                        # Exporter le rapport
                        export_path = export_report(
                            report_data=report_data,
                            output_path=output_path,
                            fmt=export_format.lower(),
                            style_options={
                                'primary_color': primary_color,
                                'secondary_color': secondary_color,
                                'font_family': font_family.split(',')[0],
                                'author_info': AUTHOR_INFO
                            }
                        )

                        # Stocker les données du rapport pour le téléchargement
                        with open(export_path, 'rb') as f:
                            st.session_state.report_data = f.read()

                        st.success("Rapport généré avec succès !")

                        # Afficher le bouton de téléchargement
                        st.download_button(
                            label="📥 Télécharger le rapport",
                            data=st.session_state.report_data,
                            file_name=f"{base_filename}.{export_format.lower()}",
                            mime="application/octet-stream"
                        )

                    except Exception as e:
                        st.error(f"Erreur lors de la génération du rapport : {str(e)}")
                        st.exception(e)

        # Section d'interprétation globale
        with st.expander("📊 Interprétation globale de l'analyse", expanded=True):
            st.markdown("### Synthèse des résultats")
            
            if st.button("🔄 Générer l'interprétation globale"):
                with st.spinner("Génération de l'interprétation globale en cours..."):
                    interpretation = generate_global_interpretation()
                    st.session_state.global_interpretation = interpretation
            
            if 'global_interpretation' in st.session_state:
                st.markdown(st.session_state.global_interpretation)
            else:
                st.info("Cliquez sur le bouton pour générer une interprétation globale des analyses.")
                st.markdown("#### Types d'analyses à effectuer")
                analysis_types = st.multiselect(
                    "Sélectionnez les types d'analyses à effectuer",
                    ["Statistiques descriptives", "Corrélations", "Clustering", "Analyse temporelle",
                     "Analyse de tendances", "Modélisation prédictive"],
                    default=["Statistiques descriptives", "Corrélations"],
                    key="global_analysis_types"
                )

        # Boutons de navigation
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("← Retour au nettoyage", use_container_width=True):
                st.session_state.step = 2
                st.rerun()
        with col2:
            if st.button("Réinitialiser l'analyse", use_container_width=True):
                st.session_state.df_clean = st.session_state.df_raw.copy()
                st.session_state.step = 3
                st.rerun()
        with col3:
            if st.button("Passer à l'étape suivante →", type="primary", use_container_width=True):
                st.session_state.step = 4
                st.rerun()

def generate_automated_conclusion():
    """
    Génère automatiquement une conclusion basée sur les analyses disponibles dans la session.
    
    Returns:
        str: Une chaîne formatée en markdown contenant la conclusion générée
    """
    conclusion = "### Synthèse des principaux résultats\n\n"
    
    # Récupérer les métriques de base si disponibles
    if hasattr(st.session_state, 'df_clean') and st.session_state.df_clean is not None:
        df = st.session_state.df_clean
        nb_lignes, nb_colonnes = df.shape
        
        # Ajouter des informations sur le jeu de données
        conclusion += f"- L'analyse a porté sur un jeu de données de **{nb_lignes} lignes** et **{nb_colonnes} colonnes**\n"
        
        # Ajouter des informations sur les types de données
        types_donnees = df.dtypes.value_counts().to_dict()
        type_desc = ", ".join([f"{v} {k}" for k, v in types_donnees.items()])
        conclusion += f"- Types de données : {type_desc}\n"
    
    # Ajouter des informations sur les analyses spécifiques si disponibles
    if hasattr(st.session_state, 'saved_interpretations') and st.session_state.saved_interpretations:
        nb_analyses = len(st.session_state.saved_interpretations)
        conclusion += f"- **{nb_analyses} analyses spécifiques** ont été réalisées sur les données\n"
    
    # Section Recommandations
    conclusion += "\n### Recommandations\n\n"
    
    # Recommandations basées sur la taille des données
    if hasattr(st.session_state, 'df_clean') and st.session_state.df_clean is not None:
        df = st.session_state.df_clean
        if len(df) > 10000:
            conclusion += "- **Volume important** : L'échantillon analysé est conséquent. Pensez à mettre en place des analyses plus poussées comme des modèles prédictifs.\n"
        elif len(df) < 100:
            conclusion += "- **Échantillon limité** : Les résultats pourraient bénéficier de davantage de données pour une meilleure robustesse.\n"
    
    # Recommandations générales
    conclusion += "- **Validation continue** : Ces résultats devraient être validés sur de nouvelles données pour confirmer les tendances observées.\n"
    conclusion += "- **Approfondissement** : Certaines analyses mériteraient d'être approfondies avec des méthodes statistiques plus avancées.\n"
    
    # Section Perspectives
    conclusion += "\n### Perspectives\n\n"
    conclusion += "- **Automatisation** : Mettre en place des tableaux de bord automatisés pour suivre l'évolution des indicateurs clés.\n"
    conclusion += "- **Analyse temporelle** : Si des données temporelles sont disponibles, une analyse des tendances serait pertinente.\n"
    conclusion += "- **Segmentation** : Explorer des analyses par segments pour identifier des sous-groupes intéressants.\n"
    
    # Ajouter les informations de contact
    conclusion += "\n---\n"
    conclusion += "*Rapport généré automatiquement par Analyser IA - Développé par Sidoine YEBADOKPO*  \n"
    conclusion += "*Contact : +229 01 96 91 13 46*"
    
    return conclusion

def render_report_step():
    """Affiche l'interface du rapport final d'analyse (étape 4)."""
    
    # Style CSS personnalisé pour le rapport
    st.markdown("""
    <style>
        .main-title {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        .section-header {
            color: #2980b9;
            border-left: 4px solid #3498db;
            padding-left: 10px;
            margin-top: 30px;
        }
        .subsection {
            background-color: #f8f9fa;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
        }
        .contact-info {
            background-color: #e8f4fc;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 5px 5px 0;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # En-tête du rapport
    st.markdown("<h1 class='main-title'>📊 Rapport d'analyse complet</h1>", unsafe_allow_html=True)
    
    # Informations générales
    with st.container():
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown(f"### {st.session_state.get('project_name', 'Analyse sans titre')}")
            st.caption(f"Généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}")
        with col2:
            st.caption(f"**Auteur:** {AUTHOR_INFO['name']}")
            st.caption(f"**Version:** {VERSION}")
    
    # 1. Introduction et présentation du contexte
    st.markdown("## 1. Introduction et contexte de l'analyse")
    with st.expander("📋 Contexte et objectifs", expanded=True):
        if 'project_name' in st.session_state and st.session_state.project_name:
            st.markdown(f"**Projet:** {st.session_state.project_name}")
        if 'industry' in st.session_state and st.session_state.industry:
            st.markdown(f"**Secteur d'activité:** {st.session_state.industry}")
        if 'analysis_context' in st.session_state and st.session_state.analysis_context:
            st.markdown("### Contexte")
            st.markdown(st.session_state.analysis_context)
        else:
            st.info("Aucun contexte d'analyse n'a été défini.")
            
        if 'hypotheses' in st.session_state and st.session_state.hypotheses:
            st.markdown("### Hypothèses")
            st.markdown(st.session_state.hypotheses)
            
        if 'constraints' in st.session_state and st.session_state.constraints:
            st.markdown("### Contraintes")
            st.markdown(st.session_state.constraints)
    
    # 2. Vue d'ensemble des données
    st.markdown("## 2. Vue d'ensemble des données")
    with st.expander("📊 Aperçu des données", expanded=True):
        st.dataframe(st.session_state.df_clean.head(10), use_container_width=True)
        st.caption(f"Dimensions des données : {st.session_state.df_clean.shape[0]:,} lignes x {st.session_state.df_clean.shape[1]:,} colonnes".replace(",", " "))
        
        # Statistiques rapides
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            st.markdown("### Statistiques descriptives")
            st.dataframe(st.session_state.df_clean[numeric_cols].describe().T, use_container_width=True)
    
    # 3. Méthodologie d'analyse
    st.markdown("## 3. Méthodologie d'analyse")
    with st.expander("🔍 Détails de la méthodologie", expanded=False):
        st.markdown("""
        L'analyse a été réalisée selon la méthodologie suivante :
        
        ### 1. Préparation des données
        - Nettoyage des valeurs manquantes et des doublons
        - Détection et traitement des valeurs aberrantes
        - Conversion des types de données appropriés
        
        ### 2. Analyse exploratoire
        - Statistiques descriptives
        - Visualisation des distributions
        - Identification des corrélations
        
        ### 3. Analyse approfondie
        - Tests statistiques
        - Modélisation (si applicable)
        - Validation des hypothèses
        
        ### 4. Interprétation
        - Synthèse des résultats
        - Mise en perspective avec le contexte métier
        - Recommandations actionnables
        """)
    
    # 4. Résultats détaillés
    st.markdown("## 4. Résultats détaillés")
    
    # 4.1. Interprétation globale
    with st.expander("📈 Synthèse des résultats", expanded=True):
        if hasattr(st.session_state, 'global_interpretation'):
            st.markdown(st.session_state.global_interpretation)
        else:
            interpretation = generate_global_interpretation()
            st.session_state.global_interpretation = interpretation
            st.markdown(interpretation)
    
    # 4.2. Analyses spécifiques
    if hasattr(st.session_state, 'saved_interpretations') and st.session_state.saved_interpretations:
        with st.expander("📋 Détails des analyses", expanded=False):
            for i, (title, content) in enumerate(st.session_state.saved_interpretations.items()):
                st.markdown(f"### {title}")
                st.markdown(content)
    
    # 5. Conclusion et recommandations
    st.markdown("## 5. Conclusion et recommandations")
    with st.expander("✅ Synthèse finale", expanded=True):
        if hasattr(st.session_state, 'analysis_conclusion') and st.session_state.analysis_conclusion:
            st.markdown(st.session_state.analysis_conclusion)
        else:
            conclusion = generate_automated_conclusion()
            st.session_state.analysis_conclusion = conclusion
            st.markdown(conclusion)
    
    # Section de contact
    st.markdown("## 6. Contact et informations complémentaires")
    with st.expander("📞 Nous contacter", expanded=False):
        st.markdown("""
        <div class='contact-info'>
            <h3>Contact</h3>
            <p>Pour toute question ou demande d'information complémentaire :</p>
            <p>📱 <strong>Téléphone :</strong> +33 6 12 34 56 78</p>
            <p>📧 <strong>Email :</strong> contact@sidoineyebadokpo.com</p>
            <p>🌐 <strong>Site web :</strong> <a href='https://sidoineyebadokpo.com' target='_blank'>sidoineyebadokpo.com</a></p>
        </div>
        """, unsafe_allow_html=True)
    
    # Boutons de navigation et d'export
    st.markdown("---")
    
    # Options d'export
    export_col1, export_col2 = st.columns([1, 1])
    
    with export_col1:
        export_format = st.selectbox(
            "Format d'export",
            ["PDF", "HTML", "Word"],
            key="export_format_selector"
        )
    
    with export_col2:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("📥 Télécharger le rapport", 
                    type="primary", 
                    use_container_width=True,
                    key="download_report_btn"):
            st.session_state.show_export = True
    
    # Navigation
    nav_col1, nav_col2 = st.columns([1, 1])
    with nav_col1:
        if st.button("← Retour à l'analyse", 
                    use_container_width=True,
                    key="back_to_analysis_btn"):
            st.session_state.step = 3
            st.rerun()
    with nav_col2:
        if st.button("🔄 Régénérer les analyses", 
                    use_container_width=True,
                    key="regenerate_analysis_btn"):
            if 'global_interpretation' in st.session_state:
                del st.session_state.global_interpretation
            if 'analysis_conclusion' in st.session_state:
                del st.session_state.analysis_conclusion
            st.rerun()
            st.rerun()

def generate_global_interpretation():
    """Génère une interprétation globale des analyses effectuées."""
    if not hasattr(st.session_state, 'analysis_metrics'):
        return "Aucune donnée d'analyse disponible pour générer une interprétation."
    
    try:
        # Préparer le contexte pour l'interprétation globale
        context = "Résumé global de l'analyse des données"
        
        # Ajouter le contexte utilisateur s'il existe
        if 'analysis_context' in st.session_state and st.session_state.analysis_context:
            context += f"\n\nContexte fourni par l'utilisateur: {st.session_state.analysis_context}"
        
        # Préparer la description des données
        data_desc = "## Métriques d'analyse collectées\n\n"
        
        # Ajouter les métriques numériques
        if hasattr(st.session_state, 'analysis_metrics') and st.session_state.analysis_metrics:
            data_desc += "### Variables numériques\n"
            for var, metrics in st.session_state.analysis_metrics.items():
                data_desc += f"- **{var}**: "
                data_desc += f"{metrics['valeurs_uniques']} valeurs uniques, "
                data_desc += f"{metrics['valeurs_manquantes']} valeurs manquantes"
                if metrics['moyenne'] is not None:
                    data_desc += f", moyenne: {metrics['moyenne']:.2f}, "
                    data_desc += f"écart-type: {metrics['ecart_type']:.2f}"
                data_desc += "\n"
        
        # Ajouter les métriques catégorielles
        if hasattr(st.session_state, 'categorical_metrics') and st.session_state.categorical_metrics:
            data_desc += "\n### Variables catégorielles\n"
            for var, metrics in st.session_state.categorical_metrics.items():
                data_desc += (
                    f"- **{var}**: {metrics['nb_categories']} catégories, "
                    f"la plus fréquente est '{metrics['categorie_principale']}' "
                    f"({metrics['freq_categorie_principale']}/{metrics['total']} soit "
                    f"{metrics['freq_categorie_principale']/metrics['total']*100:.1f}%)\n"
                )
        
        # Ajouter les informations de corrélation
        if hasattr(st.session_state, 'correlation_metrics') and st.session_state.correlation_metrics:
            nb_vars = st.session_state.correlation_metrics['nb_variables']
            if nb_vars > 1:
                data_desc += f"\n### Analyse des corrélations\n"
                data_desc += f"{nb_vars} variables numériques analysées pour les corrélations.\n"
        
        # Générer l'interprétation avec l'IA
        interpretation = generate_ai_interpretation(
            context=context,
            data_description=data_desc,
            chart_type="global_analysis"
        )
        
        return interpretation if interpretation else "Impossible de générer une interprétation pour le moment."
    
    except Exception as e:
        st.error(f"Erreur lors de la génération de l'interprétation globale: {str(e)}")
        return f"Erreur lors de la génération de l'interprétation: {str(e)}"

# Section pour l'export final
with st.expander("📤 Export final", expanded=False):
    st.markdown("### Options d'export final")

    export_options = st.multiselect(
        "Sélectionnez les éléments à exporter",
        ["Données nettoyées", "Rapport complet", "Code des analyses", "Visualisations"],
        default=["Données nettoyées", "Rapport complet"]
    )

    export_format = st.selectbox(
        "Format d'export",
        ["ZIP (tous les formats)", "CSV", "Excel", "HTML", "PDF"],
        index=0
    )

    if st.button("Exporter les résultats", type="primary"):
        with st.spinner("Préparation de l'export..."):
            try:
                # Créer le répertoire d'export avec horodatage
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                export_dir = REPORTS_DIR / f"export_analyse_{timestamp}"
                export_dir.mkdir(parents=True, exist_ok=True)

                # Informations de contact
                author_info = {
                    'name': 'Sidoine YEBADOKPO',
                    'title': 'Data Analyst/Scientist Freelance',
                    'phone': '+229 01 96 91 13 46',
                    'email': 'yebadokposidoine2000@gmail.com',
                    'website': 'www.sidoine-yebadokpo.com'
                }

                # Exporter les données nettoyées
                if "Données nettoyées" in export_options:
                    csv_path = export_dir / "donnees_nettoyees.csv"
                    st.session_state.df_clean.to_csv(csv_path, index=False)
                    excel_path = export_dir / "donnees_nettoyees.xlsx"
                    st.session_state.df_clean.to_excel(excel_path, index=False)

                # Exporter le rapport
                if "Rapport complet" in export_options:
                    report_data = {
                        'metadata': {
                            'title': "Rapport d'analyse complet",
                            'author': author_info['name'],
                            'contact': author_info['phone'],
                            'email': author_info['email'],
                            'website': author_info['website'],
                            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        },
                        'context': st.session_state.get('analysis_context', ''),
                        'objectives': st.session_state.get('analysis_objectives', ''),
                        'df_clean': st.session_state.df_clean,
                        'analysis_results': st.session_state.get('analysis_results', {}),
                        'preprocessing_steps': st.session_state.get('preprocessing_steps', []),
                        'custom_queries': {
                            'sql': st.session_state.get('sql_queries', []),
                            'python': st.session_state.get('python_queries', [])
                        },
                        'author_info': author_info
                    }

                    # Générer le rapport HTML
                    html_path = export_dir / "rapport_complet.html"
                    try:
                        export_report(report_data, str(html_path), fmt='html')
                        st.success(f"Rapport HTML généré avec succès : {html_path}")
                    except Exception as e:
                        st.error(f"Erreur lors de la génération du rapport HTML : {str(e)}")

                    # Générer le rapport PDF si disponible
                    if _PDF_AVAILABLE:
                        pdf_path = export_dir / "rapport_complet.pdf"
                        try:
                            export_report(report_data, str(pdf_path), fmt='pdf')
                            st.success(f"Rapport PDF généré avec succès : {pdf_path}")
                        except Exception as e:
                            st.warning(f"Impossible de générer le PDF : {str(e)}")

                # Exporter le code
                if "Code des analyses" in export_options:
                    code_path = export_dir / "code_analyses.py"
                    with open(code_path, 'w', encoding='utf-8') as f:
                        f.write("# Code généré par Analyser IA\n")
                        f.write("# Développé par Sidoine YEBADOKPO\n")
                        f.write("# Contact: +229 01 96 91 13 46\n")
                        f.write("# Date: " + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + "\n\n")
                        
                        # Ajouter les requêtes SQL
                        if st.session_state.get('sql_queries'):
                            f.write("# Requêtes SQL exécutées\n")
                            for query in st.session_state.sql_queries:
                                f.write(f"# {query}\n")
                                f.write(f"result = sqldf(\"\"\"{query}\"\"\", {{'df': df}})\n\n")

                        # Ajouter les requêtes Python
                        if st.session_state.get('python_queries'):
                            f.write("# Code Python exécuté\n")
                            for code in st.session_state.python_queries:
                                    f.write(f"# {code}\n")
                                    f.write(f"{code}\n\n")

                    # Exporter les visualisations
                    if "Visualisations" in export_options:
                        try:
                            viz_dir = export_dir / "visualisations"
                            viz_dir.mkdir(exist_ok=True)
                            
                            # Exporter quelques visualisations de base
                            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns
                            
                            if len(numeric_cols) > 0:
                                # Créer un histogramme pour chaque colonne numérique (max 3)
                                for col in numeric_cols[:3]:
                                    try:
                                        import plotly.express as px
                                        fig = px.histogram(
                                            st.session_state.df_clean, 
                                            x=col, 
                                            title=f'Distribution de {col}',
                                            labels={col: 'Valeurs'},
                                            width=800,
                                            height=500
                                        )
                                        fig_path = viz_dir / f"histogram_{col}.png"
                                        fig.write_image(str(fig_path))
                                    except Exception as e:
                                        st.warning(f"Impossible d'exporter la visualisation pour {col}: {str(e)}")
                            else:
                                st.warning("Aucune colonne numérique trouvée pour générer des visualisations.")
                        except Exception as e:
                            st.warning(f"Erreur lors de la création des visualisations: {str(e)}")

                # Créer une archive ZIP si nécessaire
                if export_format == "ZIP (tous les formats)":
                    shutil.make_archive(str(export_dir), 'zip', export_dir)
                    export_path = f"{str(export_dir)}.zip"
                    mime_type = "application/zip"
                else:
                    # Trouver le fichier correspondant au format demandé
                    if export_format == "CSV" and "Données nettoyées" in export_options:
                        file_path = csv_path
                        mime_type = "text/csv"
                    elif export_format == "Excel" and "Données nettoyées" in export_options:
                        file_path = excel_path
                        mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    elif export_format == "HTML" and "Rapport complet" in export_options:
                        file_path = html_path
                        mime_type = "text/html"
                    elif export_format == "PDF" and "Rapport complet" in export_options:
                        file_path = pdf_path
                        mime_type = "application/pdf"
                    else:
                        # Par défaut, créer une archive ZIP
                        shutil.make_archive(str(export_dir), 'zip', export_dir)
                        export_path = f"{str(export_dir)}.zip"
                        mime_type = "application/zip"

                # Télécharger le fichier
                if export_format == "ZIP (tous les formats)":
                    with open(export_path, "rb") as f:
                        st.download_button(
                            label="Télécharger l'archive ZIP",
                            data=f,
                            file_name=f"export_analyse_{timestamp}.zip",
                            mime=mime_type
                        )
                else:
                    with open(file_path, "rb") as f:
                        st.download_button(
                            label=f"Télécharger le fichier {export_format}",
                            data=f,
                            file_name=file_path.name,
                            mime=mime_type
                        )

                st.success("Export terminé avec succès !")

            except Exception as e:
                st.error(f"Erreur lors de l'export: {str(e)}")
                st.exception(e)

# Boutons de navigation
col1, col2 = st.columns([1, 1])
with col1:
    if st.button("← Retour à l'analyse", use_container_width=True):
        st.session_state.step = 3
        st.rerun()
with col2:
    if st.button("Générer le rapport final →", type="primary", use_container_width=True):
        st.session_state.step = 4
        st.rerun()

# ============================================
# 5. Point d'entrée principal
# ============================================

@st.cache_resource(ttl=3600)
def load_assets():
    """Charge les ressources statiques (modèles, données de référence, etc.)."""
    # Cette fonction est mise en cache pour éviter de recharger les ressources à chaque interaction
    assets = {
        'example_datasets': {
            'iris': px.data.iris(),
            'tips': px.data.tips(),
            'gapminder': px.data.gapminder(),
        },
        'templates': {
            'analysis': {
                'exploratoire': """# Analyse exploratoire des données

## 1. Aperçu des données

### Dimensions
- Nombre d'observations : {n_rows}
- Nombre de variables : {n_cols}

### Types de données
{data_types}

## 2. Statistiques descriptives

### Variables numériques
{num_stats}

### Variables catégorielles
{cat_stats}
"""
            }
        }
    }
    return assets

def log_interaction(action: str, details: dict = None):
    """Enregistre une interaction utilisateur pour l'analyse d'usage."""
    if details is None:
        details = {}
    
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'step': st.session_state.step,
        'action': action,
        'details': details,
        'session_duration': (datetime.now() - st.session_state.app_start_time).total_seconds()
    }
    
    # En production, on enverrait ces données à un service d'analyse
    if st.secrets.get("ENV") == "production":
        pass  # Intégration avec un service d'analyse

def handle_errors(func: Callable) -> Callable:
    """Décorateur pour gérer les erreurs de manière élégante."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            error_details = {
                'error': str(e),
                'type': type(e).__name__,
                'traceback': traceback.format_exc()
            }
            log_interaction('error', error_details)
            error_message("Une erreur est survenue lors de l'exécution.")
            st.error("Détails techniques : " + str(e))
            if st.checkbox("Afficher les détails de l'erreur"):
                st.code(traceback.format_exc())
    return wrapper

def main():
    """Point d'entrée principal de l'application."""
    try:
        # Initialisation
        init_session_state()
        
        # Mise à jour de la dernière interaction
        st.session_state.last_interaction = datetime.now()
        
        # Chargement des ressources
        assets = load_assets()
        
        # Barre latérale
        render_sidebar()
        
        # Affichage des notifications
        if 'notifications' in st.session_state and st.session_state.notifications:
            for notification in st.session_state.notifications:
                if notification['type'] == 'success':
                    success_message(notification['message'])
                elif notification['type'] == 'error':
                    error_message(notification['message'])
                elif notification['type'] == 'warning':
                    warning_message(notification['message'])
            st.session_state.notifications = []
        
        # Gestion des étapes
        with st.spinner(f"Chargement de l'étape {st.session_state.step + 1}..."):
            if st.session_state.step == 0:
                render_context_step()
            elif st.session_state.step == 1:
                render_loading_step()
            elif st.session_state.step == 2:
                render_cleaning_step()
            elif st.session_state.step == 3:
                render_analysis_step()
            elif st.session_state.step == 4:
                render_report_step()
    except Exception as e:
        st.error(f"Une erreur inattendue s'est produite : {str(e)}")
        st.exception(e)
    finally:
        # Nettoyage des ressources si nécessaire
        pass



def generate_goal_based_suggestions(goals_text, numeric_cols, cat_cols, date_cols, max_suggestions=3):
    """
    Génère des suggestions d'analyse basées sur les objectifs de l'utilisateur.
    
    Args:
        goals_text: Texte des objectifs d'analyse de l'utilisateur
        numeric_cols: Liste des colonnes numériques
        cat_cols: Liste des colonnes catégorielles
        date_cols: Liste des colonnes de date
        max_suggestions: Nombre maximum de suggestions à générer
        
    Returns:
        list: Liste de suggestions basées sur les objectifs
    """
    if not goals_text:
        return []
        
    goals_text = goals_text.lower()
    suggestions = []
    
    # Détection des mots-clés dans les objectifs
    if any(word in goals_text for word in ['tendance', 'évolution', 'prévoir', 'prédire', 'futur']):
        if date_cols and numeric_cols:
            date_var = date_cols[0]
            num_var = next((col for col in numeric_cols if col != date_var), numeric_cols[0])
            suggestions.append({
                'title': f'📈 Prévision de {num_var}',
                'description': f'Prévision de {num_var} avec un modèle de série temporelle',
                'query': f'Crée une prévision de {num_var} pour les 12 prochaines périodes en utilisant un modèle de série temporelle',
                'code_type': 'Python',
                'priority': 2
            })
    
    if any(word in goals_text for word in ['groupe', 'segment', 'cluster', 'regrouper']):
        if len(numeric_cols) >= 2:
            suggestions.append({
                'title': '🔍 Analyse des segments',
                'description': 'Regroupement des données en segments homogènes',
                'query': 'Effectue une analyse de clustering pour identifier des segments dans les données',
                'code_type': 'Python',
                'priority': 2
            })
    
    if any(word in goals_text for word in ['anomalie', 'erreur', 'incohérence', 'anormal']):
        if numeric_cols:
            num_var = numeric_cols[0]
            suggestions.append({
                'title': f'⚠️ Détection des anomalies dans {num_var}',
                'description': f'Identification des valeurs aberrantes dans {num_var}',
                'query': f'Détecte et affiche les valeurs aberrantes dans la colonne {num_var} en utilisant la méthode IQR',
                'code_type': 'Python',
                'priority': 2
            })
    
    if any(word in goals_text for word in ['comparer', 'différence', 'contraste']):
        if cat_cols and numeric_cols:
            cat_var = cat_cols[0]
            num_var = next((col for col in numeric_cols if col != cat_var), numeric_cols[0])
            suggestions.append({
                'title': f'🔄 Comparaison de {num_var} par {cat_var}',
                'description': f'Comparaison statistique de {num_var} entre les groupes de {cat_var}',
                'query': f'Compare la distribution de {num_var} entre les différentes catégories de {cat_var} avec un test statistique',
                'code_type': 'Python',
                'priority': 1
            })
    
    # Trier par priorité et limiter le nombre de suggestions
    suggestions.sort(key=lambda x: -x.get('priority', 0))
    return suggestions[:max_suggestions]


def generate_analysis_suggestions(numeric_cols, cat_cols, date_cols, max_suggestions=6):
    """
    Génère des suggestions d'analyse basées sur les variables disponibles et le contexte utilisateur.
    
    Args:
        numeric_cols: Liste des colonnes numériques
        cat_cols: Liste des colonnes catégorielles
        date_cols: Liste des colonnes de date
        max_suggestions: Nombre maximum de suggestions à générer
        
    Returns:
        list: Liste de dictionnaires contenant les suggestions d'analyse avec titre, description,
              méthodologie et code associé
    """
    suggestions = []
    df = st.session_state.get('df_clean')
    
    # Récupérer le contexte utilisateur s'il existe
    analysis_goals = st.session_state.get('analysis_goals', '').lower()
    analysis_context = st.session_state.get('analysis_context', '').lower()
    
    # 1. Analyse de corrélation entre variables numériques (si au moins 2 variables numériques)
    if len(numeric_cols) >= 2:
        # Prendre jusqu'à 5 variables numériques pour la corrélation
        corr_vars = numeric_cols[:min(5, len(numeric_cols))]
        
        # Générer une description plus détaillée
        desc = "Analyse des relations linéaires entre variables numériques clés. "
        desc += "Permet d'identifier des patterns et des relations potentielles dans vos données."
        
        suggestions.append({
            'title': '📊 Matrice de corrélation',
            'description': desc,
            'query': f'Génère une matrice de corrélation entre les variables {", ".join(corr_vars[:3])}...',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['relation', 'corrélation', 'lien']) else 0
        })
    
    # 2. Analyse de distribution pour les variables catégorielles
    if cat_cols and numeric_cols:
        cat_var = cat_cols[0]
        num_var = next((col for col in numeric_cols if col != cat_var), numeric_cols[0])
        
        suggestions.append({
            'title': f'📦 Distribution de {num_var} par {cat_var}',
            'description': f'Analyse de la distribution de {num_var} selon les catégories de {cat_var}.',
            'query': f'Affiche un boxplot de {num_var} groupé par {cat_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['distribution', 'comparaison', 'différence']) else 0
        })
    
    # 3. Analyse temporelle si des dates sont disponibles
    if date_cols and numeric_cols:
        date_var = date_cols[0]
        value_var = next((col for col in numeric_cols if col != date_var), numeric_cols[0])
        
        suggestions.append({
            'title': f'📈 Évolution temporelle de {value_var}',
            'description': f'Analyse de l\'évolution de {value_var} dans le temps.',
            'query': f'Affiche l\'évolution de {value_var} en fonction du temps ({date_var})',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['tendance', 'évolution', 'temporel']) else 0
        })
    
    # 4. Analyse des valeurs manquantes
    missing_cols = df.isnull().sum()
    if not missing_cols.empty and missing_cols.sum() > 0:
        suggestions.append({
            'title': '🔍 Analyse des valeurs manquantes',
            'description': 'Identification et quantification des valeurs manquantes dans le jeu de données.',
            'query': 'Affiche le nombre et le pourcentage de valeurs manquantes par colonne',
            'code_type': 'Python',
            'priority': 0
        })
    
    # 5. Analyse des valeurs uniques pour les variables catégorielles
    if cat_cols:
        cat_var = cat_cols[0]
        suggestions.append({
            'title': f'🏷️ Distribution de {cat_var}',
            'description': f'Analyse de la distribution des valeurs dans la colonne {cat_var}.',
            'query': f'Affiche la distribution des valeurs uniques de {cat_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['fréquence', 'distribution', 'catégorie']) else 0
        })
    
    # 6. Analyse bivariée pour les variables numériques
    if len(numeric_cols) >= 2:
        x_var, y_var = numeric_cols[:2]
        suggestions.append({
            'title': f'🔄 Relation entre {x_var} et {y_var}',
            'description': f'Analyse de la relation entre {x_var} et {y_var} avec un nuage de points.',
            'query': f'Affiche un nuage de points de {y_var} en fonction de {x_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['relation', 'corrélation', 'lien']) else 0
        })
    
    # 7. Analyse de la distribution des variables numériques
    if numeric_cols:
        num_var = numeric_cols[0]
        suggestions.append({
            'title': f'📉 Distribution de {num_var}',
            'description': f'Analyse de la distribution de la variable numérique {num_var}.',
            'query': f'Affiche un histogramme de la distribution de {num_var}',
            'code_type': 'Python',
            'priority': 0
        })
    
    # 8. Analyse des valeurs aberrantes
    if numeric_cols:
        num_var = numeric_cols[0]
        suggestions.append({
            'title': f'⚠️ Détection des valeurs aberrantes dans {num_var}',
            'description': f'Identification des valeurs aberrantes dans la colonne {num_var}.',
            'query': f'Détecte et affiche les valeurs aberrantes dans {num_var}',
            'code_type': 'Python',
            'priority': 1 if 'aberrant' in analysis_goals or 'anomalie' in analysis_goals else 0
        })
    
    # 9. Analyse temporelle avancée (saisonnalité, tendance)
    if date_cols and numeric_cols and len(date_cols) > 0 and len(numeric_cols) > 0:
        date_var = date_cols[0]
        value_var = next((col for col in numeric_cols if col != date_var), numeric_cols[0])
        suggestions.append({
            'title': f'📅 Analyse de saisonnalité de {value_var}',
            'description': f'Analyse des motifs saisonniers pour {value_var} au fil du temps.',
            'query': f'Analyse la saisonnalité de {value_var} par mois/année',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['saison', 'tendance', 'périodicité']) else 0
        })
    
    # 10. Analyse des agrégations par catégorie
    if cat_cols and numeric_cols:
        cat_var = cat_cols[0]
        num_var = next((col for col in numeric_cols if col != cat_var), numeric_cols[0])
        suggestions.append({
            'title': f'📊 Agrégations de {num_var} par {cat_var}',
            'description': f'Calcul des statistiques agrégées de {num_var} pour chaque catégorie de {cat_var}.',
            'query': f'Calcule les statistiques (moyenne, médiane, etc.) de {num_var} groupé par {cat_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['agrégation', 'moyenne', 'comparaison']) else 0
        })
    
    # Trier les suggestions par priorité (les plus pertinentes en premier)
    suggestions.sort(key=lambda x: (-x.get('priority', 0), x['title']))
    
    # Limiter le nombre de suggestions
    return suggestions[:max_suggestions][:max_suggestions]

# ============================================
# 6. Fonctions utilitaires
# ============================================
def safe_json(obj: Any, label: str) -> None:
    """Affiche un objet JSON ou une erreur lisible si ce n'est pas un dict."""
    st.subheader(label)
    if isinstance(obj, dict):
        st.json(obj, expanded=False)
    else:
        st.error(str(obj))

def reset_analysis():
    """Réinitialise les étapes d'analyse."""
    st.session_state.df_clean = None
    st.session_state.step = 1

def detect_column_type(column_name: str, df_columns: list) -> str:
    """Détecte le type d'une colonne basé sur son nom."""
    col_lower = str(column_name).lower()
    
    # Détection des types de colonnes courants
    if any(word in col_lower for word in ['date', 'jour', 'mois', 'annee', 'year', 'month', 'day']):
        return 'date'
    elif any(word in col_lower for word in ['prix', 'montant', 'valeur', 'quantite', 'qte', 'amount', 'price', 'value', 'total', 'cout', 'coût']):
        return 'numeric'
    elif any(word in col_lower for word in ['nom', 'prenom', 'name', 'ville', 'pays', 'pays', 'adresse', 'email', 'telephone']):
        return 'text'
    elif any(word in col_lower for word in ['actif', 'valide', 'est_', 'has_', 'is_']):
        return 'boolean'
    return 'unknown'

def find_best_columns(query: str, df_columns: list, target_type: str = None) -> list:
    """Trouve les colonnes les plus pertinentes en fonction de la requête."""
    query_terms = set(query.lower().split())
    best_matches = []
    
    for col in df_columns:
        col_str = str(col).lower()
        col_terms = set(col_str.split('_'))
        
        # Vérifier le type de colonne si spécifié
        if target_type and detect_column_type(col, df_columns) != target_type:
            continue
            
        # Calculer le score de correspondance
        score = len(query_terms.intersection(col_terms))
        if score > 0:
            best_matches.append((col, score))
    
    # Trier par score décroissant
    best_matches.sort(key=lambda x: x[1], reverse=True)
    return [col for col, _ in best_matches]

def generate_sql_query(query: str, df_columns: list) -> str:
    """
    Génère une requête SQL à partir d'une description en langage naturel.
    
    Args:
        query: La description en langage naturel de la requête
        df_columns: Liste des colonnes disponibles dans le DataFrame
        
    Returns:
        str: La requête SQL générée
    """
    try:
        # Préparation du contexte pour l'API
        columns_str = "\n- " + "\n- ".join(df_columns)
        
        prompt = f"""
        Tu es un expert en SQL et en analyse de données. Ton rôle est de générer des requêtes SQL précises et optimisées
        à partir de descriptions en langage naturel. Voici les colonnes disponibles dans la table 'df':
        {columns_str}
        
        Règles importantes à suivre :
        1. Toujours utiliser des noms de colonnes exacts (respecter la casse)
        2. Utiliser des alias explicites pour les colonnes calculées
        3. Inclure des commentaires explicatifs pour les parties complexes
        4. Optimiser les requêtes pour la performance
        5. Pour les agrégations, toujours inclure un GROUP BY approprié
        6. Pour les tris, toujours spécifier l'ordre (ASC ou DESC)
        7. Utiliser des guillemets doubles pour les noms de colonnes
        8. Inclure une clause LIMIT appropriée pour les grands jeux de données
        9. Gérer correctement les valeurs NULL avec COALESCE si nécessaire
        
        Exemples de requêtes :
        - "Afficher les 10 produits les plus chers" :
          SELECT * FROM df ORDER BY "prix" DESC LIMIT 10;
          
        - "Compter le nombre de produits par catégorie" :
          SELECT "categorie", COUNT(*) AS nb_produits 
          FROM df 
          GROUP BY "categorie" 
          ORDER BY nb_produits DESC;
          
        - "Calculer la moyenne des ventes par mois" :
          SELECT 
              STRFTIME('%Y-%m', "date_vente") AS mois,
              AVG("montant") AS moyenne_ventes,
              COUNT(*) AS nb_ventes
          FROM df
          WHERE "date_vente" IS NOT NULL
          GROUP BY STRFTIME('%Y-%m', "date_vente")
          HAVING COUNT(*) > 5  -- Exclure les mois avec peu de données
          ORDER BY mois;
          
        - "Trouver les doublons" :
          SELECT "colonne1", "colonne2", COUNT(*) AS occurrences
          FROM df
          GROUP BY "colonne1", "colonne2"
          HAVING COUNT(*) > 1
          ORDER BY occurrences DESC;
        
        Requête à générer : {query}
        
        Réponds UNIQUEMENT avec la requête SQL, sans commentaires ni explications supplémentaires.
        """
        
        # Appel à l'API Gemini pour générer la requête
        response = call_gemini_api(prompt)
        
        # Nettoyage de la réponse
        if response:
            # Extraction du code SQL entre les balises ```sql ou ```
            import re
            sql_match = re.search(r'```(?:sql)?\n?(.*?)\n?```', response, re.DOTALL)
            if sql_match:
                return sql_match.group(1).strip()
            return response.strip()
        else:
            raise ValueError("Aucune réponse de l'API")
            
    except Exception as e:
        # En cas d'erreur, on retourne une requête simple mais valide
        error_msg = f"-- Erreur lors de la génération : {str(e)}\n"
        error_msg += "-- Voici une requête par défaut que vous pouvez adapter :\n"
        error_msg += "SELECT * FROM df LIMIT 10;"
        return error_msg

def generate_python_code(query: str, df_columns: list) -> str:
    """
    Génère du code Python à partir d'une description en langage naturel.
    
    Args:
        query: Description en langage naturel de la requête
        df_columns: Liste des colonnes disponibles dans le DataFrame
        
    Returns:
        str: Le code Python généré
    """
    try:
        # Préparation du contexte pour l'IA
        columns_str = "\n- " + "\n- ".join(df_columns)
        
        prompt = f"""
        Tu es un expert en analyse de données avec Python. Ton rôle est de générer du code Python
        pour analyser un DataFrame pandas à partir d'une description en langage naturel.
        
        Le DataFrame s'appelle 'df' et contient les colonnes suivantes :
        {columns_str}
        
        Règles importantes à suivre :
        1. Utiliser les bonnes pratiques de pandas pour des performances optimales
        2. Inclure des commentaires explicites
        3. Gérer les valeurs manquantes si nécessaire
        4. Utiliser des visualisations appropriées quand c'est pertinent
        5. Le résultat final doit être stocké dans une variable 'result'
        6. Toujours inclure des librairies nécessaires (pandas, matplotlib, seaborn, etc.)
        7. Utiliser des noms de variables explicites
        8. Ajouter des titres et des labels aux graphiques
        
        Exemples de requêtes :
        - "Afficher les 10 premières lignes" :
          # Afficher les 10 premières lignes du DataFrame
          result = df.head(10)
          
        - "Afficher les statistiques descriptives" :
          # Statistiques descriptives pour les colonnes numériques
          result = df.describe(include='all')
          
        - "Afficher un histogramme des prix" :
          # Importer les librairies nécessaires
          import matplotlib.pyplot as plt
          import seaborn as sns
          
          # Configuration du style des graphiques
          sns.set(style="whitegrid")
          
          # Création de la figure
          plt.figure(figsize=(12, 6))
          
          # Tracer l'histogramme
          sns.histplot(data=df, x='prix', bins=30, kde=True)
          
          # Personnalisation du graphique
          plt.title('Distribution des prix', fontsize=14, pad=20)
          plt.xlabel('Prix (en €)', fontsize=12)
          plt.ylabel('Fréquence', fontsize=12)
          
          # Afficher la grille
          plt.grid(True, linestyle='--', alpha=0.7)
          
          # Ajuster les marges
          plt.tight_layout()
          
          # Afficher le graphique
          plt.show()
          
          # Retourner les statistiques descriptives
          result = df['prix'].describe()
          
        - "Afficher la corrélation entre les variables numériques" :
          # Calcul de la matrice de corrélation
          correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()
          
          # Création d'une heatmap de corrélation
          plt.figure(figsize=(12, 10))
          sns.heatmap(correlation_matrix, 
                     annot=True, 
                     cmap='coolwarm', 
                     center=0,
                     fmt=".2f",
                     linewidths=0.5)
          plt.title('Matrice de corrélation des variables numériques', fontsize=14, pad=20)
          plt.xticks(rotation=45, ha='right')
          plt.tight_layout()
          plt.show()
          
          result = correlation_matrix
          
        Requête à traiter : {query}
        
        Réponds UNIQUEMENT avec le code Python, sans commentaires ni explications supplémentaires.
        """
        
        # Appel à l'API Gemini
        response = call_gemini_api(prompt)
        
        # Nettoyage de la réponse
        if response:
            # Extraction du code Python entre les balises ```python ou ```
            import re
            python_match = re.search(r'```(?:python)?\n?(.*?)\n?```', response, re.DOTALL)
            if python_match:
                return python_match.group(1).strip()
            return response.strip()
        else:
            raise ValueError("Aucune réponse de l'API")
            
    except Exception as e:
        # En cas d'erreur, on retourne un code minimal
        error_msg = f"""# Erreur lors de la génération du code : {str(e)}
# Voici un exemple de code que vous pouvez adapter :

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Afficher les premières lignes du DataFrame
result = df.head()
"""
        return error_msg

def generate_code_from_natural_language(query: str, query_type: str, df_columns: list) -> str:
    """
    Génère du code SQL ou Python à partir d'une description en langage naturel.
    
    Args:
        query: La description en langage naturel
        query_type: 'sql' ou 'python'
        df_columns: Liste des colonnes disponibles dans le DataFrame

    Returns:
        str: Le code généré
    """
    try:
        # Nettoyage de la requête
        query = query.strip().strip('\'"').strip()
        
        if query_type.lower() == 'sql':
            return generate_sql_query(query, df_columns)
        else:  # Python
            return generate_python_code(query, df_columns)
                
    except Exception as e:
        error_msg = f"""# Erreur lors de la génération du code
# Détails de l'erreur: {str(e)}

# Voici un exemple de requête de base que vous pouvez adapter:
# Pour SQL: SELECT * FROM df LIMIT 10
# Pour Python: df.head()
"""
        return error_msg

# ============================================
# 7. Exécution de l'application
# ============================================

if __name__ == "__main__":
    main()

# La barre latérale est maintenant gérée par la fonction render_sidebar()
# Cette section a été supprimée car elle était en double
