"""
Streamlit interface for the Analyser IA pipeline.

Ce module est le point d'entr√©e principal de l'application d'analyse de donn√©es.
Il g√®re l'interface utilisateur et orchestre les diff√©rentes fonctionnalit√©s.
"""
from __future__ import annotations
import os
import sys
import tempfile
import traceback
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, Union, Callable

# Configuration du chemin d'importation
sys.path.append(str(Path(__file__).parent.parent))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pandasql as psql
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import pytz
import re
import json
from typing import Dict, List, Tuple, Any, Optional, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import hashlib
import base64
import time
import traceback
from pathlib import Path
import io
from pandas.api.types import is_numeric_dtype
import streamlit as st
from pandasql import sqldf
from openpyxl.utils.dataframe import dataframe_to_rows

# Import des modules personnalis√©s
from analyser_ia.app.ui_enhancements import (
    set_custom_theme,
    Spinner,
    info_box,
    success_message,
    error_message,
    warning_message,
    card
)
from analyser_ia.app.caching import cache_data, clear_cache

from analyser_ia.app.ai_interpreter import interpret
from analyser_ia.app.pipeline import load_data, clean_data, run_analysis
from analyser_ia.app.report_generator import (
    export_report,
    generate_html_report,
    AUTHOR_INFO
)

# Version de l'application
VERSION = "1.0.0"
from analyser_ia.app.visualization import (
    histogram,
    boxplot,
    correlation_heatmap,
    pairplot_matrix,
    pca_scatter,
    timeseries_line,
    scatter_plot
)

# ============================================
# 1. Configuration initiale
# ============================================

# Configuration des chemins
REPORTS_DIR = Path("D:/Dev/Analyser/reports")
REPORTS_DIR.mkdir(parents=True, exist_ok=True)

# Configuration de la page
st.set_page_config(
    page_title="üìä Analyser IA | Plateforme d'Analyse de Donn√©es",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/your-repo/analyser-ia/issues',
        'Report a bug': 'https://github.com/your-repo/analyser-ia/issues',
        'About': "### Analyser IA\nUne application puissante pour l'analyse de donn√©es assist√©e par IA\n\nD√©velopp√© par Sidoine YEBADOKPO\nContact: +229 01 96 91 13 46"
    }
)

# Application du th√®me personnalis√©
set_custom_theme()

# Initialisation de l'√©tat de session
def join_dataframes(df1: pd.DataFrame, df2: pd.DataFrame, on_columns: list, how: str = 'inner') -> pd.DataFrame:
    """
    Joint deux DataFrames sur les colonnes sp√©cifi√©es.
    
    Args:
        df1: Premier DataFrame
        df2: Deuxi√®me DataFrame
        on_columns: Liste des colonnes de jointure
        how: Type de jointure ('inner', 'left', 'right', 'outer')
        
    Returns:
        DataFrame: Le r√©sultat de la jointure
    """
    try:
        # V√©rifier que les colonnes de jointure existent dans les deux DataFrames
        missing_in_df1 = [col for col in on_columns if col not in df1.columns]
        missing_in_df2 = [col for col in on_columns if col not in df2.columns]
        
        if missing_in_df1:
            raise ValueError(f"Colonnes manquantes dans la premi√®re table: {', '.join(missing_in_df1)}")
        if missing_in_df2:
            raise ValueError(f"Colonnes manquantes dans la deuxi√®me table: {', '.join(missing_in_df2)}")
            
        # Effectuer la jointure
        return df1.merge(df2, on=on_columns, how=how)
        
    except Exception as e:
        st.error(f"Erreur lors de la jointure des tables: {str(e)}")
        return None

def init_session_state():
    """Initialise l'√©tat de la session avec des valeurs par d√©faut."""
    if 'step' not in st.session_state:
        # √âtat de l'interface utilisateur
        st.session_state.ui_state = {
            'sidebar_expanded': True,
            'show_config': False,
            'show_quick_preview': False,
            'dark_mode': False,
            'show_advanced': False,
            'selected_cols': [],
            'selected_analysis': None
        }
        
        # Configuration
        st.session_state.config = {
            'ai_model': 'GPT-4',
            'detail_level': 3,
            'require_manual_approval': True,
            'limit_query_results': True,
            'include_raw_data': True,
            'include_charts': True,
            'generate_summary': True,
            'include_source_code': False
        }
        
        # Donn√©es
        st.session_state.df_raw = None  # Donn√©es brutes
        st.session_state.df_clean = None  # Donn√©es nettoy√©es
        st.session_state.df_secondary = None  # Deuxi√®me ensemble de donn√©es pour jointure
        st.session_state.df_joined = None  # R√©sultat de la jointure
        st.session_state.data_loaded = False  # Indique si des donn√©es sont charg√©es
        st.session_state.data_cleaned = False  # Indique si les donn√©es ont √©t√© nettoy√©es
        st.session_state.join_columns = []  # Colonnes de jointure
        st.session_state.join_type = 'inner'  # Type de jointure par d√©faut
        
        # Navigation
        st.session_state.step = 0  # √âtape actuelle (0=Contexte, 1=Chargement, 2=Nettoyage, 3=Analyse, 4=Rapport)
        st.session_state.previous_step = None  # √âtape pr√©c√©dente pour la navigation
        st.session_state.app_start_time = datetime.now()  # Heure de d√©marrage de la session
        st.session_state.last_interaction = None  # Derni√®re interaction utilisateur
        
        # Contexte et objectifs
        st.session_state.context_objective = ""  # Objectif de l'analyse
        st.session_state.context_metrics = []  # M√©triques cl√©s √† surveiller
        st.session_state.context_constraints = []  # Contraintes connues
        
        # Requ√™tes et analyses
        st.session_state.suggested_queries = []  # Requ√™tes sugg√©r√©es par l'IA
        st.session_state.custom_queries = []  # Requ√™tes personnalis√©es de l'utilisateur
        st.session_state.custom_analysis_results = {}  # R√©sultats des analyses personnalis√©es
        st.session_state.selected_analysis_types = ["Statistiques descriptives", "Corr√©lations"]  # Types d'analyses s√©lectionn√©s
        st.session_state.widget_counter = 0  # Compteur pour les cl√©s uniques
        
        # Sorties et r√©sultats
        st.session_state.outputs = []
        
        # Configuration et param√®tres
        st.session_state.cleaning_steps = []  # √âtapes de nettoyage appliqu√©es
        st.session_state.config_saved = False  # Configuration enregistr√©e
        st.session_state.generated_code = None  # Code g√©n√©r√©
        st.session_state.show_generated_code = False  # Afficher le code g√©n√©r√©
        st.session_state.cache_enabled = True  # Activer la mise en cache
        st.session_state.performance_mode = False  # Mode performance (d√©sactive certaines fonctionnalit√©s)

# ============================================
# 2. Fonctions utilitaires
# ============================================

def generate_interpretation(data):
    """
    G√©n√®re une interpr√©tation automatique des donn√©es d'un DataFrame ou d'une structure de donn√©es.
    
    Args:
        data: Donn√©es √† analyser (DataFrame, Series, dict, list, r√©sultats de mod√®le, etc.)
        
    Returns:
        str: Interpr√©tation textuelle des donn√©es
    """
    try:
        # V√©rifier si les donn√©es sont vides
        if data is None:
            return "Aucune donn√©e √† analyser (None)."
        
        # V√©rifier si c'est un r√©sultat de r√©gression statsmodels
        if hasattr(data, 'summary'):
            return _interpret_regression_results(data)
            
        # V√©rifier si c'est une liste de r√©sultats
        if isinstance(data, (list, tuple)) and len(data) > 0:
            # Si le premier √©l√©ment est un r√©sultat de r√©gression
            if hasattr(data[0], 'summary'):
                return _interpret_regression_results(data[0])
            # Si c'est une liste de DataFrames ou de r√©sultats
            interpretations = []
            for i, item in enumerate(data):
                if hasattr(item, 'summary'):  # R√©sultat de r√©gression
                    interpretations.append(f"## R√©sultat de r√©gression {i+1}")
                    interpretations.append(_interpret_regression_results(item))
                elif hasattr(item, 'to_string'):  # DataFrame ou similaire
                    try:
                        df = pd.DataFrame(item) if not isinstance(item, pd.DataFrame) else item
                        interpretations.append(f"## Tableau de donn√©es {i+1}")
                        interpretations.append(_analyze_dataframe(df))
                    except:
                        interpretations.append(f"## √âl√©ment {i+1}")
                        interpretations.append(f"Type: {type(item).__name__}")
                        interpretations.append(str(item)[:500] + ("..." if len(str(item)) > 500 else ""))
            
            if interpretations:
                return "\n\n".join(interpretations)
            
        # Convertir en DataFrame si ce n'en est pas un
        if not isinstance(data, pd.DataFrame):
            if hasattr(data, 'to_frame'):
                return _analyze_dataframe(data.to_frame())
            elif hasattr(data, 'to_dict'):
                return _analyze_dataframe(pd.DataFrame(data.to_dict()))
            elif isinstance(data, (dict, list, tuple)) and data:
                try:
                    return _analyze_dataframe(pd.DataFrame(data))
                except Exception as e:
                    return f"### ‚ùå Erreur de conversion\nImpossible de convertir les donn√©es en DataFrame: {str(e)}"
            else:
                # Pour les types simples (nombres, cha√Ænes, etc.)
                return f"### üìã R√©sultat\nValeur unique : {data}"
        
        # Si on arrive ici, c'est un DataFrame
        return _analyze_dataframe(data)
    
    except Exception as e:
        # En cas d'erreur, retourner un message d'erreur d√©taill√©
        error_msg = [
            "### ‚ùå Erreur lors de l'analyse",
            "Impossible de g√©n√©rer une interpr√©tation automatique.",
            "",
            f"**D√©tails de l'erreur:**",
            f"```",
            f"{str(e)[:1000]}",  # Limiter la taille pour √©viter les probl√®mes d'affichage
            f"```",
            "",
            f"**Type de donn√©es re√ßu:** {type(data).__name__}",
            ""
        ]
        
        # Ajouter un aper√ßu des donn√©es si possible
        try:
            if hasattr(data, 'head') and callable(data.head):
                error_msg.extend([
                    "",
                    "**Aper√ßu des donn√©es:**",
                    f"```",
                    f"{data.head().to_string()}",
                    f"```"
                ])
            elif hasattr(data, '__str__'):
                error_msg.extend([
                    "",
                    "**Contenu:**",
                    f"```",
                    f"{str(data)[:1000]}",
                    f"..." if len(str(data)) > 1000 else "",
                    f"```"
                ])
        except:
            pass
            
        return "\n".join(str(item) for item in error_msg)

def _interpret_regression_results(reg_result):
    """Interpr√®te les r√©sultats d'une r√©gression statsmodels."""
    try:
        interpretation = ["## üìà R√©sultats de la r√©gression lin√©aire"]
        
        # R√©cup√©rer le r√©sum√© sous forme de texte
        summary = str(reg_result.summary())
        
        # Extraire les informations cl√©s avec des expressions r√©guli√®res
        import re
        
        # R-carr√©
        r_sq = re.search(r'R-squared:\s+([0-9.]+)', summary)
        adj_r_sq = re.search(r'Adj. R-squared:\s+([0-9.]+)', summary)
        
        if r_sq and adj_r_sq:
            interpretation.append(f"- **Qualit√© du mod√®le**:")
            interpretation.append(f"  - R¬≤ = {float(r_sq.group(1)):.3f} (plus proche de 1, meilleur est le mod√®le)")
            interpretation.append(f"  - R¬≤ ajust√© = {float(adj_r_sq.group(1)):.3f} (tient compte du nombre de variables)")
        
        # Variables et coefficients
        coef_section = re.search(r'={5,}\n(.+?)\n={5,}', summary, re.DOTALL)
        if coef_section:
            interpretation.append("\n### üîç Coefficients du mod√®le:")
            lines = coef_section.group(1).strip().split('\n')
            
            # En-t√™te
            if len(lines) > 1:
                headers = [h.strip() for h in re.split('\s{2,}', lines[0].strip()) if h.strip()]
                var_lines = lines[2:]  # Sauter l'en-t√™te et la ligne de s√©paration
                
                for line in var_lines:
                    if not line.strip():
                        continue
                    parts = [p.strip() for p in re.split('\s{2,}', line.strip()) if p.strip()]
                    if len(parts) >= len(headers):
                        var_name = parts[0]
                        coef = parts[1]
                        p_value = parts[4] if len(parts) > 4 else 'N/A'
                        ci_low = parts[5] if len(parts) > 5 else 'N/A'
                        ci_high = parts[6] if len(parts) > 6 else 'N/A'
                        
                        interpretation.append(f"- **{var_name}**:")
                        interpretation.append(f"  - Coefficient = {coef}")
                        interpretation.append(f"  - p-valeur = {p_value}")
                        interpretation.append(f"  - Intervalle de confiance √† 95%: [{ci_low}, {ci_high}]")
        
        # Tests de diagnostic
        diag_section = re.search(r'Omnibus:.+', summary, re.DOTALL)
        if diag_section:
            interpretation.append("\n### üîç Tests de diagnostic:")
            diag_lines = diag_section.group(0).split('\n')
            for line in diag_lines:
                if ':' in line:
                    test, value = line.split(':', 1)
                    interpretation.append(f"- **{test.strip()}**: {value.strip()}")
        
        # Notes et avertissements
        if 'Notes:' in summary:
            notes = summary.split('Notes:')[1].strip()
            if notes:
                interpretation.append("\n### ‚ö†Ô∏è Notes importantes:")
                for note in notes.split('\n'):
                    if note.strip():
                        interpretation.append(f"- {note.strip()}")
        
        # Interpr√©tation du R¬≤
        if r_sq:
            r2 = float(r_sq.group(1))
            interpretation.append("\n### üìä Interpr√©tation du R¬≤:")
            if r2 < 0.2:
                interpretation.append("- Le mod√®le explique tr√®s peu de la variance des donn√©es (R¬≤ < 0.2).")
            elif r2 < 0.5:
                interpretation.append("- Le mod√®le explique une partie modeste de la variance des donn√©es (0.2 ‚â§ R¬≤ < 0.5).")
            elif r2 < 0.7:
                interpretation.append("- Le mod√®le explique une part substantielle de la variance des donn√©es (0.5 ‚â§ R¬≤ < 0.7).")
            else:
                interpretation.append("- Le mod√®le explique bien la variance des donn√©es (R¬≤ ‚â• 0.7).")
        
        return "\n".join(interpretation)
    
    except Exception as e:
        return f"### ‚ùå Erreur d'interpr√©tation des r√©sultats de r√©gression\n{str(e)}"

def _analyze_dataframe(df):
    """Analyse un DataFrame et retourne une interpr√©tation."""
    try:
        interpretation = []
        
        # V√©rifier si le DataFrame est vide
        if df.empty:
            return "Aucune donn√©e √† analyser (DataFrame vide)."
        
        # Informations de base
        interpretation.append("### üìä Aper√ßu des donn√©es")
        interpretation.append(f"- Nombre de lignes : {len(df)}")
        interpretation.append(f"- Nombre de colonnes : {len(df.columns)}")
        
        # Aper√ßu des colonnes
        interpretation.append("\n### üìã Aper√ßu des colonnes")
        for col in df.columns:
            try:
                dtype = str(df[col].dtype)
                unique_count = df[col].nunique()
                interpretation.append(f"- **{col}** (*{dtype}*) : {unique_count} valeurs uniques")
            except Exception as e:
                interpretation.append(f"- **{col}** : Erreur lors de l'analyse")
        
        # Analyse des colonnes num√©riques
        try:
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            if numeric_cols:
                interpretation.append("\n### üî¢ Variables num√©riques")
                
                for col in numeric_cols[:10]:  # Limiter √† 10 colonnes
                    try:
                        if is_numeric_dtype(df[col]):
                            stats = df[col].describe()
                            interpretation.append(
                                f"- **{col}**: "
                                f"Moyenne = {stats.get('mean', 'N/A'):.2f}, "
                                f"M√©diane = {stats.get('50%', 'N/A'):.2f}, "
                                f"Min = {stats.get('min', 'N/A')}, "
                                f"Max = {stats.get('max', 'N/A')}"
                            )
                    except Exception as e:
                        interpretation.append(f"- **{col}**: Impossible d'analyser cette colonne num√©rique")
        except Exception as e:
            interpretation.append("\n‚ö†Ô∏è Impossible d'analyser les variables num√©riques")
        
        # Analyse des colonnes cat√©gorielles
        try:
            cat_cols = df.select_dtypes(include=['object', 'category', 'bool', 'string']).columns.tolist()
            if cat_cols:
                interpretation.append("\n### üî§ Variables cat√©gorielles")
                
                for col in cat_cols[:10]:  # Limiter √† 10 colonnes
                    try:
                        unique_count = df[col].nunique()
                        if unique_count < 20:  # Limite pour √©viter les sorties trop longues
                            value_counts = df[col].value_counts().head(5)
                            interpretation.append(f"- **{col}**: {unique_count} valeurs uniques")
                            for val, count in value_counts.items():
                                interpretation.append(f"  - {val}: {count} ({count/len(df)*100:.1f}%)")
                        else:
                            interpretation.append(f"- **{col}**: {unique_count} valeurs uniques (trop pour l'affichage)")
                    except Exception as e:
                        interpretation.append(f"- **{col}**: Impossible d'analyser cette colonne cat√©gorielle")
        except Exception as e:
            interpretation.append("\n‚ö†Ô∏è Impossible d'analyser les variables cat√©gorielles")
        
        # D√©tection des corr√©lations pour les donn√©es num√©riques
        try:
            if len(numeric_cols) > 1:
                # Calculer la matrice de corr√©lation
                corr_matrix = df[numeric_cols].corr()
                # Obtenir les paires de corr√©lations
                corr_pairs = corr_matrix.unstack().sort_values(ascending=False)
                # Filtrer les corr√©lations avec soi-m√™me et les doublons
                corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]
                corr_pairs = corr_pairs[~corr_pairs.index.duplicated()]
                # Prendre les 3 premi√®res corr√©lations les plus fortes
                corr_pairs = corr_pairs.head(3)
                
                if len(corr_pairs) > 0:
                    interpretation.append("\n### üîó Corr√©lations notables")
                    for (col1, col2), value in corr_pairs.items():
                        if abs(value) > 0.5:  # Seuil de corr√©lation mod√©r√©
                            direction = "positive" if value > 0 else "n√©gative"
                            interpretation.append(
                                f"- Corr√©lation {direction} entre **{col1}** et **{col2}** "
                                f"(r = {value:.2f})"
                            )
        except Exception as e:
            # En cas d'erreur, on passe simplement √† la suite
            pass
        
        # Conseils d'analyse
        interpretation.append("\n### üí° Conseils pour l'analyse")
        if numeric_cols:
            interpretation.append("- Visualisez la distribution des variables num√©riques avec des histogrammes")
        if cat_cols:
            interpretation.append("- Explorez les relations entre variables cat√©gorielles avec des diagrammes en barres ou camemberts")
        if len(numeric_cols) >= 2:
            interpretation.append("- Examinez les relations entre variables num√©riques avec des nuages de points ou des matrices de corr√©lation")
        
        return "\n".join(str(item) for item in interpretation)
    
    except Exception as e:
        return f"### ‚ùå Erreur lors de l'analyse du DataFrame\n{str(e)}"

def generate_ai_interpretation(context: str, data_description: str, chart_type: str = "") -> str:
    """
    G√©n√®re une interpr√©tation automatique des donn√©es ou graphiques.
    
    Args:
        context: Contexte de l'analyse (description de ce qui est affich√©)
        data_description: Description des donn√©es (statistiques, tendances, valeurs cl√©s)
        chart_type: Type de graphique (optionnel)
        
    Returns:
        str: Interpr√©tation g√©n√©r√©e par l'IA
    """
    try:
        # Construction du prompt pour l'IA
        prompt = f"""
        Tu es un expert en analyse de donn√©es. Analyse les informations suivantes et fournis une interpr√©tation claire et concise en fran√ßais.
        
        Contexte: {context}
        Type de visualisation: {chart_type if chart_type else 'Tableau de donn√©es'}
        Donn√©es: {data_description}
        
        Fournis une analyse en 3 parties:
        1. Ce que montrent les donn√©es
        2. Les tendances ou points marquants
        3. 1-2 recommandations d'actions bas√©es sur ces donn√©es
        """
        
        return call_gemini_api(prompt)
        
    except Exception as e:
        st.warning(f"Impossible de g√©n√©rer l'interpr√©tation: {str(e)}")
        return ""

def display_with_interpretation(content, context: str, data_description: str, chart_type: str = ""):
    """
    Affiche un contenu (graphique ou tableau) avec son interpr√©tation automatique.
    """
    # Afficher le contenu principal
    st.write(content)
    
    # G√©n√©rer et afficher l'interpr√©tation
    with st.expander("üîç Interpr√©tation automatique", expanded=True):
        with st.spinner("G√©n√©ration de l'interpr√©tation..."):
            interpretation = generate_ai_interpretation(context, data_description, chart_type)
            if interpretation:
                st.markdown(interpretation)
            else:
                st.info("Impossible de g√©n√©rer une interpr√©tation pour ces donn√©es.")

def call_gemini_api(prompt: str, model_name: str = "gemini-1.5-flash") -> str:
    """
    Appelle l'API Gemini avec le prompt donn√© et retourne la r√©ponse.
    
    Args:
        prompt: Le prompt √† envoyer √† l'API
        model_name: Le nom du mod√®le √† utiliser (par d√©faut: gemini-1.5-flash)
        
    Returns:
        str: La r√©ponse de l'API ou un message d'erreur
    """
    try:
        import google.generativeai as genai
        
        # Configuration de l'API (√† s√©curiser dans les variables d'environnement)
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("Cl√© API Google non configur√©e. Veuillez d√©finir la variable d'environnement GEMINI_API_KEY dans le fichier .env")
            
        genai.configure(api_key=api_key)
        
        # Liste des mod√®les disponibles avec leurs priorit√©s
        available_models = [
            "gemini-1.5-flash",      # Dernier mod√®le Flash (rapide et efficace)
            "gemini-1.5-pro",        # Dernier mod√®le Pro (plus puissant)
            "gemini-pro"             # Ancien mod√®le Pro (r√©trocompatibilit√©)
        ]
        
        # Si le mod√®le demand√© n'est pas disponible, on essaie les autres dans l'ordre
        if model_name not in available_models:
            model_name = available_models[0]  # Utilise le premier mod√®le disponible
            
        st.session_state.last_used_model = model_name  # Sauvegarder le mod√®le utilis√©
        
        # Cr√©ation du mod√®le
        model = genai.GenerativeModel(model_name)
        
        # Configuration de la g√©n√©ration
        generation_config = {
            "temperature": 0.7,
            "top_p": 1,
            "top_k": 40,
            "max_output_tokens": 2048,
        }
        
        # Appel √† l'API
        response = model.generate_content(
            prompt,
            generation_config=generation_config,
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        # V√©rification de la r√©ponse
        if not response or not response.text:
            raise ValueError("R√©ponse vide de l'API Gemini")
            
        return response.text
        
    except Exception as e:
        raise Exception(f"Erreur lors de l'appel √† l'API Gemini: {str(e)}")
        


def safe_json(obj: Any, label: str) -> None:
    """Affiche un objet JSON ou une erreur lisible si ce n'est pas un dict."""
    st.subheader(label)
    if isinstance(obj, dict):
        st.json(obj, expanded=False)
    else:
        st.error(str(obj))

def reset_analysis():
    """R√©initialise les √©tapes d'analyse."""
    st.session_state.df_clean = None
    st.session_state.step = 1

def detect_analysis_type(query: str) -> str:
    """
    D√©tecte le type d'analyse √† partir d'une requ√™te en langage naturel.
    
    Args:
        query: La requ√™te en langage naturel
        
    Returns:
        str: Le type d'analyse d√©tect√© ('time_series', 'correlation', 'distribution', 'groupby', 'other')
    """
    if not query or not isinstance(query, str):
        return 'other'
        
    query = query.lower()
    
    # D√©tection des s√©ries temporelles
    time_keywords = ['s√©rie temporelle', '√©volution dans le temps', 'tendance', 'au fil du temps',
                   'historique', 'p√©riode', 'date', 'mois', 'ann√©e', 'jour', 'heure']
    if any(keyword in query for keyword in time_keywords):
        return 'time_series'
    
    # D√©tection des corr√©lations
    corr_keywords = ['corr√©lation', 'relation entre', 'li√© √†', 'associ√© √†', 'd√©pend de',
                   'influence de', 'impact de', 'lien entre']
    if any(keyword in query for keyword in corr_keywords):
        return 'correlation'
    
    # D√©tection des distributions
    dist_keywords = ['distribution', 'r√©partition', 'histogramme', 'fr√©quence', 
                   'densit√©', 'distribution des valeurs']
    if any(keyword in query for keyword in dist_keywords):
        return 'distribution'
    
    # D√©tection des regroupements
    group_keywords = ['par cat√©gorie', 'par r√©gion', 'par type', 'grouper par', 
                    'regrouper par', 'agr√©ger par', 'agr√©gation par']
    if any(keyword in query for keyword in group_keywords):
        return 'groupby'
        
    # Par d√©faut, retourner 'other' si aucun type sp√©cifique n'est d√©tect√©
    return 'other'

def clean_column_name(column_name: str) -> str:
    """
    Nettoie un nom de colonne en supprimant les balises HTML et en rempla√ßant les caract√®res sp√©ciaux.
    
    Args:
        column_name: Nom de la colonne √† nettoyer
        
    Returns:
        str: Nom de colonne nettoy√© et valide
        
    Exemples:
        >>> clean_column_name("Nom de l'article")
        'nom_de_l_article'
        >>> clean_column_name("Prix (‚Ç¨)")
        'prix_eur'
        >>> clean_column_name("  Date d'achat  ")
        'date_d_achat'
    """
    if not isinstance(column_name, str):
        column_name = str(column_name)
        
    # Suppression des balises HTML
    clean_name = re.sub(r'<[^>]*>', '', column_name)
    
    # Remplacement des caract√®res sp√©ciaux par des underscores
    # Conversion en minuscules pour la coh√©rence
    clean_name = clean_name.lower()
    
    # Remplacement des caract√®res accentu√©s
    clean_name = (
        clean_name
        .replace('√©', 'e').replace('√®', 'e').replace('√™', 'e')
        .replace('√†', 'a').replace('√¢', 'a')
        .replace('√Æ', 'i').replace('√Ø', 'i')
        .replace('√¥', 'o').replace('√∂', 'o')
        .replace('√π', 'u').replace('√ª', 'u').replace('√º', 'u')
        .replace('√ß', 'c')
    )
    
    # Remplacement des caract√®res sp√©ciaux
    clean_name = re.sub(r'[^a-z0-9_]+', '_', clean_name)
    
    # Suppression des underscores multiples
    clean_name = re.sub(r'_+', '_', clean_name)
    
    # Suppression des underscores en d√©but et fin
    clean_name = clean_name.strip('_')
    
    # V√©rification que le nom n'est pas vide apr√®s nettoyage
    if not clean_name:
        clean_name = 'unnamed_column'
    
    # V√©rification que le nom ne commence pas par un chiffre (invalide en Python)
    if clean_name[0].isdigit():
        clean_name = f'col_{clean_name}'
    
    return clean_name

def clean_dataframe_columns(df: pd.DataFrame, inplace: bool = False) -> pd.DataFrame:
    """
    Nettoie les noms de colonnes d'un DataFrame.
    
    Args:
        df: DataFrame dont les colonnes doivent √™tre nettoy√©es
        inplace: Si True, modifie le DataFrame en place. Sinon, retourne une copie.
        
    Returns:
        DataFrame: DataFrame avec des noms de colonnes nettoy√©s
        
    Exemples:
        >>> df = pd.DataFrame({'Nom du client': [1], '√Çge (ans)': [25]})
        >>> clean_dataframe_columns(df).columns.tolist()
        ['nom_du_client', 'age_ans']
    """
    if df is None:
        return None
        
    if df.empty:
        return df.copy() if not inplace else df
    
    # Cr√©ation d'un dictionnaire de mappage des anciens noms vers les nouveaux
    column_mapping = {}
    name_counts = {}
    
    for col in df.columns:
        clean_name = clean_column_name(col)
        
        # Gestion des doublons potentiels apr√®s nettoyage
        if clean_name in name_counts:
            name_counts[clean_name] += 1
            clean_name = f"{clean_name}_{name_counts[clean_name]}"
        else:
            name_counts[clean_name] = 0
            
        column_mapping[col] = clean_name
    
    # V√©rification des colonnes en double apr√®s nettoyage
    if len(column_mapping) != len(set(column_mapping.values())):
        duplicates = {}
        for orig, new in column_mapping.items():
            duplicates[new] = duplicates.get(new, []) + [orig]
        
        duplicates = {k: v for k, v in duplicates.items() if len(v) > 1}
        if duplicates:
            st.warning(f"Attention : Certaines colonnes ont le m√™me nom apr√®s nettoyage : {duplicates}")
    
    # Application du nettoyage des noms de colonnes
    if inplace:
        df.rename(columns=column_mapping, inplace=True)
        return df
    else:
        return df.rename(columns=column_mapping)

def split_sql_queries(sql: str) -> list:
    """
    Divise une cha√Æne SQL contenant plusieurs requ√™tes en une liste de requ√™tes individuelles.
    G√®re les blocs BEGIN/END et les proc√©dures stock√©es.
    
    Args:
        sql: Cha√Æne SQL contenant potentiellement plusieurs requ√™tes
        
    Returns:
        list: Liste des requ√™tes SQL individuelles
        
    Exemples:
    ```python
    # S√©paration de requ√™tes simples
    split_sql_queries("SELECT * FROM table1; SELECT * FROM table2;")
    # Retourne: ['SELECT * FROM table1', 'SELECT * FROM table2']
    ```
    """
    if not sql or not isinstance(sql, str):
        return []
        
    # Suppression des commentaires (lignes commen√ßant par --)
    sql = re.sub(r'--.*?$', '', sql, flags=re.MULTILINE)
    # Suppression des commentaires multi-lignes (/* ... */)
    sql = re.sub(r'/\*.*?\*/', '', sql, flags=re.DOTALL)
    
    # Normalisation des espaces blancs
    sql = ' '.join(sql.split())
    
    # D√©tection des blocs BEGIN...END et proc√©dures
    queries = []
    current_query = []
    in_block = False
    block_level = 0
    
    # Parcours caract√®re par caract√®re
    i = 0
    n = len(sql)
    while i < n:
        # V√©rification des blocs BEGIN...END
        if sql.startswith('BEGIN', i) and (i == 0 or not sql[i-1].isalnum()):
            in_block = True
            block_level += 1
            current_query.append('BEGIN')
            i += 5
            continue
            
        if sql.startswith('END', i) and (i == 0 or not sql[i-1].isalnum()):
            block_level = max(0, block_level - 1)
            current_query.append('END')
            i += 3
            if block_level == 0:
                in_block = False
            continue
        
        # Gestion des points-virgules
        if sql[i] == ';' and not in_block:
            query = ''.join(current_query).strip()
            if query:
                queries.append(query)
            current_query = []
        else:
            current_query.append(sql[i])
            
        i += 1
    
    # Ajout de la derni√®re requ√™te si elle existe
    last_query = ''.join(current_query).strip()
    if last_query:
        queries.append(last_query)
    
    # Nettoyage des requ√™tes vides
    return [q for q in queries if q.strip()]

def execute_sql_query(query: str, df: pd.DataFrame, max_rows: int = 10000) -> tuple[bool, str, pd.DataFrame | None]:
    """
    Ex√©cute une seule requ√™te SQL sur un DataFrame avec gestion des erreurs et des performances.
    
    Args:
        query: Requ√™te SQL √† ex√©cuter
        df: DataFrame source
        max_rows: Nombre maximum de lignes √† retourner (pour √©viter les fuites de m√©moire)
        
    Returns:
        tuple: (succ√®s: bool, message: str, r√©sultat: DataFrame ou None)
        
    Exemples:
        >>> df = pd.DataFrame({'nom': ['Alice', 'Bob'], 'age': [25, 30]})
        >>> success, msg, result = execute_sql_query("SELECT * FROM df WHERE age > 25", df)
        >>> success
        True
        >>> len(result)
        1
    """
    # V√©rification des entr√©es
    if not query or not isinstance(query, str) or not query.strip():
        return False, "La requ√™te SQL ne peut pas √™tre vide.", None
        
    if df is None or df.empty:
        return False, "Le DataFrame source est vide.", None
    
    try:
        # Nettoyage de la requ√™te
        query = query.strip()
        
        # V√©rification des requ√™tes potentiellement dangereuses (optionnel)
        if any(cmd in query.upper() for cmd in ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER']):
            return False, "Les op√©rations de modification de donn√©es ne sont pas autoris√©es.", None
        
        # Nettoyage des noms de colonnes dans le DataFrame
        start_time = time.time()
        df_clean = clean_dataframe_columns(df)
        clean_time = time.time() - start_time
        
        # Limitation du nombre de lignes pour les requ√™tes non limit√©es
        if 'LIMIT' not in query.upper():
            query = f"{query.rstrip(';')} LIMIT {max_rows}"
        
        # Ex√©cution de la requ√™te avec gestion du temps d'ex√©cution
        start_time = time.time()
        try:
            result = psql.sqldf(query, {'df': df_clean})
            exec_time = time.time() - start_time
            
            # V√©rification si le r√©sultat est vide
            if result is None or result.empty:
                return False, "La requ√™te n'a retourn√© aucun r√©sultat.", None
                
            # Nettoyage des noms de colonnes dans le r√©sultat
            result = clean_dataframe_columns(result)
            
            # Journalisation des performances
            st.session_state.setdefault('query_metrics', []).append({
                'query': query[:100] + ('...' if len(query) > 100 else ''),
                'execution_time': round(exec_time, 4),
                'clean_time': round(clean_time, 4),
                'result_rows': len(result),
                'result_columns': list(result.columns),
                'timestamp': time.time()
            })
            
            return True, f"Requ√™te ex√©cut√©e en {exec_time:.2f}s. {len(result)} lignes retourn√©es.", result
            
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            
            # Messages d'erreur plus conviviaux
            if 'no such table' in error_msg.lower():
                error_msg = "Erreur: La table sp√©cifi√©e n'existe pas. V√©rifiez le nom de la table dans votre requ√™te."
            elif 'no such column' in error_msg.lower():
                error_msg = f"Erreur: Colonne non trouv√©e. V√©rifiez les noms des colonnes: {', '.join(df_clean.columns)}"
            elif 'syntax error' in error_msg.lower():
                error_msg = f"Erreur de syntaxe SQL: {error_msg}"
                
            return False, f"Erreur lors de l'ex√©cution de la requ√™te: {error_msg}", None
            
    except Exception as e:
        # Erreur inattendue
        error_msg = f"Erreur inattendue: {str(e)}"
        st.error(f"Erreur critique: {error_msg}")
        import traceback
        st.error(traceback.format_exc())
        return False, error_msg, None

def execute_code(
    code: str, 
    code_type: str, 
    df: pd.DataFrame,
    max_rows: int = 10000,
    timeout: int = 30
) -> tuple[bool, str, dict[str, any] | pd.DataFrame | None]:
    """
    Ex√©cute du code SQL ou Python sur un DataFrame avec gestion des erreurs et des performances.
    
    Args:
        code: Code SQL ou Python √† ex√©cuter
        code_type: 'sql' ou 'python'
        df: DataFrame source pour l'ex√©cution
        max_rows: Nombre maximum de lignes √† retourner (pour SQL)
        timeout: D√©lai d'expiration en secondes pour l'ex√©cution
        
    Returns:
        tuple: (succ√®s: bool, message: str, r√©sultat: DataFrame/dict ou None)
        
    Exemples:
    ```python
    # Exemple avec SQL
    df = pd.DataFrame({'nom': ['Alice', 'Bob'], 'age': [25, 30]})
    success, msg, result = execute_code("SELECT * FROM df WHERE age > 25", 'sql', df)
    print(success)  # True
    
    # Exemple avec Python
    code = """
    result = df[df['age'] > 25].copy()
    result['categorie'] = pd.cut(
        result['age'], 
        bins=[0, 30, 100],
        labels=['jeune', 'adulte']
    )
    """
    success, msg, result = execute_code(code, 'python', df)
    print(success)  # True
    ```
    """
    if not code or not isinstance(code, str) or not code.strip():
        return False, "Le code ne peut pas √™tre vide.", None
        
    if df is None or df.empty:
        return False, "Le DataFrame source est vide.", None
    
    code_type = code_type.lower()
    if code_type not in ('sql', 'python'):
        return False, f"Type de code non pris en charge: {code_type}. Utilisez 'sql' ou 'python'.", None
    
    # Journalisation de l'ex√©cution
    exec_id = f"{code_type}_{int(time.time())}"
    st.session_state.setdefault('execution_logs', {})[exec_id] = {
        'code_type': code_type,
        'code': code,
        'timestamp': time.time(),
        'success': False
    }
    
    try:
        if code_type == 'sql':
            # Division des requ√™tes multiples
            queries = split_sql_queries(code)
            
            if not queries:
                return False, "Aucune requ√™te valide trouv√©e.", None
                
            results = {}
            start_time = time.time()
            
            for i, query in enumerate(queries, 1):
                # V√©rification du timeout
                if time.time() - start_time > timeout:
                    return False, f"D√©lai d'ex√©cution d√©pass√© ({timeout}s) √† la requ√™te {i}/{len(queries)}.", None
                
                success, message, result = execute_sql_query(query, df, max_rows)
                if not success:
                    return False, f"Erreur dans la requ√™te {i}/{len(queries)}: {message}", None
                    
                results[f"requete_{i}"] = {
                    'query': query,
                    'result': result,
                    'message': message
                }
            
            # Mise √† jour du journal d'ex√©cution
            exec_time = time.time() - start_time
            st.session_state['execution_logs'][exec_id].update({
                'success': True,
                'execution_time': round(exec_time, 2),
                'num_queries': len(queries),
                'result_columns': [list(r['result'].columns) for r in results.values() if hasattr(r['result'], 'columns')]
            })
            
            # Si une seule requ√™te, on retourne directement le r√©sultat
            if len(results) == 1:
                return True, results["requete_1"]['message'], results["requete_1"]['result']
            # Sinon on retourne un dictionnaire avec tous les r√©sultats
            else:
                return True, f"{len(queries)} requ√™tes ex√©cut√©es avec succ√®s en {exec_time:.2f}s.", results
                
        elif code_type == 'python':
            start_time = time.time()
            
            # Cr√©ation d'un espace de noms s√©curis√© pour l'ex√©cution
            safe_globals = {
                'pd': pd,
                'np': np,
                'px': px,
                'go': go,
                'time': time,
                'datetime': datetime,
                'timedelta': timedelta
            }
            
            local_vars = {
                'df': df.copy(),
                'result': None
            }
            
            # Code de pr√©fixe pour l'importation des biblioth√®ques
            prefix = """
# Importations standards
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import time
from datetime import datetime, timedelta

# Initialisation du r√©sultat
result = None
"""
            # Ex√©cution du code Python avec gestion du timeout
            try:
                # Ex√©cution dans un thread s√©par√© pour le timeout
                from concurrent.futures import ThreadPoolExecutor, TimeoutError as ThreadTimeoutError
                
                def execute():
                    exec(prefix + code, safe_globals, local_vars)
                    return local_vars.get('result')
                
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(execute)
                    result = future.result(timeout=timeout)
                    
            except ThreadTimeoutError:
                return False, f"D√©lai d'ex√©cution d√©pass√© ({timeout}s). Le code Python est trop long.", None
                
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                
                # Messages d'erreur plus conviviaux
                if 'NameError' in error_type:
                    error_msg = f"Erreur de nom: {error_msg}"
                elif 'TypeError' in error_type:
                    error_msg = f"Erreur de type: {error_msg}"
                elif 'KeyError' in error_type:
                    error_msg = f"Cl√© non trouv√©e: {error_msg}"
                    
                return False, f"Erreur Python: {error_msg}", None
            
            # Calcul du temps d'ex√©cution
            exec_time = time.time() - start_time
            
            # V√©rification du r√©sultat
            result = local_vars.get('result')
            if result is not None:
                # Si le r√©sultat est un DataFrame, on le nettoie
                if isinstance(result, pd.DataFrame):
                    result = clean_dataframe_columns(result)
                    
                    # Journalisation des performances
                    st.session_state['execution_logs'][exec_id].update({
                        'success': True,
                        'execution_time': round(exec_time, 2),
                        'result_type': 'dataframe',
                        'result_shape': result.shape,
                        'result_columns': list(result.columns) if hasattr(result, 'columns') else []
                    })
                    
                    return True, f"Code ex√©cut√© avec succ√®s en {exec_time:.2f}s. R√©sultat: {result.shape[0]} lignes x {result.shape[1]} colonnes.", result
                else:
                    # Autres types de r√©sultats
                    result_type = type(result).__name__
                    st.session_state['execution_logs'][exec_id].update({
                        'success': True,
                        'execution_time': round(exec_time, 2),
                        'result_type': result_type,
                        'result_value': str(result)[:500]  # Limiter la taille pour √©viter les probl√®mes de s√©rialisation
                    })
                    return True, f"Code ex√©cut√© avec succ√®s en {exec_time:.2f}s. Type de r√©sultat: {result_type}", result
            else:
                st.session_state['execution_logs'][exec_id].update({
                    'success': True,
                    'execution_time': round(exec_time, 2),
                    'result_type': 'none'
                })
                return True, "Code ex√©cut√© avec succ√®s (pas de r√©sultat retourn√©).", None
                
    except Exception as e:
        # Erreur inattendue
        error_type = type(e).__name__
        error_msg = str(e)
        
        # Journalisation de l'erreur
        st.session_state['execution_logs'][exec_id].update({
            'error_type': error_type,
            'error_message': error_msg,
            'traceback': traceback.format_exc()
        })
        
        return False, f"Erreur inattendue: {error_type} - {error_msg}", None

def generate_query_code(query: str, query_type: str, df_columns: list) -> str:
    """
    G√©n√®re du code SQL ou Python √† partir d'une description en langage naturel.
    
    Args:
        query: Description en langage naturel de la requ√™te
        query_type: 'sql' ou 'python'
        df_columns: Liste des colonnes disponibles dans le DataFrame
        
    Returns:
        str: Le code g√©n√©r√©
    """
    try:
        columns_str = ", ".join(df_columns)
        prompt = f"""
        Je veux effectuer l'analyse suivante sur un DataFrame pandas :
        "{query}"

        Colonnes disponibles : {columns_str}

        G√©n√®re uniquement le code {query_type.upper()} n√©cessaire, sans explications suppl√©mentaires.
        Pour SQL, utilise 'df' comme nom de table.
        Pour Python, stocke le r√©sultat dans une variable 'result'.
        """

        if query_type.lower() == 'sql':
            # G√©n√©ration d'une requ√™te SQL basique si l'IA √©choue
            return f"""-- Requ√™te g√©n√©r√©e pour : {query}
SELECT * 
FROM df 
WHERE {df_columns[0]} IS NOT NULL 
LIMIT 10;"""
        else:  # Python
            # G√©n√©ration d'un code Python basique si l'IA √©choue
            if len(df_columns) >= 2:
                return f"""# {query}
result = df[['{df_columns[0]}', '{df_columns[1]}']].head()"""
            else:
                return f"""# {query}
result = df[['{df_columns[0]}']].head()"""
                
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du code : {str(e)}")
        # En cas d'erreur, on retourne une requ√™te simple mais valide
        if query_type.lower() == 'sql':
            return "-- Requ√™te par d√©faut\nSELECT * FROM df LIMIT 10;"
        else:
            # Retourne un code Python minimal qui fonctionnera avec n'importe quel DataFrame
            return "# Code par d√©faut\nresult = df.head()"
            return f"# {query}\nresult = df.head()"

# ============================================
# 3. Barre lat√©rale
# ============================================

def render_sidebar():
    """Affiche la barre lat√©rale avec la navigation et les contr√¥les principaux."""
    with st.sidebar:
        # En-t√™te avec logo et titre
        col1, col2 = st.columns([1, 3])
        with col1:
            st.image("https://via.placeholder.com/60", width=60)  # Remplacer par votre logo
        with col2:
            st.markdown("# Analyser IA")
            st.caption("Analyse de donn√©es assist√©e par IA")
        
        st.markdown("---")
        
        # Menu de navigation
        with st.expander("üîç Navigation", expanded=st.session_state.ui_state['sidebar_expanded']):
            steps = ["1. Contexte", "2. Chargement", "3. Nettoyage", "4. Analyse", "5. Rapport"]
            for i, step in enumerate(steps):
                # Mise en forme de l'√©tape actuelle
                if i == st.session_state.step:
                    st.markdown(f"**‚û°Ô∏è {step}**")
                # √âtapes termin√©es
                elif i < st.session_state.step:
                    st.markdown(f"‚úÖ ~~{step}~~")
                # √âtapes √† venir
                else:
                    st.markdown(f"‚è≥ {step}")
                
                # Ajout d'un s√©parateur sauf pour le dernier √©l√©ment
                if i < len(steps) - 1:
                    st.markdown("---")
        
        st.markdown("---")
        
        # Section d'aide et d'information
        with st.expander("‚ÑπÔ∏è Aide et informations"):
            st.markdown("""
            **Comment utiliser :**
            1. D√©finissez le contexte de votre analyse
            2. Chargez vos donn√©es
            3. Nettoyez si n√©cessaire
            4. Explorez avec les outils d'analyse
            5. G√©n√©rez votre rapport
            """)
        
        # Boutons d'action
        if st.button("üîÑ Recommencer l'analyse", 
                    use_container_width=True, 
                    help="R√©initialise compl√®tement l'application"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
            
        # Pied de page
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; font-size: 0.8em; color: #666;">
            <p>Analyser IA v1.0.0</p>
            <p>¬© 2025 Tous droits r√©serv√©s</p>
        </div>
        """, unsafe_allow_html=True)

def export_to_colab():
    """Exporte les donn√©es actuelles vers Google Colab."""
    if 'df' not in st.session_state or st.session_state.df is None:
        st.warning("Aucune donn√©e √† exporter vers Colab.")
        return
    
    try:
        # Obtenir la date et l'heure actuelles pour le commentaire
        import datetime
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Cr√©er la structure du notebook Colab
        notebook_content = {
            "cells": [
                {
                    "cell_type": "markdown",
                    "metadata": {"id": "imports"},
                    "source": [
                        "# Analyse avanc√©e avec Google Colab\n",
                        "*Ce notebook a √©t√© g√©n√©r√© automatiquement depuis Analyser IA*\n\n",
                        "## Configuration initiale"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {"id": "install-deps"},
                    "source": [
                        "# Installation des d√©pendances\n",
                        "!pip install pandas numpy matplotlib seaborn plotly"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {"id": "imports"},
                    "source": [
                        "import pandas as pd\n",
                        "import numpy as np\n",
                        "import matplotlib.pyplot as plt\n",
                        "import seaborn as sns\n",
                        "import plotly.express as px\n",
                        "from google.colab import files\n\n",
                        "# Configuration des styles\n",
                        "plt.style.use('seaborn')\n",
                        "sns.set_theme(style=\"whitegrid\")\n",
                        "%matplotlib inline"
                    ]
                },
                {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {"id": "load-data"},
                    "source": [
                        "# T√©l√©chargement des donn√©es\n",
                        f"# Donn√©es export√©es depuis Analyser IA le {timestamp}\n\n",
                        "# Chargement des donn√©es\n",
                        "import io\n",
                        f"df = pd.DataFrame({st.session_state.df.to_dict('list')})\n\n",
                        "# Aper√ßu des donn√©es\n",
                        "print('Aper√ßu des donn√©es :')\n",
                        "display(df.head())\n\n",
                        "# Informations sur les donn√©es\n",
                        "print('\\nInformations sur les donn√©es :')\n",
                        "df.info()"
                    ]
                },
                {
                    "cell_type": "markdown",
                    "metadata": {"id": "analysis-section"},
                    "source": [
                        "## Analyse des donn√©es\n",
                        "Ajoutez vos cellules d'analyse ici"
                    ]
                }
            ],
            "metadata": {
                "colab": {
                    "provenance": [],
                    "toc_visible": True
                },
                "kernelspec": {
                    "name": "python3",
                    "display_name": "Python 3"
                },
                "language_info": {
                    "name": "python"
                }
            },
            "nbformat": 4,
            "nbformat_minor": 0
        }
        
        # Convertir en JSON
        import json
        notebook_json = json.dumps(notebook_content, indent=2, ensure_ascii=False)
        
        # Afficher les instructions
        st.markdown("### Exporter vers Google Colab")
        st.markdown("1. T√©l√©chargez le notebook ci-dessous")
        st.markdown("2. Allez sur [Google Colab](https://colab.research.google.com/)")
        st.markdown("3. Faites Fichier > Importer un notebook > Choisissez le fichier t√©l√©charg√©")
        
        # Bouton de t√©l√©chargement
        st.download_button(
            label="üì• T√©l√©charger le notebook Colab",
            data=notebook_json,
            file_name="analyse_avancee.ipynb",
            mime="application/x-ipynb+json"
        )
        
        # Lien pour ouvrir directement dans Colab
        st.markdown("---")
        st.markdown("Ou ouvrez directement dans Colab (n√©cessite un compte Google) :")
        st.markdown(
            """
            <a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb" target="_blank">
                <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Ouvrir dans Colab">
            </a>
            """,
            unsafe_allow_html=True
        )
        
    except Exception as e:
        st.error(f"Une erreur est survenue lors de la pr√©paration de l'export Colab : {str(e)}")
        st.exception(e)

def render_sidebar():
    """Affiche la barre lat√©rale avec la navigation et les contr√¥les principaux."""
    with st.sidebar:
        # En-t√™te avec logo et titre
        col1, col2 = st.columns([1, 3])
        with col1:
            st.image("https://via.placeholder.com/60", width=60)  # Remplacer par votre logo
        with col2:
            st.markdown("# Analyser IA")
            st.caption("Analyse de donn√©es assist√©e par IA")
        
        st.markdown("---")
        
        # Menu de navigation
        with st.expander("üîç Navigation", expanded=st.session_state.get('ui_state', {}).get('sidebar_expanded', True)):
            steps = ["1. Contexte", "2. Chargement", "3. Nettoyage", "4. Analyse", "5. Rapport"]
            for i, step in enumerate(steps):
                # Mise en forme de l'√©tape actuelle
                if i == st.session_state.get('step', 0):
                    st.markdown(f"**‚û°Ô∏è {step}**")
                # √âtapes termin√©es
                elif i < st.session_state.get('step', 0):
                    st.markdown(f"‚úÖ ~~{step}~~")
                # √âtapes √† venir
                else:
                    st.markdown(f"‚è≥ {step}")
                
                # Ajout d'un s√©parateur sauf pour le dernier √©l√©ment
                if i < len(steps) - 1:
                    st.markdown("---")
        
        st.markdown("---")
        
        # Section d'aide et d'information
        with st.expander("‚ÑπÔ∏è Aide et informations"):
            st.markdown("""
            **Comment utiliser :**
            1. D√©finissez le contexte de votre analyse
            2. Chargez vos donn√©es
            3. Nettoyez si n√©cessaire
            4. Explorez avec les outils d'analyse
            5. G√©n√©rez votre rapport
            """)
        
        # Boutons d'action
        if st.button("üîÑ Recommencer l'analyse", 
                    use_container_width=True, 
                    help="R√©initialise compl√®tement l'application"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
            
        # Export vers Colab
        if 'df' in st.session_state and st.session_state.df is not None:
            with st.expander("üöÄ Exporter vers Colab", expanded=False):
                st.markdown("Exportez vos donn√©es vers Google Colab pour des analyses avanc√©es avec GPU/TPU :")
                if st.button("üì• Pr√©parer l'export Colab", use_container_width=True):
                    export_to_colab()
        
        # Pied de page
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; font-size: 0.8em; color: #666;">
            <p>Analyser IA v1.0.0</p>
            <p>D√©velopp√© avec ‚ù§Ô∏è par Sidoine YEBADOKPO</p>
            <p>¬© 2025 Tous droits r√©serv√©s</p>
        </div>
        """, unsafe_allow_html=True)

# ============================================
# 4. √âcrans de l'application
# ============================================

def render_context_step():
    with st.container():
        st.subheader("üéØ Contexte et Objectifs de l'Analyse")
        
        # Section pour les informations de base
        col1, col2 = st.columns(2)
        with col1:
            project_name = st.text_input("Nom du projet", 
                                      value=st.session_state.get('project_name', ''),
                                      help="Donnez un nom √† votre projet d'analyse")
            
        with col2:
            industry = st.selectbox(
                "Secteur d'activit√©",
                options=["S√©lectionner...", "Commerce de d√©tail", "Sant√©", "Finance", "√âducation", 
                         "Technologie", "Manufacture", "Services", "Autre"],
                index=0 if not st.session_state.get('industry') else 
                     ["S√©lectionner...", "Commerce de d√©tail", "Sant√©", "Finance", "√âducation", 
                     "Technologie", "Manufacture", "Services", "Autre"].index(st.session_state.get('industry', 'S√©lectionner...')),
                key="industry_select"
            )
        
        # Description d√©taill√©e du contexte et des objectifs
        context_objectif = st.text_area(
            "D√©crivez en d√©tail le contexte de votre analyse et vos objectifs :",
            placeholder="Ex: Analyse des ventes trimestrielles 2023. Objectifs: 1) Identifier les tendances mensuelles, 2) Comprendre les facteurs influen√ßant les ventes, 3) Pr√©dire les ventes pour le prochain trimestre.",
            height=200,
            value=st.session_state.get('context_objectif', '')
        )
        
        # Section pour les hypoth√®ses et contraintes
        with st.expander("Hypoth√®ses et contraintes (optionnel)"):
            hypotheses = st.text_area(
                "Hypoth√®ses de travail :",
                placeholder="Ex: Les tendances pass√©es sont repr√©sentatives des tendances futures. Les donn√©es sont compl√®tes et exactes.",
                height=100,
                value=st.session_state.get('hypotheses', '')
            )
            
            constraints = st.text_area(
                "Contraintes connues :",
                placeholder="Ex: Donn√©es manquantes pour certains mois. Limitation des donn√©es √† la r√©gion Europe.",
                height=100,
                value=st.session_state.get('constraints', '')
            )
        
        # Boutons de navigation
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("Valider et continuer", type="primary", use_container_width=True):
                if not context_objectif.strip():
                    st.warning("Veuillez fournir une description du contexte et des objectifs.")
                else:
                    # Sauvegarde des informations dans la session
                    st.session_state["project_name"] = project_name
                    st.session_state["industry"] = industry if industry != "S√©lectionner..." else ""
                    st.session_state["context_objectif"] = context_objectif
                    st.session_state["hypotheses"] = hypotheses
                    st.session_state["constraints"] = constraints
                    
                    # G√©n√©ration de suggestions d'analyse bas√©es sur le contexte
                    with st.spinner("Pr√©paration des suggestions d'analyse..."):
                        # G√©n√©ration des suggestions avec l'IA
                        # R√©cup√©rer les noms de colonnes du DataFrame si disponible
                        df_columns = []
                        if 'df' in st.session_state and st.session_state.df is not None:
                            df_columns = list(st.session_state.df.columns)
                        
                        prompt = f"""
                        En tant qu'expert en analyse de donn√©es, g√©n√®re 10 suggestions d'analyses pertinentes 
                        bas√©es sur le contexte suivant :
                        
                        Projet: {project_name}
                        Secteur: {industry}
                        Objectifs: {context_objectif}
                        
                        Pour chaque suggestion, fournis :
                        1. Un titre court et descriptif
                        2. Les variables √† utiliser (si des colonnes sont disponibles)
                        3. Le type d'analyse recommand√© (statistique, visualisation, etc.)
                        4. La m√©thodologie √† suivre
                        
                        Format de sortie attendu pour chaque suggestion :
                        - **Titre** : [Titre de l'analyse]
                          **Variables** : [liste des variables]
                          **Type** : [type d'analyse]
                          **M√©thodologie** : [description d√©taill√©e de la m√©thode √† suivre]
                        
                        Colonnes disponibles : {', '.join(df_columns) if df_columns else 'Aucune donn√©e charg√©e'}
                        """
                        
                        try:
                            response = call_gemini_api(prompt)
                            # Nettoyer et formater la r√©ponse
                            if response:
                                # Traitement des suggestions avec le nouveau format
                                suggestions = []
                                current_suggestion = {}
                                
                                lines = [line.strip() for line in response.split('\n') if line.strip()]
                                
                                for line in lines:
                                    if line.startswith('- **Titre** :'):
                                        if current_suggestion:  # Sauvegarder la suggestion pr√©c√©dente
                                            suggestions.append(current_suggestion)
                                        current_suggestion = {'title': line.replace('- **Titre** :', '').strip()}
                                    elif line.startswith('**Variables** :') and current_suggestion:
                                        current_suggestion['variables'] = line.replace('**Variables** :', '').strip()
                                    elif line.startswith('**Type** :') and current_suggestion:
                                        current_suggestion['type'] = line.replace('**Type** :', '').strip()
                                    elif line.startswith('**M√©thodologie** :') and current_suggestion:
                                        current_suggestion['methodology'] = line.replace('**M√©thodologie** :', '').strip()
                                    elif current_suggestion and 'methodology' in current_suggestion:
                                        # Ajouter des lignes suppl√©mentaires √† la m√©thodologie
                                        current_suggestion['methodology'] += '\n' + line
                                
                                # Ajouter la derni√®re suggestion si elle existe
                                if current_suggestion:
                                    suggestions.append(current_suggestion)
                                
                                # Limiter √† 10 suggestions et filtrer les entr√©es vides
                                st.session_state.analysis_suggestions = [s for s in suggestions[:10] if isinstance(s, dict) and s.get('title')]
                                
                                if st.session_state.analysis_suggestions:
                                    st.toast("Suggestions d'analyse g√©n√©r√©es avec succ√®s !")
                                else:
                                    st.warning("Le format des suggestions n'est pas reconnu. Utilisation du format texte.")
                                    # Fallback: utiliser le texte brut si le format structur√© √©choue
                                    st.session_state.analysis_suggestions = [s.strip() for s in response.split('\n') 
                                                                           if s.strip() and len(s.strip()) > 10][:10]
                            else:
                                st.warning("Aucune suggestion n'a pu √™tre g√©n√©r√©e.")
                                st.session_state.analysis_suggestions = []
                            
                        except Exception as e:
                            st.error(f"Erreur lors de la g√©n√©ration des suggestions : {str(e)}")
                            st.exception(e)  # Afficher plus de d√©tails sur l'erreur
                            st.session_state.analysis_suggestions = []
                    
                        st.session_state["step"] = 1
                        st.rerun()
        
        with col2:
            if st.button("Passer cette √©tape", use_container_width=True):
                st.session_state["step"] = 1
                st.rerun()
                
        # Aper√ßu des informations saisies
        if project_name or context_objectif:
            with col3:
                with st.expander("Aper√ßu du contexte"):
                    st.caption("Voici comment ces informations seront utilis√©es :")
                    if project_name:
                        st.markdown(f"**Projet :** {project_name}")
                    if industry and industry != "S√©lectionner...":
                        st.markdown(f"**Secteur :** {industry}")
                    if context_objectif:
                        st.markdown("**Objectifs :**")
                        st.caption(context_objectif[:200] + ("..." if len(context_objectif) > 200 else ""))

def render_join_interface():
    """Affiche l'interface de jointure de tables."""
    st.subheader("üîó Jointure de tables")
    
    if st.session_state.df_clean is None:
        st.warning("Veuvez d'abord charger et nettoyer vos donn√©es principales.")
        return
        
    # Section pour charger une deuxi√®me table
    st.markdown("### Charger une deuxi√®me table")
    
    # Options de source pour la deuxi√®me table (similaire √† render_loading_step)
    source_choice = st.radio(
        "Source de la deuxi√®me table",
        ["Fichier local", "URL (CSV/Excel)", "Exemple de jeu de donn√©es"],
        horizontal=True
    )
    
    uploaded = None
    data_url = None
    example_choice = None
    
    with st.form("load_secondary_data_form"):
        if source_choice == "Fichier local":
            uploaded = st.file_uploader(
                "üìÇ Charger un deuxi√®me fichier",
                type=["csv", "xlsx", "xls", "json", "parquet"],
                key="secondary_uploader"
            )
        elif source_choice == "URL (CSV/Excel)":
            data_url = st.text_input("URL du deuxi√®me fichier")
        else:  # Exemple de jeu de donn√©es
            example_datasets = {
                'Iris': 'iris',
                'Titanic': 'titanic',
                'Diamants': 'diamonds'
            }
            example_choice = st.selectbox(
                "S√©lectionnez un exemple de jeu de donn√©es",
                options=list(example_datasets.keys())
            )
            
        if st.form_submit_button("Charger la deuxi√®me table"):
            try:
                df_secondary = None
                
                if uploaded is not None:
                    # Chargement du fichier t√©l√©vers√©
                    if uploaded.name.endswith('.csv'):
                        df_secondary = pd.read_csv(uploaded)
                    elif uploaded.name.endswith(('.xlsx', '.xls')):
                        df_secondary = pd.read_excel(uploaded)
                    elif uploaded.name.endswith('.json'):
                        df_secondary = pd.read_json(uploaded, lines=True)
                    elif uploaded.name.endswith('.parquet'):
                        df_secondary = pd.read_parquet(uploaded, engine='pyarrow')
                        
                elif data_url:
                    # Chargement depuis URL
                    if data_url.endswith('.csv'):
                        df_secondary = pd.read_csv(data_url)
                    elif data_url.endswith(('.xlsx', '.xls')):
                        df_secondary = pd.read_excel(data_url)
                    elif data_url.endswith('.json'):
                        df_secondary = pd.read_json(data_url, lines=True)
                    else:
                        df_secondary = pd.read_csv(data_url)  # Essayer CSV par d√©faut
                        
                elif example_choice:
                    # Chargement d'un exemple
                    dataset_name = example_datasets[example_choice]
                    url = f"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/{dataset_name}.csv"
                    df_secondary = pd.read_csv(url)
                
                if df_secondary is not None:
                    st.session_state.df_secondary = df_secondary
                    st.success(f"Deuxi√®me table charg√©e avec succ√®s ! {df_secondary.shape[0]} lignes et {df_secondary.shape[1]} colonnes.")
                    
                    # Afficher un aper√ßu
                    st.dataframe(df_secondary.head())
                    
                    # D√©tection automatique des colonnes communes pour la jointure
                    common_columns = list(set(st.session_state.df_clean.columns) & set(df_secondary.columns))
                    if common_columns:
                        st.session_state.join_columns = common_columns
                        st.session_state.join_type = 'inner'
                        st.info(f"Colonnes communes d√©tect√©es : {', '.join(common_columns)}")
                else:
                    st.warning("Aucune donn√©e n'a pu √™tre charg√©e.")
                    
            except Exception as e:
                st.error(f"Erreur lors du chargement de la deuxi√®me table : {str(e)}")
    
    # Section pour configurer la jointure
    if st.session_state.df_secondary is not None:
        st.markdown("### Configurer la jointure")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # S√©lection des colonnes de jointure
            all_columns = list(set(st.session_state.df_clean.columns) | set(st.session_state.df_secondary.columns))
            st.session_state.join_columns = st.multiselect(
                "Colonnes de jointure",
                options=all_columns,
                default=st.session_state.get('join_columns', []),
                help="S√©lectionnez les colonnes communes pour la jointure"
            )
        
        with col2:
            # Type de jointure
            st.session_state.join_type = st.selectbox(
                "Type de jointure",
                ['inner', 'left', 'right', 'outer'],
                index=['inner', 'left', 'right', 'outer'].index(st.session_state.get('join_type', 'inner')),
                help="Type de jointure √† effectuer"
            )
        
        # Bouton pour effectuer la jointure
        if st.button("üîó Effectuer la jointure", type="primary"):
            if not st.session_state.join_columns:
                st.error("Veuvez s√©lectionner au moins une colonne de jointure.")
            else:
                with st.spinner("Jointure des tables en cours..."):
                    joined_df = join_dataframes(
                        st.session_state.df_clean,
                        st.session_state.df_secondary,
                        st.session_state.join_columns,
                        st.session_state.join_type
                    )
                    
                    if joined_df is not None:
                        st.session_state.df_joined = joined_df
                        st.session_state.df_clean = joined_df  # Remplacer les donn√©es principales par le r√©sultat de la jointure
                        st.success(f"Jointure r√©ussie ! {joined_df.shape[0]} lignes et {joined_df.shape[1]} colonnes.")
                        
                        # Afficher un aper√ßu du r√©sultat
                        st.dataframe(joined_df.head())
                        
                        # Mettre √† jour l'√©tat
                        st.session_state.data_loaded = True
                        st.session_state.data_cleaned = True
                        st.rerun()

def render_loading_step():
    """Affiche l'interface de chargement des donn√©es (√©tape 1)."""
    st.header("1Ô∏è‚É£ Chargement des donn√©es")
    
    # Afficher le contexte et les objectifs
    with st.expander("üìã Voir le contexte et les objectifs"):
        st.markdown(f"**Contexte et Objectifs :** {st.session_state.get('context_objectif', 'Non d√©fini')}")

    # S√©lection de la source
    source_choice = st.radio(
        "Source des donn√©es",
        ["Fichier local", "URL (CSV/Excel)", "Google Sheets", "Base de donn√©es", "Exemple de jeu de donn√©es"],
        horizontal=True
    )

    uploaded = None
    data_url = None
    gs_url = None
    sheet_name_input = None
    db_connection_string = None
    example_choice = None
    
    # D√©finir les exemples de jeux de donn√©es
    example_datasets = {
        'Iris': 'iris',
        'Titanic': 'titanic',
        'Diamants': 'diamonds',
        'Tips': 'tips',
        'MPG': 'mpg'
    }

    with st.form("load_data_form"):
        if source_choice == "Fichier local":
            uploaded = st.file_uploader(
                "üìÇ Charger un fichier (CSV / Excel / JSON / Parquet)",
                type=["csv", "xlsx", "xls", "json", "parquet"],
                help="Taille maximale : 200 Mo"
            )
        elif source_choice == "URL (CSV/Excel)":
            data_url = st.text_input("Ins√©rez l'URL du fichier CSV / Excel / JSON")
        elif source_choice == "Google Sheets":
            gs_url = st.text_input("Lien ou ID Google Sheets")
            sheet_name_input = st.text_input("Nom de l'onglet (optionnel)") or 0
        elif source_choice == "Base de donn√©es":
            db_connection_string = st.text_input("Cha√Æne de connexion √† la base de donn√©es", type="password")
            query = st.text_area("Requ√™te SQL pour extraire les donn√©es")
        elif source_choice == "Exemple de jeu de donn√©es":
            example_choice = st.selectbox(
                "S√©lectionnez un exemple de jeu de donn√©es",
                options=list(example_datasets.keys())
            )

        submit_col1, submit_col2 = st.columns([1, 1])
        with submit_col1:
            submit_button = st.form_submit_button("Charger les donn√©es")
        
        if submit_button:
            try:
                if uploaded is not None:
                    # Chargement du fichier t√©l√©vers√©
                    try:
                        # R√©initialiser la position du fichier
                        uploaded.seek(0)
                        
                        # Chargement selon le type de fichier
                        if uploaded.name.endswith('.csv'):
                            df = pd.read_csv(uploaded)
                        elif uploaded.name.endswith(('.xlsx', '.xls')):
                            df = pd.read_excel(uploaded)
                        elif uploaded.name.endswith('.json'):
                            df = pd.read_json(uploaded, lines=True)
                        elif uploaded.name.endswith('.parquet'):
                            df = pd.read_parquet(uploaded, engine='pyarrow')
                        
                        st.session_state.df_raw = df
                        st.session_state.df_clean = df.copy()
                        st.session_state.data_loaded = True
                        st.success(f"Donn√©es charg√©es avec succ√®s ! {df.shape[0]} lignes et {df.shape[1]} colonnes.")
                        
                        # Afficher un aper√ßu des donn√©es
                        st.dataframe(df.head())
                        
                        # Passer √† l'√©tape de nettoyage
                        st.session_state.step = 2
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors du chargement du fichier : {str(e)}")
                        st.error("D√©tails techniques : " + traceback.format_exc())
                
                elif data_url and source_choice == "URL (CSV/Excel)":
                    # Chargement depuis une URL
                    try:
                        if data_url.endswith('.csv'):
                            df = pd.read_csv(data_url)
                        elif data_url.endswith(('.xlsx', '.xls')):
                            df = pd.read_excel(data_url)
                        elif data_url.endswith('.json'):
                            df = pd.read_json(data_url, lines=True)
                        else:
                            # Essayer de charger en tant que CSV par d√©faut
                            df = pd.read_csv(data_url)
                            
                        st.session_state.df_raw = df
                        st.session_state.df_clean = df.copy()
                        st.session_state.data_loaded = True
                        st.success(f"Donn√©es charg√©es depuis l'URL avec succ√®s ! {df.shape[0]} lignes et {df.shape[1]} colonnes.")
                        
                        # Afficher un aper√ßu des donn√©es
                        st.dataframe(df.head())
                        
                        # Passer √† l'√©tape de nettoyage
                        st.session_state.step = 2
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors du chargement depuis l'URL : {str(e)}")
                        st.error("D√©tails techniques : " + traceback.format_exc())
                        
                elif example_choice and source_choice == "Exemple de jeu de donn√©es":
                    # Chargement d'un exemple de jeu de donn√©es
                    try:
                        dataset_name = example_datasets[example_choice]
                        if 'example_datasets' in assets and dataset_name in assets['example_datasets']:
                            df = assets['example_datasets'][dataset_name].copy()
                        else:
                            # T√©l√©chargement depuis une URL si pas dans le cache
                            url = f"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/{dataset_name}.csv"
                            df = pd.read_csv(url)
                        
                        st.session_state.df_raw = df
                        st.session_state.df_clean = df.copy()
                        st.session_state.data_loaded = True
                        st.success(f"Jeu de donn√©es '{example_choice}' charg√© avec succ√®s ! {df.shape[0]} lignes et {df.shape[1]} colonnes.")
                        
                        # Afficher un aper√ßu des donn√©es
                        st.dataframe(df.head())
                        
                        # Passer √† l'√©tape de nettoyage
                        st.session_state.step = 2
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors du chargement de l'exemple : {str(e)}")
                        st.error("D√©tails techniques : " + traceback.format_exc())
                else:
                    st.warning("Veuillez s√©lectionner un fichier, une URL ou un exemple de jeu de donn√©es.")
                    
            except Exception as e:
                st.error("Une erreur inattendue est survenue : " + str(e))
                st.error("D√©tails techniques : " + traceback.format_exc())

    # Aper√ßu rapide si des donn√©es sont charg√©es
    if st.session_state.df_raw is not None:
        tab1, tab2, tab3 = st.tabs(["Donn√©es brutes", "R√©sum√© des variables", "Jointure de tables"])
        
        with tab1:
            st.subheader("Aper√ßu des donn√©es brutes")
            st.dataframe(st.session_state.df_raw.head())
        
        with tab2:
            st.subheader("R√©sum√© des variables")
            st.dataframe(pd.DataFrame({
                'Variable': st.session_state.df_raw.columns,
                'Type': st.session_state.df_raw.dtypes.astype(str).values,
                'Valeurs manquantes': st.session_state.df_raw.isna().sum().values,
                'Valeurs uniques': st.session_state.df_raw.nunique().values,
                'Exemple': st.session_state.df_raw.iloc[0].values if len(st.session_state.df_raw) > 0 else [None] * len(st.session_state.df_raw.columns)
            }), use_container_width=True)
            
            # Visualisation rapide
            st.subheader("Visualisation rapide")
            numeric_cols = st.session_state.df_raw.select_dtypes(include=['number']).columns.tolist()
            if numeric_cols:
                selected_col = st.selectbox("S√©lectionnez une colonne num√©rique", numeric_cols)
        
        with tab3:
            render_join_interface()
            st.plotly_chart(histogram(st.session_state.df_raw, selected_col), use_container_width=True)

def render_cleaning_step():
    st.title("üîß Nettoyage des donn√©es")
    
    if 'df_clean' not in st.session_state or st.session_state.df_clean is None:
        st.warning("Veuillez d'abord charger des donn√©es dans l'√©tape pr√©c√©dente.")
        return
    
    st.markdown("""
    ## Nettoyage des donn√©es
    
    Dans cette section, vous pouvez nettoyer vos donn√©es en appliquant diff√©rentes transformations.
    """)
    
    # Section de s√©lection des colonnes √† conserver
    st.markdown("### S√©lection des colonnes √† conserver")
    
    # V√©rifier si des donn√©es sont disponibles
    if st.session_state.df_clean is not None and not st.session_state.df_clean.empty:
        # Calculer le pourcentage de valeurs manquantes par colonne
        missing_percent = (st.session_state.df_clean.isnull().sum() / len(st.session_state.df_clean)) * 100
        
        # Cr√©er un DataFrame pour l'affichage
        columns_info = []
        for col in st.session_state.df_clean.columns:
            col_info = {
                'Colonne': col,
                'Type': str(st.session_state.df_clean[col].dtype),
                'Valeurs uniques': st.session_state.df_clean[col].nunique(),
                '% Valeurs manquantes': round(missing_percent[col], 2)
            }
            columns_info.append(col_info)
        
        # Afficher le tableau des colonnes avec des cases √† cocher
        df_columns_info = pd.DataFrame(columns_info)
        
        # Ajouter une colonne de s√©lection
        df_columns_info['Conserver'] = True  # Par d√©faut, toutes les colonnes sont s√©lectionn√©es
        
        # Afficher le tableau avec des cases √† cocher
        edited_df = st.data_editor(
            df_columns_info,
            column_config={
                "Conserver": st.column_config.CheckboxColumn(
                    "Conserver",
                    help="D√©cochez pour exclure cette colonne de l'analyse",
                    default=True,
                )
            },
            hide_index=True,
            use_container_width=True,
            key="columns_selector"
        )
        
        # Appliquer les modifications
        if st.button("Appliquer la s√©lection des colonnes", type="primary"):
            try:
                # R√©cup√©rer les colonnes s√©lectionn√©es
                selected_columns = edited_df[edited_df['Conserver']]['Colonne'].tolist()
                
                # Si aucune colonne n'est s√©lectionn√©e, garder toutes les colonnes
                if not selected_columns:
                    selected_columns = st.session_state.df_clean.columns.tolist()
                
                # Filtrer le DataFrame pour ne garder que les colonnes s√©lectionn√©es
                st.session_state.df_clean = st.session_state.df_clean[selected_columns]
                
                # Supprimer les colonnes avec 100% de valeurs manquantes
                cols_to_drop = st.session_state.df_clean.columns[st.session_state.df_clean.isnull().all()].tolist()
                if cols_to_drop:
                    st.session_state.df_clean = st.session_state.df_clean.drop(columns=cols_to_drop)
                    st.warning(f"Les colonnes suivantes ont √©t√© supprim√©es car elles √©taient vides: {', '.join(cols_to_drop)}")
                
                st.success(f"{len(selected_columns)} colonnes ont √©t√© conserv√©es pour l'analyse.")
                
                # Afficher un aper√ßu des donn√©es
                st.subheader("Aper√ßu des donn√©es apr√®s s√©lection")
                st.dataframe(st.session_state.df_clean.head(), use_container_width=True)
                
            except Exception as e:
                st.error(f"Une erreur s'est produite lors de l'application des modifications: {e}")
                st.exception(e)
    
    st.markdown("---")  # Ligne de s√©paration
    st.markdown("### Autres options de nettoyage")

    # Configuration avanc√©e
    with st.expander("‚öôÔ∏è Configuration avanc√©e", expanded=False):
        st.markdown("### Param√®tres de nettoyage")

        # Options de gestion des valeurs manquantes
        st.markdown("#### Valeurs manquantes")
        missing_threshold = st.slider(
            "Seuil de suppression des colonnes avec trop de valeurs manquantes (%)",
            min_value=0,
            max_value=100,
            value=30,
            help="Supprime les colonnes avec plus de X% de valeurs manquantes"
        )

        # Options de conversion de type
        st.markdown("#### Conversion de type")
        st.checkbox(
            "Convertir automatiquement les colonnes num√©riques stock√©es comme texte",
            value=True,
            key="auto_convert_numeric"
        )

        # Options de normalisation
        st.markdown("#### Normalisation")
        st.checkbox(
            "Normaliser les colonnes cat√©gorielles (trim, lowercase)",
            value=True,
            key="normalize_categorical"
        )

    # Aper√ßu avant/apr√®s
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Donn√©es brutes")
        st.dataframe(st.session_state.df_raw.head())

    with col2:
        st.subheader("Donn√©es nettoy√©es")
        st.dataframe(st.session_state.df_clean.head())

    # D√©tection automatique des probl√®mes
    st.subheader("üîç Probl√®mes d√©tect√©s")
    
    # 1. Valeurs manquantes
    missing_cols = st.session_state.df_clean.columns[st.session_state.df_clean.isna().any()].tolist()
    if missing_cols:
        with st.expander("üîç Valeurs manquantes d√©tect√©es", expanded=True):
            st.write(f"Colonnes avec valeurs manquantes: {', '.join(missing_cols)}")

            for col in missing_cols:
                missing_pct = st.session_state.df_clean[col].isna().mean() * 100
                st.write(f"- **{col}**: {missing_pct:.1f}% de valeurs manquantes")

                # Suggestions de nettoyage
                col1, col2 = st.columns([3, 1])
                with col1:
                    action = st.selectbox(
                        f"Action pour '{col}':",
                        ["Ne rien faire", "Supprimer les lignes", "Remplacer par la moyenne/m√©diane",
                         "Remplir avec une valeur", "Remplir avec la valeur pr√©c√©dente/suivante"],
                        key=f"missing_{col}"
                    )
                with col2:
                    if action == "Remplir avec une valeur":
                        fill_value = st.text_input("Valeur", key=f"fill_{col}")
                    elif action == "Remplacer par la moyenne/m√©diane":
                        method = st.radio("M√©thode", ["Moyenne", "M√©diane"], key=f"method_{col}", horizontal=True)

    # 2. Colonnes dupliqu√©es
    duplicated_cols = st.session_state.df_clean.T.duplicated().sum()
    if duplicated_cols > 0:
        with st.expander(f"‚ö†Ô∏è {duplicated_cols} colonnes dupliqu√©es d√©tect√©es"):
            st.warning("Des colonnes dupliqu√©es ont √©t√© d√©tect√©es. Vous devriez les supprimer.")
            if st.button("Supprimer les colonnes dupliqu√©es"):
                st.session_state.df_clean = st.session_state.df_clean.T.drop_duplicates().T
                st.rerun()

    # 3. Valeurs aberrantes
    with st.expander("üìä D√©tection des valeurs aberrantes", expanded=False):
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
        if numeric_cols:
            selected_col = st.selectbox("S√©lectionnez une colonne num√©rique", numeric_cols)
            st.plotly_chart(boxplot(st.session_state.df_clean, selected_col), use_container_width=True)

            # Options de traitement des valeurs aberrantes
            col1, col2 = st.columns(2)
            with col1:
                outlier_method = st.selectbox(
                    "M√©thode de traitement",
                    ["Ne rien faire", "Supprimer les valeurs aberrantes", "Remplacer par la m√©diane",
                     "Winsorization (√©cr√™tage)"],
                    key=f"outlier_{selected_col}"
                )
            with col2:
                if outlier_method == "Winsorization (√©cr√™tage)":
                    quantile = st.slider("Quantile pour l'√©cr√™tage", 0.01, 0.1, 0.05, key=f"quantile_{selected_col}")

    # 4. Incoh√©rences de format
    with st.expander("üî§ Incoh√©rences de format", expanded=False):
        date_cols = st.session_state.df_clean.select_dtypes(include=['datetime64']).columns.tolist()
        if date_cols:
            st.write("Colonnes de date d√©tect√©es:", ", ".join(date_cols))
        else:
            st.warning("Aucune colonne de date d√©tect√©e automatiquement.")

        # D√©tection des colonnes qui pourraient √™tre des dates (version plus robuste)
        potential_date_cols = []
        for col in st.session_state.df_clean.select_dtypes(include=['object']).columns:
            try:
                # V√©rifier si la colonne contient des dates dans un format commun
                sample = st.session_state.df_clean[col].dropna().astype(str).sample(min(10, len(st.session_state.df_clean)))
                date_matches = sample.str.contains(
                    r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}|\d{4}[-/]\d{1,2}[-/]\d{1,2}'
                )
                if date_matches.any():
                    potential_date_cols.append(col)
            except Exception as e:
                st.warning(f"Impossible de v√©rifier la colonne {col} pour des dates: {str(e)}")

        if potential_date_cols:
            st.write("Colonnes qui pourraient √™tre des dates:", ", ".join(potential_date_cols))
            for col in potential_date_cols:
                col1, col2 = st.columns([2, 1])
                with col1:
                    date_format = st.text_input(
                        f"Format de date pour '{col}' (ex: %d/%m/%Y, %Y-%m-%d, %m/%d/%Y, etc.)",
                        value="%d/%m/%Y"
                    )
                with col2:
                    st.write("<div style='margin-top: 1.5rem;'></div>", unsafe_allow_html=True)
                    if st.button(f"Convertir '{col}' en date"):
                        try:
                            # Essayer de convertir avec le format sp√©cifi√©
                            st.session_state.df_clean[col] = pd.to_datetime(
                                st.session_state.df_clean[col], 
                                format=date_format,
                                errors='coerce'  # Convertit les erreurs en NaT au lieu de lever une exception
                            )
                            
                            # V√©rifier si la conversion a r√©ussi pour au moins certaines valeurs
                            if st.session_state.df_clean[col].notna().any():
                                st.success(f"Colonne '{col}' convertie en date avec succ√®s!")
                                st.rerun()
                            else:
                                st.error("Aucune date valide trouv√©e avec ce format. Essayez un format diff√©rent.")
                        except Exception as e:
                            st.error(f"Erreur lors de la conversion: {str(e)}")
                            st.warning("Essayez un format diff√©rent ou v√©rifiez les donn√©es.")

    # Boutons de navigation
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        if st.button("‚Üê Retour au chargement", use_container_width=True):
            st.session_state.step = 1
            st.rerun()
    with col2:
        if st.button("R√©initialiser le nettoyage", use_container_width=True):
            st.session_state.df_clean = st.session_state.df_raw.copy()
            st.rerun()
    with col3:
        if st.button("Valider le nettoyage ‚Üí", type="primary", use_container_width=True):
            # Appliquer les √©tapes de nettoyage s√©lectionn√©es
            st.session_state.step = 3  # Passe √† l'√©tape d'analyse
            st.rerun()

def render_analysis_step():
    """Affiche l'interface d'analyse des donn√©es (√©tape 3)."""
    st.header("3Ô∏è‚É£ Analyse des donn√©es")

    if st.session_state.df_clean is None:
        st.warning("Aucune donn√©e nettoy√©e disponible. Revenez √† l'√©tape 2.")
        if st.button("‚Üê Retour au nettoyage"):
            st.session_state.step = 2
            st.rerun()
    else:
        # Bouton de t√©l√©chargement Excel
        from analyser_ia.app.utils.helpers import get_excel_download_link
        
        # G√©n√©rer un nom de fichier avec horodatage
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"donnees_analyse_{timestamp}.xlsx"
        
        # Afficher le bouton de t√©l√©chargement
        st.markdown("### T√©l√©chargement des donn√©es")
        st.markdown("T√©l√©chargez les donn√©es nettoy√©es au format Excel :")
        st.markdown(
            get_excel_download_link(
                st.session_state.df_clean,
                filename=filename,
                button_text="üìä T√©l√©charger les donn√©es Excel"
            ),
            unsafe_allow_html=True
        )
        st.markdown("---")  # S√©parateur visuel
        # Panneau de configuration
        with st.expander("‚öôÔ∏è Configuration de l'analyse", expanded=False):
            st.markdown("### Param√®tres d'analyse")

            # Configuration des analyses
            st.markdown("#### Types d'analyses √† effectuer")
            analysis_types = st.multiselect(
                "S√©lectionnez les types d'analyses √† effectuer",
                ["Statistiques descriptives", "Corr√©lations", "Clustering", "Analyse temporelle",
                 "Analyse de tendances", "Mod√©lisation pr√©dictive"],
                default=["Statistiques descriptives", "Corr√©lations"],
                key="selected_analysis_types"
            )

            # Param√®tres de l'IA
            st.markdown("#### Param√®tres IA")
            col1, col2 = st.columns(2)

            with col1:
                st.selectbox(
                    "Mod√®le d'IA",
                    ["GPT-4", "GPT-3.5", "Claude", "Gemini"],
                    index=0,
                    key="ai_model"
                )

            with col2:
                st.slider(
                    "Niveau de d√©tail",
                    min_value=1,
                    max_value=5,
                    value=3,
                    help="Niveau de d√©tail des analyses g√©n√©r√©es",
                    key="detail_level"
                )

            # Param√®tres d'export
            st.markdown("#### Options d'export")
            export_col1, export_col2 = st.columns(2)

            with export_col1:
                st.checkbox(
                    "Inclure les donn√©es brutes",
                    value=True,
                    key="include_raw_data_export"
                )

                st.checkbox(
                    "G√©n√©rer un sommaire",
                    value=True,
                    key="generate_summary"
                )

            with export_col2:
                st.checkbox(
                    "Inclure les graphiques",
                    value=True,
                    key="include_charts"
                )

                st.checkbox(
                    "Inclure le code source",
                    value=False,
                    key="include_source_code"
                )

            # Param√®tres de s√©curit√©
            st.markdown("#### Param√®tres de s√©curit√©")
            security_col1, security_col2 = st.columns(2)

            with security_col1:
                st.checkbox(
                    "Validation manuelle requise",
                    value=True,
                    help="N√©cessite une validation manuelle avant l'ex√©cution des requ√™tes",
                    key="require_manual_approval"
                )

            with security_col2:
                st.checkbox(
                    "Limiter les r√©sultats",
                    value=True,
                    help="Limite le nombre de lignes retourn√©es par les requ√™tes",
                    key="limit_query_results"
                )

            # Bouton de sauvegarde de la configuration
            if st.button("üíæ Enregistrer la configuration", key="save_config_btn"):
                st.session_state.config_saved = True
                st.success("Configuration enregistr√©e avec succ√®s !")

        # Section pour les requ√™tes en langage naturel
        with st.expander("üí¨ Requ√™te en langage naturel", expanded=True):
            st.markdown("""
            <style>
            .stTextArea [data-baseweb="textarea"] {
                min-height: 100px;
            }
            </style>
            """, unsafe_allow_html=True)

            # Zone de texte pour la description
            user_query = st.text_area(
                "D√©crivez votre requ√™te ou analyse souhait√©e :",
                placeholder="Exemple : 'Trouve les 10 produits les plus vendus'",
                key="user_query_input"
            )

            # D√©finir le type de requ√™te par d√©faut
            query_type = "Python"
            
            # Boutons d'action
            col1, col2 = st.columns([1, 2])
            with col1:
                generate_btn = st.button(
                    "üîÑ G√©n√©rer le code",
                    key="generate_code_btn_natural",
                    help="G√©n√®re le code Python √† partir de votre description"
                )
                
            with col2:
                execute_btn = st.button(
                    "‚ñ∂Ô∏è Ex√©cuter",
                    key="execute_code_btn_natural",
                    disabled=not st.session_state.get('generated_code', False),
                    help="Ex√©cute le code g√©n√©r√©"
                )

            # G√©n√©ration du code
            if generate_btn and user_query.strip():
                with st.spinner("G√©n√©ration du code en cours..."):
                    try:
                        # R√©cup√©rer les colonnes du DataFrame
                        df_columns = st.session_state.df_clean.columns.tolist()

                        # G√©n√©rer le code
                        generated_code = generate_code_from_natural_language(
                            user_query,
                            query_type.lower(),
                            df_columns
                        )

                        if generated_code:
                            st.session_state.generated_code = generated_code
                            st.session_state.show_generated_code = True
                            st.success("Code g√©n√©r√© avec succ√®s !")
                        else:
                            st.warning("Impossible de g√©n√©rer le code. Veuillez reformuler votre demande.")

                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du code : {str(e)}")
                        st.exception(e)

            # Affichage du code g√©n√©r√©
            if st.session_state.get('show_generated_code', False) and 'generated_code' in st.session_state:
                st.markdown("### Code g√©n√©r√©")
                st.code(st.session_state.generated_code, language=query_type.lower())

                # Bouton pour copier le code
                st.download_button(
                    label="üìã Copier le code",
                    data=st.session_state.generated_code,
                    file_name=f"generated_code.{query_type.lower()}",
                    mime="text/plain"
                )

            # Ex√©cution du code
            if execute_btn and st.session_state.get('generated_code'):
                with st.spinner("Ex√©cution en cours..."):
                    try:
                        if query_type == "SQL":
                            # Ex√©cuter la requ√™te SQL
                            result = sqldf(st.session_state.generated_code, {'df': st.session_state.df_clean})
                        else:
                            # Ex√©cuter le code Python
                            local_vars = {'df': st.session_state.df_clean}
                            exec(st.session_state.generated_code, globals(), local_vars)
                            result = local_vars.get('result', local_vars.get('df', None))

                        if result is not None:
                            st.session_state.last_query_result = result
                            st.success("Ex√©cution r√©ussie !")
                            
                            # Ajouter un s√©parateur visuel
                            st.markdown("---")
                            
                            # Afficher les r√©sultats selon leur type
                            if hasattr(result, 'head') and hasattr(result, 'to_csv'):
                                # Si c'est un DataFrame ou similaire
                                st.markdown("### üìä R√©sultats de l'analyse")
                                
                                # Afficher un aper√ßu des donn√©es
                                st.dataframe(result.head(100))  # Limiter √† 100 lignes
                                
                            elif isinstance(result, (dict, list, tuple, set)):
                                # Pour les types de collection standards
                                st.markdown("### üìã R√©sultat de l'ex√©cution")
                                st.json(result)  # Affiche le r√©sultat brut de mani√®re format√©e
                                
                            else:
                                # Pour tous les autres types (nombres, cha√Ænes, objets personnalis√©s, etc.)
                                st.markdown("### üìã R√©sultat de l'ex√©cution")
                                st.write("Type de r√©sultat :", type(result).__name__)
                                st.write(result)
                            
                            # Section d'interpr√©tation automatique
                            try:
                                st.markdown("---")
                                st.markdown("### üìù Interpr√©tation des r√©sultats")
                                
                                # Convertir le r√©sultat en DataFrame pour l'analyse si n√©cessaire
                                if hasattr(result, 'head') and hasattr(result, 'to_csv'):
                                    df_to_analyze = result
                                elif isinstance(result, dict):
                                    # Essayer de convertir le dict en DataFrame
                                    try:
                                        df_to_analyze = pd.DataFrame([result] if result else {})
                                    except:
                                        df_to_analyze = pd.DataFrame({'Valeur': [str(result)]})
                                elif isinstance(result, (list, tuple, set)) and result:
                                    # Essayer de convertir la liste en DataFrame
                                    try:
                                        df_to_analyze = pd.DataFrame(result)
                                    except:
                                        df_to_analyze = pd.DataFrame({'Valeurs': [str(x) for x in result]})
                                else:
                                    # Pour les types simples ou inconnus
                                    df_to_analyze = pd.DataFrame({'R√©sultat': [str(result)]})
                                
                                # G√©n√©rer et afficher l'interpr√©tation
                                interpretation = generate_interpretation(df_to_analyze)
                                st.markdown(interpretation)
                                
                            except Exception as e:
                                st.warning("Impossible de g√©n√©rer une interpr√©tation automatique des r√©sultats.")
                                st.error(f"Erreur: {str(e)}")
                            
                            # Section d'exportation
                            st.markdown("---")
                            st.markdown("### üíæ Exporter les r√©sultats")
                            
                            # Cr√©er des colonnes pour les boutons d'exportation
                            col1, col2, col3 = st.columns(3)
                            
                            # Fonction pour convertir n'importe quel r√©sultat en DataFrame
                            def convert_to_exportable(data):
                                try:
                                    if hasattr(data, 'to_frame'):
                                        return data.to_frame()
                                    elif isinstance(data, pd.DataFrame):
                                        return data
                                    elif isinstance(data, (dict, list, tuple, set)):
                                        return pd.DataFrame(data) if data else pd.DataFrame()
                                    else:
                                        # Pour les types simples (nombres, cha√Ænes, etc.)
                                        return pd.DataFrame({'R√©sultat': [data]})
                                except Exception as e:
                                    st.error(f"Erreur de conversion des donn√©es: {str(e)}")
                                    return None
                            
                            # Convertir le r√©sultat en DataFrame pour l'export
                            export_df = convert_to_exportable(result)
                            
                            # Colonne CSV
                            with col1:
                                try:
                                    if export_df is not None and not export_df.empty:
                                        csv = export_df.to_csv(index=False, encoding='utf-8-sig')
                                        st.download_button(
                                            label="üíæ CSV",
                                            data=csv,
                                            file_name="resultats_analyse.csv",
                                            mime="text/csv",
                                            help="T√©l√©charger au format CSV (UTF-8 avec BOM)"
                                        )
                                    else:
                                        st.info("CSV: Aucune donn√©e √† exporter")
                                except Exception as e:
                                    st.warning("Export CSV indisponible")
                                    st.error(f"Erreur: {str(e)}")
                            
                            # Colonne Excel
                            with col2:
                                try:
                                    if export_df is not None and not export_df.empty:
                                        excel_buffer = io.BytesIO()
                                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                            export_df.to_excel(writer, index=False, sheet_name='R√©sultats')
                                        
                                        st.download_button(
                                            label="üìä Excel",
                                            data=excel_buffer.getvalue(),
                                            file_name="resultats_analyse.xlsx",
                                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                            help="T√©l√©charger au format Excel"
                                        )
                                    else:
                                        st.info("Excel: Aucune donn√©e √† exporter")
                                except Exception as e:
                                    st.warning("Export Excel indisponible")
                                    st.error(f"Erreur: {str(e)}")
                            
                            # Colonne JSON
                            with col3:
                                try:
                                    if export_df is not None and not export_df.empty:
                                        # Essayer d'abord avec to_json si disponible
                                        if hasattr(export_df, 'to_json'):
                                            json_data = export_df.to_json(orient='records', force_ascii=False, indent=2)
                                        else:
                                            # Sinon convertir en dict puis en JSON
                                            json_data = json.dumps(export_df.to_dict(orient='records') 
                                                                if hasattr(export_df, 'to_dict') 
                                                                else export_df, 
                                                              indent=2, 
                                                              ensure_ascii=False,
                                                              default=str)
                                        
                                        st.download_button(
                                            label="üî§ JSON",
                                            data=json_data,
                                            file_name="resultats_analyse.json",
                                            mime="application/json",
                                            help="T√©l√©charger au format JSON"
                                        )
                                    else:
                                        # Pour les petits objets non-DataFrame
                                        try:
                                            json_data = json.dumps(result, indent=2, ensure_ascii=False, default=str)
                                            st.download_button(
                                                label="üî§ JSON",
                                                data=json_data,
                                                file_name="resultat_export.json",
                                                mime="application/json"
                                            )
                                        except:
                                            st.info("JSON: Aucune donn√©e √† exporter")
                                except Exception as e:
                                    st.warning("Export JSON indisponible")
                                    st.error(f"Erreur: {str(e)}")

                            # V√©rifier et initialiser custom_queries si n√©cessaire
                            if 'custom_queries' not in st.session_state:
                                st.session_state.custom_queries = []
                                
                            # V√©rifier que custom_queries est bien une liste
                            if not isinstance(st.session_state.custom_queries, list):
                                st.warning("R√©initialisation de la liste des requ√™tes personnalis√©es")
                                st.session_state.custom_queries = []
                            
                            # Ajouter aux requ√™tes personnalis√©es
                            try:
                                st.session_state.custom_queries.append({
                                    'type': query_type,
                                    'description': user_query if 'user_query' in locals() else 'Sans description',
                                    'code': st.session_state.get('generated_code', ''),
                                    'result': result.to_dict('records') if hasattr(result, 'to_dict') else str(result),
                                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                })
                            except Exception as e:
                                st.error(f"Erreur lors de l'enregistrement de la requ√™te : {str(e)}")
                                st.exception(e)

                    except Exception as e:
                        st.error(f"Erreur lors de l'ex√©cution du code : {str(e)}")
                        st.exception(e)

        # Section pour les analyses statistiques
        st.markdown("## üìä Analyse descriptive des donn√©es")
        
        # S√©lection des colonnes
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()

        # Onglets pour les diff√©rents types de variables
        tab1, tab2, tab3 = st.tabs([
            "Variables num√©riques", 
            "Variables cat√©gorielles",
            "Analyses avanc√©es"
        ])

        with tab1:
            if numeric_cols:
                selected_num_cols = st.multiselect(
                    "S√©lectionnez les variables num√©riques",
                    numeric_cols,
                    default=numeric_cols[:3]
                )

                if selected_num_cols:
                    st.markdown("### Statistiques descriptives")
                    
                    # Afficher le tableau des statistiques
                    stats_df = st.session_state.df_clean[selected_num_cols].describe().T
                    st.dataframe(stats_df)
                    
                    # Pour chaque variable s√©lectionn√©e
                    for col in selected_num_cols:
                        # Cr√©er un conteneur pour chaque variable
                        var_container = st.container()
                        with var_container:
                            # Calculer les statistiques d√©taill√©es
                            desc = st.session_state.df_clean[col].describe()
                            skewness = st.session_state.df_clean[col].skew()
                            
                            # Calculer les valeurs aberrantes
                            q1 = desc['25%']
                            q3 = desc['75%']
                            iqr = q3 - q1
                            lower_bound = q1 - 1.5 * iqr
                            upper_bound = q3 + 1.5 * iqr
                            outliers = st.session_state.df_clean[
                                (st.session_state.df_clean[col] < lower_bound) | 
                                (st.session_state.df_clean[col] > upper_bound)
                            ]
                            
                            # Afficher les m√©triques cl√©s
                            st.markdown("#### M√©triques cl√©s")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Moyenne", f"{desc['mean']:.2f}")
                                st.metric("M√©diane", f"{desc['50%']:.2f}")
                            with col2:
                                st.metric("√âcart-type", f"{desc['std']:.2f}")
                                st.metric("Min / Max", f"{desc['min']:.2f} / {desc['max']:.2f}")
                            with col3:
                                st.metric("Asym√©trie", f"{skewness:.2f}")
                                st.metric("Valeurs aberrantes", f"{len(outliers)}")
                            
                            # Interpr√©tation automatique
                            st.markdown("#### Interpr√©tation")
                            
                            # D√©crire la distribution
                            if abs(skewness) > 1:
                                skew_text = "fortement asym√©trique"
                            elif abs(skewness) > 0.5:
                                skew_text = "mod√©r√©ment asym√©trique"
                            else:
                                skew_text = "approximativement sym√©trique"
                            
                            skew_direction = "vers la droite" if skewness > 0 else "vers la gauche" if skewness < 0 else ""
                            
                            # Afficher l'interpr√©tation de base
                            st.markdown(f"- La distribution est **{skew_text}** {skew_direction}.")
                            st.markdown(f"- L'√©cart entre la moyenne ({desc['mean']:.2f}) et la m√©diane ({desc['50%']:.2f}) sugg√®re une distribution {'' if abs(desc['mean'] - desc['50%']) < 0.1 * desc['std'] else 'non '}sym√©trique.")
                            
                            if len(outliers) > 0:
                                st.warning(f"- **Attention** : {len(outliers)} valeurs aberrantes d√©tect√©es en dehors de l'intervalle [{lower_bound:.2f}, {upper_bound:.2f}].")
                            
                            # Bouton pour une analyse plus d√©taill√©e avec l'IA
                            if st.button(f"Analyse d√©taill√©e pour {col}"):
                                with st.spinner("G√©n√©ration de l'analyse..."):
                                    context = f"Analyse statistique d√©taill√©e de la variable {col}"
                                    data_desc = (
                                        f"- Type: Num√©rique\n"
                                        f"- Nombre d'observations: {int(desc['count'])}\n"
                                        f"- Moyenne: {desc['mean']:.2f}\n"
                                        f"- √âcart-type: {desc['std']:.2f}\n"
                                        f"- Minimum: {desc['min']:.2f}\n"
                                        f"- 25e percentile: {desc['25%']:.2f}\n"
                                        f"- M√©diane: {desc['50%']:.2f}\n"
                                        f"- 75e percentile: {desc['75%']:.2f}\n"
                                        f"- Maximum: {desc['max']:.2f}\n"
                                        f"- Coefficient d'asym√©trie: {skewness:.2f}\n"
                                        f"- Valeurs aberrantes: {len(outliers)} (en dehors de [{lower_bound:.2f}, {upper_bound:.2f}])"
                                    )
                                    
                                    interpretation = generate_ai_interpretation(
                                        context=context,
                                        data_description=data_desc,
                                        chart_type="descriptive_stats"
                                    )
                                    
                                    if interpretation:
                                        st.markdown("#### Analyse d√©taill√©e")
                                        st.markdown(interpretation)
                        
                        # G√©n√©rer et afficher l'interpr√©tation
                        if 'context' not in locals() or context is None:
                            context = f"Analyse statistique des variables num√©riques"
                        if 'data_desc' not in locals() or data_desc is None:
                            data_desc = "\n".join([
                                f"- {col}: {st.session_state.df_clean[col].describe().to_dict()}" 
                                for col in selected_num_cols
                            ])
                            
                        interpretation = generate_ai_interpretation(
                            context=context,
                            data_description=data_desc,
                            chart_type="table"
                        )
                        
                        if interpretation:
                            st.markdown("### Interpr√©tation des statistiques")
                            st.markdown(interpretation)

                        # Section pour les analyses crois√©es
                        if len(selected_num_cols) > 1:
                            st.markdown("### üîç Analyses crois√©es")
                            cross_col1, cross_col2 = st.columns(2)
                            
                            # Incr√©menter le compteur de widgets pour des cl√©s uniques
                            if 'widget_counter' not in st.session_state:
                                st.session_state.widget_counter = 0
                            st.session_state.widget_counter += 1
                            
                            # Cr√©er des cl√©s uniques pour les widgets
                            widget_suffix = f"_{st.session_state.widget_counter}"
                            
                            with cross_col1:
                                x_var = st.selectbox(
                                    "Variable X", 
                                    selected_num_cols, 
                                    key=f"x_var{widget_suffix}"
                                )
                            with cross_col2:
                                # Filtrer les variables pour √©viter de s√©lectionner la m√™me variable pour X et Y
                                y_options = [c for c in selected_num_cols if c != x_var]
                                y_var = st.selectbox(
                                    "Variable Y", 
                                    y_options,
                                    key=f"y_var{widget_suffix}"
                                )
                            
                            # Scatter plot pour l'analyse crois√©e
                            scatter_fig = scatter_plot(
                                st.session_state.df_clean,
                                x_col=x_var,
                                y_col=y_var,
                                title=f"Relation entre {x_var} et {y_var}"
                            )
                            st.plotly_chart(
                                scatter_fig, 
                                use_container_width=True, 
                                key=f"scatter_{x_var}_{y_var}{widget_suffix}"
                            )
                            
                            # Calcul de la corr√©lation
                            correlation = st.session_state.df_clean[[x_var, y_var]].corr().iloc[0,1]
                            st.metric(
                                "Coefficient de corr√©lation", 
                                f"{correlation:.2f}"
                            )
                            
                            # Bouton d'interpr√©tation avec une cl√© unique
                            if st.button(
                                "üîç Interpr√©ter la relation", 
                                key=f"btn_corr_{x_var}_{y_var}{widget_suffix}",
                                type="secondary"
                            ):
                                with st.spinner("Analyse de la relation..."):
                                    context = f"Relation entre {x_var} et {y_var}"
                                    data_desc = (
                                        f"Le coefficient de corr√©lation entre {x_var} et {y_var} est de {correlation:.2f}. "
                                        f"Cela indique une corr√©lation {'positive' if correlation > 0 else 'n√©gative' if correlation < 0 else 'nulle'}. "
                                        f"La force de la relation est {'forte' if abs(correlation) > 0.7 else 'mod√©r√©e' if abs(correlation) > 0.3 else 'faible'}."
                                    )
                                    interpretation = generate_ai_interpretation(
                                        context=context,
                                        data_description=data_desc,
                                        chart_type="scatter"
                                    )
                                    if interpretation:
                                        st.markdown("#### Interpr√©tation de la relation")
                                        st.markdown(interpretation)
                                                # Visualisations individuelles
                        st.markdown("### üìä Analyses univari√©es")
                        
                        # Incr√©menter le compteur de widgets pour des cl√©s uniques
                        if 'widget_counter' not in st.session_state:
                            st.session_state.widget_counter = 0
                            
                        for idx, col in enumerate(selected_num_cols):
                            # Incr√©menter le compteur pour chaque variable
                            st.session_state.widget_counter += 1
                            widget_suffix = f"_{st.session_state.widget_counter}"
                            
                            # Cr√©er une cl√© unique pour le toggle de la section
                            section_key = f"section_{col}{widget_suffix}"
                            
                            # G√©rer l'√©tat d'expansion avec une variable de session
                            if section_key not in st.session_state:
                                st.session_state[section_key] = idx < 2  # Par d√©faut, √©tendre les 2 premi√®res sections
                                
                            # Cr√©er un conteneur pour la section
                            section_container = st.container()
                            
                            # Bouton pour basculer l'affichage
                            if st.button(f"üìä Afficher/Masquer l'analyse de : {col}",
                                      key=f"btn_section_{col}{widget_suffix}"):
                                st.session_state[section_key] = not st.session_state[section_key]
                            
                            # Afficher le contenu conditionnellement
                            if st.session_state[section_key]:
                                with section_container:
                                    # Cr√©er un conteneur pour la ligne de visualisations
                                    viz_container = st.container()
                                    col1, col2 = viz_container.columns(2)
                                
                                # Afficher les graphiques avec interpr√©tation
                                with col1:
                                    hist_fig = histogram(st.session_state.df_clean, col)
                                    st.plotly_chart(hist_fig, use_container_width=True, 
                                                 key=f"hist_{col}{widget_suffix}")
                                    
                                    # Cr√©er une cl√© unique pour le toggle de l'interpr√©tation
                                    hist_expander_key = f"hist_expander_{col}{widget_suffix}"
                                    
                                    # Bouton pour afficher/masquer l'interpr√©tation de l'histogramme
                                    if hist_expander_key not in st.session_state:
                                        st.session_state[hist_expander_key] = False
                                        
                                    if st.button(f"üìä Interpr√©ter l'histogramme", 
                                               key=f"btn_hist_{col}{widget_suffix}"):
                                        st.session_state[hist_expander_key] = not st.session_state[hist_expander_key]
                                    
                                    # Afficher l'interpr√©tation dans un conteneur conditionnel
                                    if st.session_state.get(hist_expander_key, False):
                                        st.markdown("#### üîç Interpr√©tation de l'histogramme")
                                        with st.spinner("G√©n√©ration de l'interpr√©tation..."):
                                            context = f"Histogramme montrant la distribution de la variable: {col}"
                                            data_desc = (
                                                f"Distribution des valeurs de {col} avec {st.session_state.df_clean[col].nunique()} valeurs uniques. "
                                                f"La plage de valeurs va de {st.session_state.df_clean[col].min()} √† {st.session_state.df_clean[col].max()}."
                                            )
                                            interpretation = generate_ai_interpretation(
                                                context=context,
                                                data_description=data_desc,
                                                chart_type="histogram"
                                            )
                                            if interpretation:
                                                st.markdown(interpretation)
                                
                                with col2:
                                    box_fig = boxplot(st.session_state.df_clean, col)
                                    st.plotly_chart(box_fig, use_container_width=True, 
                                                 key=f"box_{col}{widget_suffix}")
                                    
                                    # Cr√©er une cl√© unique pour le toggle du boxplot
                                    box_expander_key = f"box_expander_{col}{widget_suffix}"
                                    
                                    # Bouton pour afficher/masquer l'interpr√©tation du boxplot
                                    if box_expander_key not in st.session_state:
                                        st.session_state[box_expander_key] = False
                                        
                                    if st.button(f"üì¶ Interpr√©ter le boxplot", 
                                               key=f"btn_box_{col}{widget_suffix}"):
                                        st.session_state[box_expander_key] = not st.session_state[box_expander_key]
                                    
                                    # Afficher l'interpr√©tation dans un conteneur conditionnel
                                    if st.session_state.get(box_expander_key, False):
                                        st.markdown("#### üîç Interpr√©tation du boxplot")
                                        with st.spinner("G√©n√©ration de l'interpr√©tation..."):
                                            q1 = st.session_state.df_clean[col].quantile(0.25)
                                            q3 = st.session_state.df_clean[col].quantile(0.75)
                                            iqr = q3 - q1
                                            lower_bound = q1 - 1.5 * iqr
                                            upper_bound = q3 + 1.5 * iqr
                                            outliers = st.session_state.df_clean[
                                                (st.session_state.df_clean[col] < lower_bound) | 
                                                (st.session_state.df_clean[col] > upper_bound)
                                            ]
                                            
                                            context = f"Boxplot montrant la distribution statistique de la variable: {col}"
                                            data_desc = (
                                                f"La bo√Æte √† moustaches montre la distribution des valeurs avec la m√©diane √† {st.session_state.df_clean[col].median():.2f}. "
                                                f"L'intervalle interquartile (IQR) va de {q1:.2f} √† {q3:.2f}. "
                                                f"{'Aucune valeur aberrante d√©tect√©e.' if len(outliers) == 0 else f'Valeurs aberrantes potentielles: {len(outliers)} points en dehors de la plage [{lower_bound:.2f}, {upper_bound:.2f}]'}"
                                            )
                                            interpretation = generate_ai_interpretation(
                                                context=context,
                                                data_description=data_desc,
                                                chart_type="boxplot"
                                            )
                                            if interpretation:
                                                st.markdown(interpretation)
                            
                            # Stocker les m√©triques pour l'interpr√©tation globale
                            if 'analysis_metrics' not in st.session_state:
                                st.session_state.analysis_metrics = {}
                                
                            st.session_state.analysis_metrics[col] = {
                                'type': 'num√©rique',
                                'valeurs_uniques': st.session_state.df_clean[col].nunique(),
                                'valeurs_manquantes': int(st.session_state.df_clean[col].isna().sum()),
                                'moyenne': float(st.session_state.df_clean[col].mean()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'ecart_type': float(st.session_state.df_clean[col].std()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'min': float(st.session_state.df_clean[col].min()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'max': float(st.session_state.df_clean[col].max()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None,
                                'mediane': float(st.session_state.df_clean[col].median()) if st.session_state.df_clean[col].dtype in ['int64', 'float64'] else None
                            }
                else:
                    st.warning("Aucune variable num√©rique trouv√©e dans les donn√©es.")

            with tab2:
                if categorical_cols:
                    selected_cat_cols = st.multiselect(
                        "S√©lectionnez les variables cat√©gorielles",
                        categorical_cols,
                        default=categorical_cols[:3] if len(categorical_cols) > 3 else categorical_cols
                    )

                    if selected_cat_cols:
                        for col in selected_cat_cols:
                            st.markdown(f"#### Analyse de {col}")
                            # Tableau de fr√©quences avec interpr√©tation
                            freq_table = st.session_state.df_clean[col].value_counts().reset_index()
                            freq_table.columns = [col, 'Fr√©quence']
                            
                            # Afficher le tableau de fr√©quences
                            st.markdown("##### Tableau de fr√©quences")
                            st.dataframe(freq_table)
                            
                            # Pr√©parer le contexte pour l'interpr√©tation
                            context = f"Tableau de fr√©quences pour la variable cat√©gorielle: {col}"
                            data_desc = f"Nombre de cat√©gories: {len(freq_table)}\n"
                            data_desc += f"Valeurs manquantes: {st.session_state.df_clean[col].isna().sum()}\n"
                            data_desc += f"Cat√©gorie la plus fr√©quente: {freq_table.iloc[0][col]} ({freq_table.iloc[0]['Fr√©quence']} occurrences)"
                            
                            # Stocker les informations cat√©gorielles pour l'interpr√©tation globale
                            if 'categorical_metrics' not in st.session_state:
                                st.session_state.categorical_metrics = {}
                                
                            st.session_state.categorical_metrics[col] = {
                                'nb_categories': len(freq_table),
                                'categorie_principale': freq_table.iloc[0][col],
                                'freq_categorie_principale': int(freq_table.iloc[0]['Fr√©quence']),
                                'total': int(freq_table['Fr√©quence'].sum())
                            }
                            
                            # Visualisation avec interpr√©tation
                            st.markdown("##### R√©partition des cat√©gories")
                            try:
                                # Utilisation directe de plotly.express
                                import plotly.express as px
                                fig = px.pie(freq_table, names=col, values='Fr√©quence', 
                                           title=f"R√©partition de {col}")
                                st.plotly_chart(fig, use_container_width=True)
                            except Exception as e:
                                st.error(f"Erreur lors de la cr√©ation du graphique: {str(e)}")
                                # Solution de secours avec go.Figure
                                import plotly.graph_objects as go
                                fig = go.Figure(data=[go.Pie(labels=freq_table[col], 
                                                          values=freq_table['Fr√©quence'],
                                                          name=col)])
                                fig.update_layout(title=f"R√©partition de {col}")
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # Ajouter les donn√©es de r√©partition pour l'analyse globale
                            if 'categorical_distributions' not in st.session_state:
                                st.session_state.categorical_distributions = {}
                                
                            st.session_state.categorical_distributions[col] = {
                                'categories': freq_table[col].astype(str).tolist(),
                                'frequences': freq_table['Fr√©quence'].astype(int).tolist()
                            }
                else:
                    st.warning("Aucune variable cat√©gorielle trouv√©e dans les donn√©es.")
                    
            # Onglet des analyses avanc√©es
            with tab3:
                st.markdown("### Analyses statistiques avanc√©es")
                
                # S√©lection du type d'analyse
                analysis_type = st.selectbox(
                    "Type d'analyse",
                    [
                        "S√©lectionner une analyse...",
                        "Test de normalit√© (Shapiro-Wilk)",
                        "Test T pour √©chantillon unique",
                        "Test T pour √©chantillons appari√©s",
                        "Test T pour √©chantillons ind√©pendants",
                        "ANOVA √† un facteur",
                        "Test du chi-carr√© d'ind√©pendance",
                        "Analyse de corr√©lation",
                        "R√©gression lin√©aire simple",
                        "R√©gression lin√©aire multiple"
                    ]
                )
                
                if analysis_type != "S√©lectionner une analyse...":
                    st.markdown(f"### {analysis_type}")
                    
                    # Test de normalit√©
                    if "normalit√©" in analysis_type.lower():
                        if len(numeric_cols) > 0:
                            selected_var = st.selectbox("S√©lectionnez une variable num√©rique", numeric_cols)
                            if st.button("Ex√©cuter le test de normalit√©"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[selected_var].dropna()
                                    stat, p_value = stats.shapiro(data)
                                    
                                    st.markdown("#### R√©sultats du test de normalit√© de Shapiro-Wilk")
                                    st.metric("Statistique de test", f"{stat:.4f}")
                                    st.metric("Valeur p", f"{p_value:.4f}")
                                    
                                    # Interpr√©tation
                                    alpha = 0.05
                                    if p_value > alpha:
                                        st.success(f"La variable {selected_var} suit une distribution normale (p = {p_value:.4f} > {alpha}).")
                                    else:
                                        st.warning(f"La variable {selected_var} ne suit pas une distribution normale (p = {p_value:.4f} ‚â§ {alpha}).")
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test de normalit√© : {str(e)}")
                        else:
                            st.warning("Aucune variable num√©rique disponible pour le test de normalit√©.")
                    
                    # Test T pour √©chantillon unique
                    elif "√©chantillon unique" in analysis_type.lower():
                        if len(numeric_cols) > 0:
                            selected_var = st.selectbox("S√©lectionnez une variable num√©rique", numeric_cols)
                            test_value = st.number_input("Valeur de test (moyenne hypoth√©tique)", 
                                                       value=st.session_state.df_clean[selected_var].mean())
                            
                            if st.button("Ex√©cuter le test T"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[selected_var].dropna()
                                    t_stat, p_value = stats.ttest_1samp(data, test_value)
                                    
                                    st.markdown("#### R√©sultats du test T pour √©chantillon unique")
                                    st.metric("Valeur de test", f"{test_value:.4f}")
                                    st.metric("Moyenne observ√©e", f"{data.mean():.4f}")
                                    st.metric("Statistique T", f"{t_stat:.4f}")
                                    st.metric("Valeur p (bilat√©ral)", f"{p_value:.4f}")
                                    
                                    # Interpr√©tation
                                    alpha = 0.05
                                    if p_value < alpha:
                                        st.success(f"La moyenne de {selected_var} est significativement diff√©rente de {test_value:.2f} (p = {p_value:.4f} < {alpha}).")
                                    else:
                                        st.warning(f"Aucune preuve pour rejeter l'hypoth√®se nulle : la moyenne de {selected_var} n'est pas significativement diff√©rente de {test_value:.2f} (p = {p_value:.4f} ‚â• {alpha}).")
                                    
                                    # Ajouter aux r√©sultats pour le rapport
                                    if 'advanced_analyses' not in st.session_state:
                                        st.session_state.advanced_analyses = {}
                                        
                                    st.session_state.advanced_analyses['ttest_1samp'] = {
                                        'type': 'Test T pour √©chantillon unique',
                                        'variable': selected_var,
                                        'valeur_test': float(test_value),
                                        'moyenne_observ√©e': float(data.mean()),
                                        'statistique_T': float(t_stat),
                                        'valeur_p': float(p_value),
                                        'significatif': p_value < alpha,
                                        'interpretation': f"Diff√©rence significative" if p_value < alpha else "Pas de diff√©rence significative"
                                    }
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test T : {str(e)}")
                        else:
                            st.warning("Aucune variable num√©rique disponible pour le test T.")
                            
                    # Test T pour √©chantillons appari√©s
                    elif "appari√©s" in analysis_type.lower():
                        if len(numeric_cols) >= 2:
                            st.markdown("### Test T pour √©chantillons appari√©s")
                            st.info("Ce test compare les moyennes de deux variables mesur√©es sur les m√™mes individus.")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                var1 = st.selectbox("Premi√®re mesure", numeric_cols, key="paired_var1")
                            with col2:
                                var2 = st.selectbox("Deuxi√®me mesure", [col for col in numeric_cols if col != var1], key="paired_var2")
                            
                            if st.button("Ex√©cuter le test T appari√©"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[[var1, var2]].dropna()
                                    
                                    if len(data) < 2:
                                        st.error("Pas assez de donn√©es appari√©es pour effectuer le test.")
                                    else:
                                        t_stat, p_value = stats.ttest_rel(data[var1], data[var2])
                                        
                                        # Calcul des moyennes et √©carts-types
                                        mean1, mean2 = data[var1].mean(), data[var2].mean()
                                        std1, std2 = data[var1].std(), data[var2].std()
                                        
                                        # Affichage des r√©sultats
                                        st.markdown("#### R√©sultats du test T appari√©")
                                        
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.metric(f"Moyenne {var1}", f"{mean1:.4f}")
                                            st.metric(f"√âcart-type {var1}", f"{std1:.4f}")
                                        with col2:
                                            st.metric(f"Moyenne {var2}", f"{mean2:.4f}")
                                            st.metric(f"√âcart-type {var2}", f"{std2:.4f}")
                                        
                                        st.metric("Statistique T", f"{t_stat:.4f}")
                                        st.metric("Valeur p (bilat√©ral)", f"{p_value:.4f}")
                                        
                                        # Interpr√©tation
                                        alpha = 0.05
                                        if p_value < alpha:
                                            st.success(f"Il existe une diff√©rence significative entre les moyennes de {var1} et {var2} (p = {p_value:.4f} < {alpha}).")
                                        else:
                                            st.warning(f"Aucune diff√©rence significative n'a √©t√© d√©tect√©e entre les moyennes de {var1} et {var2} (p = {p_value:.4f} ‚â• {alpha}).")
                                        
                                        # Visualisation
                                        st.markdown("#### Visualisation des donn√©es")
                                        fig = px.scatter(
                                            data.melt(var_name='Variable', value_name='Valeur'),
                                            x='Variable',
                                            y='Valeur',
                                            color='Variable',
                                            title=f"Comparaison des distributions de {var1} et {var2}",
                                            box=True,
                                            points="all"
                                        )
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Ajouter aux r√©sultats pour le rapport
                                        if 'advanced_analyses' not in st.session_state:
                                            st.session_state.advanced_analyses = {}
                                            
                                        st.session_state.advanced_analyses['ttest_paired'] = {
                                            'type': 'Test T pour √©chantillons appari√©s',
                                            'variables': [var1, var2],
                                            'moyennes': [float(mean1), float(mean2)],
                                            'ecarts_types': [float(std1), float(std2)],
                                            'statistique_T': float(t_stat),
                                            'valeur_p': float(p_value),
                                            'significatif': p_value < alpha,
                                            'interpretation': f"Diff√©rence significative entre {var1} et {var2}" if p_value < alpha \
                                                else f"Pas de diff√©rence significative entre {var1} et {var2}"
                                        }
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test T appari√© : {str(e)}")
                        else:
                            st.warning("Au moins deux variables num√©riques sont n√©cessaires pour le test T appari√©.")
                            
                    # Test T pour √©chantillons ind√©pendants
                    elif "ind√©pendants" in analysis_type.lower():
                        st.markdown("### Test T pour √©chantillons ind√©pendants")
                        st.info("Ce test compare les moyennes de deux groupes ind√©pendants.")
                        
                        # S√©lection des variables
                        numeric_var = st.selectbox("Variable num√©rique √† comparer", numeric_cols)
                        
                        # Trouver les variables cat√©gorielles avec exactement 2 cat√©gories
                        cat_cols = []
                        for col in st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns:
                            if st.session_state.df_clean[col].nunique() == 2:
                                cat_cols.append(col)
                        
                        if not cat_cols:
                            st.warning("Aucune variable cat√©gorielle avec exactement deux cat√©gories trouv√©e.")
                        else:
                            group_var = st.selectbox("Variable de groupement (binaire)", cat_cols)
                            
                            if st.button("Ex√©cuter le test T ind√©pendant"):
                                try:
                                    from scipy import stats
                                    
                                    # Pr√©parer les donn√©es
                                    data = st.session_state.df_clean[[numeric_var, group_var]].dropna()
                                    groups = data[group_var].unique()
                                    
                                    if len(groups) != 2:
                                        st.error(f"La variable de groupement doit avoir exactement 2 cat√©gories (trouv√©es : {len(groups)}).")
                                    else:
                                        group1 = data[data[group_var] == groups[0]][numeric_var]
                                        group2 = data[data[group_var] == groups[1]][numeric_var]
                                        
                                        # V√©rifier l'√©galit√© des variances
                                        _, p_levene = stats.levene(group1, group2)
                                        equal_var = p_levene > 0.05
                                        
                                        # Ex√©cuter le test T
                                        t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=equal_var)
                                        
                                        # Calcul des statistiques descriptives
                                        stats_group1 = {
                                            'moyenne': group1.mean(),
                                            'ecart_type': group1.std(),
                                            'taille': len(group1)
                                        }
                                        stats_group2 = {
                                            'moyenne': group2.mean(),
                                            'ecart_type': group2.std(),
                                            'taille': len(group2)
                                        }
                                        
                                        # Affichage des r√©sultats
                                        st.markdown("#### R√©sultats du test T ind√©pendant")
                                        st.write(f"**Variable num√©rique** : {numeric_var}")
                                        st.write(f"**Variable de groupement** : {group_var}")
                                        
                                        # Tableau des statistiques descriptives
                                        st.markdown("##### Statistiques descriptives")
                                        stats_df = pd.DataFrame({
                                            'Groupe': [str(groups[0]), str(groups[1])],
                                            'Moyenne': [stats_group1['moyenne'], stats_group2['moyenne']],
                                            '√âcart-type': [stats_group1['ecart_type'], stats_group2['ecart_type']],
                                            'Effectif': [stats_group1['taille'], stats_group2['taille']]
                                        })
                                        st.dataframe(stats_df)
                                        
                                        # R√©sultats du test
                                        st.markdown("##### R√©sultats du test")
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.metric("Statistique T", f"{t_stat:.4f}")
                                        with col2:
                                            st.metric("Valeur p (bilat√©ral)", f"{p_value:.4f}")
                                        
                                        st.info(f"Test d'√©galit√© des variances (Levene) : p = {p_levene:.4f} - Hypoth√®se d'√©galit√© des variances {'accept√©e' if equal_var else 'rejet√©e'}")
                                        
                                        # Interpr√©tation
                                        alpha = 0.05
                                        if p_value < alpha:
                                            st.success(f"Il existe une diff√©rence significative entre les moyennes des deux groupes (p = {p_value:.4f} < {alpha}).")
                                        else:
                                            st.warning(f"Aucune diff√©rence significative n'a √©t√© d√©tect√©e entre les moyennes des deux groupes (p = {p_value:.4f} ‚â• {alpha}).")
                                        
                                        # Visualisation
                                        st.markdown("#### Visualisation des donn√©es")
                                        fig = px.box(
                                            data,
                                            x=group_var,
                                            y=numeric_var,
                                            color=group_var,
                                            title=f"Distribution de {numeric_var} par {group_var}",
                                            points="all"
                                        )
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Ajouter aux r√©sultats pour le rapport
                                        if 'advanced_analyses' not in st.session_state:
                                            st.session_state.advanced_analyses = {}
                                            
                                        st.session_state.advanced_analyses['ttest_ind'] = {
                                            'type': 'Test T pour √©chantillons ind√©pendants',
                                            'variable_numerique': numeric_var,
                                            'variable_groupement': group_var,
                                            'groupes': [str(g) for g in groups],
                                            'moyennes': [float(stats_group1['moyenne']), float(stats_group2['moyenne'])],
                                            'ecarts_types': [float(stats_group1['ecart_type']), float(stats_group2['ecart_type'])],
                                            'tailles': [stats_group1['taille'], stats_group2['taille']],
                                            'statistique_T': float(t_stat),
                                            'valeur_p': float(p_value),
                                            'valeur_p_levene': float(p_levene),
                                            'variances_egales': equal_var,
                                            'significatif': p_value < alpha,
                                            'interpretation': f"Diff√©rence significative entre les groupes {groups[0]} et {groups[1]}" if p_value < alpha \
                                                else f"Pas de diff√©rence significative entre les groupes {groups[0]} et {groups[1]}"
                                        }
                                        
                                except Exception as e:
                                    st.error(f"Erreur lors du test T ind√©pendant : {str(e)}")
                    
                    # Analyse de corr√©lation
                    elif "corr√©lation" in analysis_type.lower():
                        if len(numeric_cols) >= 2:
                            selected_vars = st.multiselect(
                                "S√©lectionnez deux variables num√©riques",
                                numeric_cols,
                                default=numeric_cols[:2],
                                max_selections=2
                            )
                            
                            if len(selected_vars) == 2 and st.button("Calculer la corr√©lation"):
                                try:
                                    from scipy import stats
                                    data = st.session_state.df_clean[selected_vars].dropna()
                                    
                                    # Calcul de la corr√©lation de Pearson
                                    pearson_corr, pearson_p = stats.pearsonr(data[selected_vars[0]], data[selected_vars[1]])
                                    
                                    # Calcul de la corr√©lation de Spearman
                                    spearman_corr, spearman_p = stats.spearmanr(data[selected_vars[0]], data[selected_vars[1]])
                                    
                                    st.markdown("#### Analyse de corr√©lation")
                                    
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric("Corr√©lation de Pearson", f"{pearson_corr:.4f}")
                                        st.metric("Valeur p (Pearson)", f"{pearson_p:.4f}")
                                    with col2:
                                        st.metric("Corr√©lation de Spearman", f"{spearman_corr:.4f}")
                                        st.metric("Valeur p (Spearman)", f"{spearman_p:.4f}")
                                    
                                    # Interpr√©tation
                                    def interpret_correlation(coef):
                                        abs_coef = abs(coef)
                                        if abs_coef >= 0.8:
                                            return "forte"
                                        elif abs_coef >= 0.5:
                                            return "mod√©r√©e"
                                        elif abs_coef >= 0.3:
                                            return "faible"
                                        else:
                                            return "nulle ou tr√®s faible"
                                    
                                    direction = "positive" if pearson_corr > 0 else "n√©gative" if pearson_corr < 0 else "nulle"
                                    
                                    st.markdown("#### Interpr√©tation")
                                    st.markdown(f"- **Corr√©lation de Pearson** : {interpret_correlation(pearson_corr).capitalize()} et {direction} (r = {pearson_corr:.3f})")
                                    
                                    if pearson_p < 0.05:
                                        st.success(f"La corr√©lation est statistiquement significative (p = {pearson_p:.4f} < 0.05).")
                                    else:
                                        st.warning(f"La corr√©lation n'est pas statistiquement significative (p = {pearson_p:.4f} ‚â• 0.05).")
                                    
                                    # Nuage de points
                                    import plotly.express as px
                                    fig = px.scatter(
                                        data, 
                                        x=selected_vars[0], 
                                        y=selected_vars[1],
                                        trendline="ols",
                                        title=f"Nuage de points : {selected_vars[0]} vs {selected_vars[1]}"
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                except Exception as e:
                                    st.error(f"Erreur lors du calcul de la corr√©lation : {str(e)}")
                        else:
                            st.warning("Au moins deux variables num√©riques sont n√©cessaires pour l'analyse de corr√©lation.")
                    
                    # R√©gressions
                    elif "r√©gression" in analysis_type.lower():
                        if len(numeric_cols) >= 2:
                            target_var = st.selectbox("Variable cible (Y)", numeric_cols)
                            feature_vars = st.multiselect(
                                "Variables explicatives (X)",
                                [col for col in numeric_cols if col != target_var],
                                default=[col for col in numeric_cols[:1] if col != target_var]
                            )
                            
                            if feature_vars and st.button("Ex√©cuter la r√©gression"):
                                try:
                                    import statsmodels.api as sm
                                    from sklearn.preprocessing import StandardScaler
                                    
                                    # Pr√©paration des donn√©es
                                    data = st.session_state.df_clean[[target_var] + feature_vars].dropna()
                                    X = data[feature_vars]
                                    y = data[target_var]
                                    
                                    # Standardisation des variables
                                    scaler = StandardScaler()
                                    X_scaled = scaler.fit_transform(X)
                                    X_scaled = sm.add_constant(X_scaled)  # Ajout de la constante
                                    
                                    # Mod√®le de r√©gression
                                    model = sm.OLS(y, X_scaled).fit()
                                    
                                    # Affichage des r√©sultats
                                    st.markdown("#### R√©sum√© du mod√®le de r√©gression")
                                    st.markdown(f"**Variable cible** : {target_var}")
                                    st.markdown(f"**Variables explicatives** : {', '.join(feature_vars)}")
                                    st.markdown(f"**Nombre d'observations** : {len(data)}")
                                    
                                    # M√©triques du mod√®le
                                    st.markdown("##### M√©triques du mod√®le")
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("R¬≤", f"{model.rsquared:.4f}")
                                    with col2:
                                        st.metric("R¬≤ ajust√©", f"{model.rsquared_adj:.4f}")
                                    with col3:
                                        st.metric("F-statistique", f"{model.fvalue:.2f}")
                                    
                                    # Coefficients
                                    st.markdown("##### Coefficients du mod√®le")
                                    coef_df = model.summary2().tables[1]
                                    coef_df.index = ['Constante'] + feature_vars
                                    st.dataframe(coef_df)
                                    
                                    # Interpr√©tation
                                    st.markdown("#### Interpr√©tation")
                                    interpretation = []
                                    
                                    # Qualit√© du mod√®le
                                    if model.rsquared_adj > 0.7:
                                        interpretation.append(f"- Le mod√®le explique une grande partie de la variance de la variable cible (R¬≤ ajust√© = {model.rsquared_adj:.3f}).")
                                    elif model.rsquared_adj > 0.3:
                                        interpretation.append(f"- Le mod√®le explique une partie mod√©r√©e de la variance de la variable cible (R¬≤ ajust√© = {model.rsquared_adj:.3f}).")
                                    else:
                                        interpretation.append(f"- Le mod√®le explique une faible partie de la variance de la variable cible (R¬≤ ajust√© = {model.rsquared_adj:.3f}).")
                                    
                                    # Significativit√© globale
                                    if model.f_pvalue < 0.05:
                                        interpretation.append("- Le mod√®le est globalement significatif (p < 0.05).")
                                    else:
                                        interpretation.append("- Le mod√®le n'est pas globalement significatif (p ‚â• 0.05).")
                                    
                                    # Coefficients significatifs
                                    significant_vars = []
                                    for var, pval in zip(['Constante'] + feature_vars, model.pvalues):
                                        if pval < 0.05:
                                            coef = model.params[var] if var == 'Constante' else model.params[var]
                                            direction = "positivement" if coef > 0 else "n√©gativement"
                                            interpretation.append(f"- La variable **{var}** a un effet significatif {direction} sur la variable cible (p = {pval:.4f}).")
                                            significant_vars.append(var)
                                    
                                    if not significant_vars:
                                        interpretation.append("- Aucune variable n'a d'effet significatif sur la variable cible (tous les p-values ‚â• 0.05).")
                                    
                                    st.markdown("\n".join(interpretation))
                                    
                                    # Graphique des r√©sidus
                                    st.markdown("##### Analyse des r√©sidus")
                                    fig = px.scatter(
                                        x=model.fittedvalues,
                                        y=model.resid,
                                        labels={'x': 'Valeurs pr√©dites', 'y': 'R√©sidus'},
                                        title='Graphique des r√©sidus vs valeurs pr√©dites'
                                    )
                                    fig.add_hline(y=0, line_dash="dash", line_color="red")
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                except Exception as e:
                                    st.error(f"Erreur lors de l'ex√©cution de la r√©gression : {str(e)}")
                        else:
                            st.warning("Au moins deux variables num√©riques sont n√©cessaires pour la r√©gression.")
                    
                    # Message pour les analyses non impl√©ment√©es
                    else:
                        st.info(f"L'analyse '{analysis_type}' n'est pas encore impl√©ment√©e. Elle sera disponible dans une prochaine mise √† jour.")
                        
                        # Exemple de structure pour les futures impl√©mentations
                        if "ANOVA" in analysis_type:
                            st.markdown("### ANOVA √† un facteur")
                            
                            # V√©rifier les pr√©requis
                            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
                            cat_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            if len(numeric_cols) < 1 or len(cat_cols) < 1:
                                st.warning("L'ANOVA n√©cessite au moins une variable num√©rique et une variable cat√©gorielle.")
                            else:
                                # S√©lection des variables
                                numeric_var = st.selectbox("S√©lectionnez la variable num√©rique (variable r√©ponse)", numeric_cols)
                                cat_var = st.selectbox("S√©lectionnez la variable cat√©gorielle (facteur)", cat_cols)
                                
                                # V√©rifier le nombre de groupes
                                unique_groups = st.session_state.df_clean[cat_var].nunique()
                                if unique_groups < 2:
                                    st.error(f"La variable cat√©gorielle doit avoir au moins 2 groupes (actuellement {unique_groups}).")
                                else:
                                    if st.button("Ex√©cuter l'ANOVA", key="run_anova"):
                                        try:
                                            # Pr√©parer les donn√©es
                                            groups = []
                                            for group in st.session_state.df_clean[cat_var].unique():
                                                groups.append(st.session_state.df_clean[st.session_state.df_clean[cat_var] == group][numeric_var].dropna())
                                            
                                            # Ex√©cuter le test ANOVA
                                            f_val, p_val = stats.f_oneway(*groups)
                                            
                                            # Afficher les r√©sultats
                                            st.markdown("#### R√©sultats de l'ANOVA")
                                            st.write(f"Variable num√©rique : **{numeric_var}**")
                                            st.write(f"Variable cat√©gorielle : **{cat_var}** (groupes: {', '.join(map(str, st.session_state.df_clean[cat_var].unique()))})")
                                            
                                            col1, col2 = st.columns(2)
                                            with col1:
                                                st.metric("Statistique F", f"{f_val:.4f}")
                                            with col2:
                                                st.metric("Valeur p", f"{p_val:.4f}")
                                            
                                            # Interpr√©tation
                                            alpha = 0.05
                                            if p_val < alpha:
                                                st.success("Il existe des diff√©rences statistiquement significatives entre les moyennes des groupes (p < 0.05).")
                                            else:
                                                st.info("Aucune diff√©rence statistiquement significative n'a √©t√© d√©tect√©e entre les moyennes des groupes (p ‚â• 0.05).")
                                            
                                            # Visualisation
                                            st.markdown("#### Visualisation des donn√©es")
                                            fig = px.box(
                                                st.session_state.df_clean, 
                                                x=cat_var, 
                                                y=numeric_var,
                                                title=f"Distribution de {numeric_var} par {cat_var}",
                                                color=cat_var
                                            )
                                            st.plotly_chart(fig, use_container_width=True)
                                            
                                            # Ajouter aux r√©sultats pour le rapport
                                            if 'advanced_analyses' not in st.session_state:
                                                st.session_state.advanced_analyses = {}
                                            
                                            st.session_state.advanced_analyses['anova'] = {
                                                'type': 'ANOVA √† un facteur',
                                                'variables': {
                                                    'numerique': numeric_var,
                                                    'categorielle': cat_var
                                                },
                                                'resultats': {
                                                    'statistique_F': float(f_val),
                                                    'valeur_p': float(p_val),
                                                    'significatif': p_val < alpha
                                                },
                                                'interpretation': "Diff√©rences significatives" if p_val < alpha else "Pas de diff√©rence significative"
                                            }
                                            
                                        except Exception as e:
                                            st.error(f"Erreur lors de l'ex√©cution de l'ANOVA : {str(e)}")
                        elif "chi-carr√©" in analysis_type.lower():
                            st.markdown("### Test du chi-carr√© d'ind√©pendance")
                            
                            # Trouver les variables cat√©gorielles
                            cat_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            if len(cat_cols) < 2:
                                st.warning("Au moins deux variables cat√©gorielles sont n√©cessaires pour le test du chi-carr√©.")
                            else:
                                # S√©lection des variables
                                col1, col2 = st.columns(2)
                                with col1:
                                    var1 = st.selectbox("Premi√®re variable cat√©gorielle", cat_cols, key="chi2_var1")
                                with col2:
                                    var2 = st.selectbox("Deuxi√®me variable cat√©gorielle", 
                                                      [col for col in cat_cols if col != var1], 
                                                      key="chi2_var2")
                                
                                # Options du test
                                with st.expander("Options avanc√©es"):
                                    correction = st.checkbox("Appliquer la correction de Yates", value=True, 
                                                         help="Correction de continuit√© qui doit √™tre appliqu√©e quand les effectifs sont faibles.")
                                
                                if st.button("Ex√©cuter le test du chi-carr√©"):
                                    try:
                                        from scipy import stats
                                        import numpy as np
                                        
                                        # Cr√©er un tableau de contingence
                                        contingency_table = pd.crosstab(
                                            st.session_state.df_clean[var1], 
                                            st.session_state.df_clean[var2]
                                        )
                                        
                                        # V√©rifier les effectifs th√©oriques
                                        chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table, correction=correction)
                                        
                                        # Calcul du V de Cramer (mesure d'effet)
                                        n = contingency_table.sum().sum()
                                        phi2 = chi2 / n
                                        r, k = contingency_table.shape
                                        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    
                                        rcorr = r - ((r-1)**2)/(n-1)
                                        kcorr = k - ((k-1)**2)/(n-1)
                                        cramers_v = np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))
                                        
                                        # Affichage des r√©sultats
                                        st.markdown("#### R√©sultats du test du chi-carr√©")
                                        st.write(f"**Variables analys√©es** : {var1} et {var2}")
                                        
                                        # Tableau de contingence
                                        st.markdown("##### Tableau de contingence")
                                        st.dataframe(contingency_table)
                                        
                                        # Statistiques du test
                                        st.markdown("##### Statistiques du test")
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("Khi-deux", f"{chi2:.4f}")
                                        with col2:
                                            st.metric("Degr√©s de libert√©", dof)
                                        with col3:
                                            st.metric("Valeur p", f"{p_value:.4f}")
                                        
                                        # Mesure d'effet
                                        st.markdown("##### Mesure d'effet (V de Cramer)")
                                        st.metric("V de Cramer", f"{cramers_v:.4f}")
                                        
                                        # Interpr√©tation du V de Cramer
                                        interpretation_v = "nulle"
                                        if cramers_v >= 0.5:
                                            interpretation_v = "forte"
                                        elif cramers_v >= 0.3:
                                            interpretation_v = "mod√©r√©e"
                                        elif cramers_v >= 0.1:
                                            interpretation_v = "faible"
                                            
                                        # Interpr√©tation
                                        alpha = 0.05
                                        if p_value < alpha:
                                            st.success(f"Il existe une association statistiquement significative entre {var1} et {var2} (p = {p_value:.4f} < {alpha}).")
                                            st.info(f"L'association est de force {interpretation_v} (V de Cramer = {cramers_v:.3f}).")
                                        else:
                                            st.warning(f"Aucune association significative n'a √©t√© d√©tect√©e entre {var1} et {var2} (p = {p_value:.4f} ‚â• {alpha}).")
                                        
                                        # Visualisation
                                        st.markdown("#### Visualisation")
                                        
                                        # Heatmap des fr√©quences relatives par ligne
                                        fig = px.imshow(
                                            contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100,
                                            labels=dict(x=var2, y=var1, color="%")
                                        )
                                        fig.update_layout(
                                            title=f"Pourcentages en ligne de {var1} par {var2}",
                                            xaxis_title=var2,
                                            yaxis_title=var1
                                        )
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Ajouter aux r√©sultats pour le rapport
                                        if 'advanced_analyses' not in st.session_state:
                                            st.session_state.advanced_analyses = {}
                                            
                                        st.session_state.advanced_analyses['chi2'] = {
                                            'type': "Test du Khi-deux d'ind√©pendance",
                                            'variables': [var1, var2],
                                            'tableau_contingence': contingency_table.to_dict(),
                                            'khi_deux': float(chi2),
                                            'ddl': int(dof),
                                            'valeur_p': float(p_value),
                                            'v_cramer': float(cramers_v),
                                            'significatif': p_value < alpha,
                                            'interpretation': f"Association significative ({'forte' if cramers_v >= 0.5 else 'mod√©r√©e' if cramers_v >= 0.3 else 'faible'})" if p_value < alpha \
                                                else "Pas d'association significative"
                                        }
                                        
                                    except Exception as e:
                                        st.error(f"Erreur lors du test du chi-carr√© : {str(e)}")

        # Section pour les corr√©lations
        with st.expander("üìà Analyse des corr√©lations", expanded=False):
            st.markdown("### Matrice de corr√©lation")
            
            # Initialiser les m√©triques de corr√©lation
            st.session_state.correlation_metrics = {
                'variables_numeriques': numeric_cols,
                'nb_variables': len(numeric_cols) if numeric_cols else 0
            }

            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()

            if len(numeric_cols) > 1:
                try:
                    # Calculer la matrice de corr√©lation
                    corr_matrix = st.session_state.df_clean[numeric_cols].corr()

                    # Afficher la heatmap
                    st.plotly_chart(correlation_heatmap(corr_matrix), use_container_width=True)

                    # Interpr√©tation des corr√©lations
                    st.markdown("### Interpr√©tation des corr√©lations")
                    strong_corrs = corr_matrix.unstack().sort_values(ascending=False)
                    strong_corrs = strong_corrs[strong_corrs < 1.0]  # Exclure l'auto-corr√©lation
                    strong_corrs = strong_corrs[(strong_corrs > 0.7) | (strong_corrs < -0.7)]

                    if not strong_corrs.empty:
                        st.dataframe(strong_corrs.reset_index().rename(columns={'level_0': 'Variable 1', 'level_1': 'Variable 2', 0: 'Corr√©lation'}))
                        
                        # Interpr√©tation IA des corr√©lations
                        context = "Matrice de corr√©lation entre les variables num√©riques"
                        data_desc = f"Variables analys√©es: {', '.join(numeric_cols)}\n"
                        data_desc += f"Nombre total d'observations: {len(st.session_state.df_clean)}\n"
                        data_desc += "\nCorr√©lations fortes d√©tect√©es:\n"
                        
                        # Ajouter les corr√©lations fortes √† la description
                        for idx, (pair, value) in enumerate(strong_corrs.items(), 1):
                            data_desc += f"{idx}. {pair[0]} & {pair[1]}: {value:.2f}\n"
                        
                        # G√©n√©rer l'interpr√©tation IA
                        interpretation = generate_ai_interpretation(
                            context=context,
                            data_description=data_desc,
                            chart_type="correlation_matrix"
                        )
                        
                        if interpretation:
                            st.markdown("### Interpr√©tation des corr√©lations")
                            st.markdown(interpretation)
                    else:
                        st.info("Aucune corr√©lation forte (>0.7 ou <-0.7) n'a √©t√© d√©tect√©e.")

                except Exception as e:
                    st.error(f"Erreur lors du calcul des corr√©lations: {str(e)}")
            else:
                st.warning("Au moins deux variables num√©riques sont n√©cessaires pour calculer les corr√©lations.")

        # Section pour les analyses avanc√©es
        with st.expander("ü§ñ Analyses avanc√©es", expanded=False):
            st.markdown("### Analyses avanc√©es et mod√©lisation")

            analysis_type = st.selectbox(
                "Type d'analyse avanc√©e",
                ["S√©lectionnez...", "Clustering", "Classification", "R√©gression", "S√©ries temporelles"],
                key="advanced_analysis_type"
            )

            if analysis_type != "S√©lectionnez...":
                if analysis_type in ["Classification", "R√©gression"]:
                    # S√©lection des variables
                    numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
                    categorical_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category']).columns.tolist()

                    if not numeric_cols:
                        st.warning("Aucune variable num√©rique disponible pour l'analyse.")
                    else:
                        target_col = st.selectbox(
                            "S√©lectionnez la variable cible",
                            numeric_cols + categorical_cols,
                            key="target_col"
                        )

                        # S√©lection des variables explicatives
                        available_features = [col for col in numeric_cols + categorical_cols if col != target_col]
                        default_features = [col for col in numeric_cols[:3] if col in available_features]
                        
                        feature_cols = st.multiselect(
                            "S√©lectionnez les variables explicatives",
                            options=available_features,
                            default=default_features[:min(3, len(default_features))],
                            key=f"feature_cols_{analysis_type}_{target_col}"
                        )

                        if st.button(f"Lancer l'analyse {analysis_type.lower()}"):
                            with st.spinner(f"Ex√©cution de l'analyse {analysis_type.lower()}..."):
                                try:
                                    # Pr√©paration des donn√©es
                                    X = st.session_state.df_clean[feature_cols]
                                    y = st.session_state.df_clean[target_col]

                                    # Conversion des variables cat√©gorielles
                                    X = pd.get_dummies(X)

                                    # Division des donn√©es
                                    from sklearn.model_selection import train_test_split
                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                                    # S√©lection du mod√®le
                                    if analysis_type == "Classification":
                                        from sklearn.ensemble import RandomForestClassifier
                                        model = RandomForestClassifier(random_state=42)
                                    else:  # R√©gression
                                        from sklearn.ensemble import RandomForestRegressor
                                        model = RandomForestRegressor(random_state=42)

                                    # Entra√Ænement du mod√®le
                                    model.fit(X_train, y_train)

                                    # √âvaluation
                                    from sklearn.metrics import accuracy_score, r2_score

                                    if analysis_type == "Classification":
                                        y_pred = model.predict(X_test)
                                        score = accuracy_score(y_test, y_pred)
                                        st.success(f"Pr√©cision du mod√®le: {score:.2f}")
                                    else:
                                        y_pred = model.predict(X_test)
                                        score = r2_score(y_test, y_pred)
                                        st.success(f"Coefficient de d√©termination (R¬≤): {score:.2f}")

                                    # Importance des variables
                                    st.subheader("Importance des variables")
                                    feature_importance = pd.DataFrame({
                                        'Variable': X.columns,
                                        'Importance': model.feature_importances_
                                    }).sort_values('Importance', ascending=False)

                                    st.plotly_chart(px.bar(feature_importance, x='Variable', y='Importance'), use_container_width=True)

                                    # Pr√©paration des donn√©es pour l'interpr√©tation par Gemini
                                    top_features = feature_importance.head(5).to_dict('records')
                                    
                                    # Construction du prompt pour Gemini
                                    prompt = f"""
                                    Tu es un expert en analyse de donn√©es. Analyse les r√©sultats suivants d'une analyse de {analysis_type.lower()}:
                                    
                                    Variables les plus importantes:
                                    """
                                    
                                    for i, feat in enumerate(top_features, 1):
                                        prompt += f"{i}. {feat['Variable']} (importance: {feat['Importance']:.3f})\n"
                                    
                                    prompt += f"\nScore du mod√®le: {score:.2f}\n"
                                    prompt += "\nDonne une interpr√©tation claire et concise de ces r√©sultats en fran√ßais, en mettant en avant les points cl√©s et les implications pratiques. Inclus 2-3 recommandations d'actions concr√®tes."
                                    
                                    try:
                                        # Appel √† l'API Gemini avec le mod√®le par d√©faut
                                        interpretation = call_gemini_api(prompt)
                                        
                                    except Exception as e:
                                        st.warning(f"Impossible de contacter l'API Gemini: {str(e)}")
                                        # Interpr√©tation de secours
                                        interpretation = f"""
                                        **R√©sultats de l'analyse de {analysis_type.lower()}**
                                        
                                        **Variables les plus importantes :**
                                        """
                                        for i, feat in enumerate(top_features, 1):
                                            interpretation += f"{i}. {feat['Variable']} (importance: {feat['Importance']:.3f})\n"
                                        
                                        interpretation += f"\n**Score du mod√®le :** {score:.2f}\n"
                                        interpretation += """
                                        
                                        **Recommandations :**
                                        - Les variables avec une importance √©lev√©e ont plus d'influence sur la pr√©diction
                                        - Explorez les relations entre ces variables et la cible
                                        - Envisagez d'ajouter plus de donn√©es ou d'autres variables pertinentes
                                        """
                                    
                                    # Affichage des r√©sultats
                                    st.markdown("### üìä Interpr√©tation des r√©sultats")
                                    st.markdown(interpretation)
                                    
                                    # Sauvegarde des r√©sultats
                                    st.session_state.custom_analysis_results[f"{analysis_type}_{target_col}"] = {
                                        'model': model,
                                        'features': feature_cols,
                                        'target': target_col,
                                        'score': score,
                                        'importance': feature_importance.to_dict('records')
                                    }

                                except Exception as e:
                                    st.error(f"Erreur lors de l'analyse: {str(e)}")
                                    st.exception(e)

                elif analysis_type == "Clustering":
                    numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()

                    if not numeric_cols:
                        st.warning("Aucune variable num√©rique disponible pour le clustering.")
                    else:
                        selected_cols = st.multiselect(
                            "S√©lectionnez les variables pour le clustering",
                            numeric_cols,
                            default=numeric_cols[:3],
                            key="clustering_cols"
                        )

                        n_clusters = st.slider("Nombre de clusters", 2, 10, 3, key="n_clusters")

                        if st.button("Ex√©cuter le clustering"):
                            with st.spinner("Ex√©cution du clustering..."):
                                try:
                                    from sklearn.cluster import KMeans
                                    from sklearn.preprocessing import StandardScaler

                                    # Pr√©paration des donn√©es
                                    X = st.session_state.df_clean[selected_cols]
                                    X = StandardScaler().fit_transform(X)

                                    # Clustering
                                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                                    clusters = kmeans.fit_predict(X)

                                    # Ajout des clusters au DataFrame
                                    st.session_state.df_clean['Cluster'] = clusters

                                    # Visualisation
                                    st.subheader("Visualisation des clusters")

                                    # R√©duction de dimension pour la visualisation
                                    from sklearn.decomposition import PCA
                                    pca = PCA(n_components=2)
                                    X_pca = pca.fit_transform(X)

                                    # Cr√©ation d'un DataFrame pour la visualisation
                                    viz_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
                                    viz_df['Cluster'] = clusters

                                    # Affichage
                                    st.plotly_chart(px.scatter(
                                        viz_df, x='PC1', y='PC2', color='Cluster',
                                        title="Projection des clusters (PCA)"
                                    ), use_container_width=True)

                                    # Sauvegarde des r√©sultats
                                    st.session_state.custom_analysis_results['clustering'] = {
                                        'model': kmeans,
                                        'features': selected_cols,
                                        'n_clusters': n_clusters,
                                        'clusters': clusters.tolist()
                                    }

                                    st.success("Clustering termin√© avec succ√®s!")

                                except Exception as e:
                                    st.error(f"Erreur lors du clustering: {str(e)}")
                                    st.exception(e)

                elif analysis_type == "S√©ries temporelles":
                    date_cols = st.session_state.df_clean.select_dtypes(include=['datetime64']).columns.tolist()

                    if not date_cols:
                        st.warning("Aucune colonne de date d√©tect√©e dans les donn√©es.")
                    else:
                        date_col = st.selectbox(
                            "S√©lectionnez la colonne de date",
                            date_cols,
                            key="ts_date_col"
                        )

                        numeric_cols = [col for col in st.session_state.df_clean.select_dtypes(include=['number']).columns if col != date_col]

                        if not numeric_cols:
                            st.warning("Aucune variable num√©rique disponible pour l'analyse des s√©ries temporelles.")
                        else:
                            value_col = st.selectbox(
                                "S√©lectionnez la variable √† analyser",
                                numeric_cols,
                                key="ts_value_col"
                            )

                            if st.button("Analyser la s√©rie temporelle"):
                                with st.spinner("Analyse de la s√©rie temporelle..."):
                                    try:
                                        # Pr√©paration des donn√©es
                                        ts_data = st.session_state.df_clean[[date_col, value_col]].dropna()
                                        ts_data = ts_data.set_index(date_col).sort_index()

                                        # Visualisation
                                        st.subheader("Visualisation de la s√©rie temporelle")
                                        st.plotly_chart(px.line(
                                            ts_data, x=ts_data.index, y=value_col,
                                            title=f"√âvolution de {value_col} au fil du temps"
                                        ), use_container_width=True)

                                        # D√©composition de la s√©rie temporelle
                                        from statsmodels.tsa.seasonal import seasonal_decompose

                                        st.subheader("D√©composition de la s√©rie temporelle")
                                        decomposition = seasonal_decompose(ts_data[value_col], model='additive', period=12)
                                        decomposition.plot()
                                        st.pyplot()

                                        # Sauvegarde des r√©sultats
                                        st.session_state.custom_analysis_results['time_series'] = {
                                            'date_col': date_col,
                                            'value_col': value_col,
                                            'data': ts_data.reset_index().to_dict('records')
                                        }

                                        st.success("Analyse de la s√©rie temporelle termin√©e avec succ√®s!")

                                    except Exception as e:
                                        st.error(f"Erreur lors de l'analyse de la s√©rie temporelle: {str(e)}")
                                        st.exception(e)

        # Section pour les analyses avanc√©es avec requ√™tes en langage naturel
        st.markdown("---")
        st.markdown("## üîç Analyse avanc√©e")
        
        # Section des suggestions d'analyse
        with st.expander("üí° Suggestions d'analyse rapide", expanded=True):
            st.markdown("### Analyses sugg√©r√©es")
            st.caption("S√©lectionnez une suggestion pour g√©n√©rer automatiquement le code d'analyse correspondant.")
            
            # D√©tection des types de colonnes
            df = st.session_state.df_clean
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
            date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
            
            # G√©n√©rer les suggestions bas√©es sur les donn√©es disponibles
            suggestions = generate_analysis_suggestions(numeric_cols, cat_cols, date_cols, max_suggestions=8)
            
            # Afficher les suggestions sous forme de cartes
            if suggestions:
                # Cr√©er un espace pour afficher les d√©tails de la suggestion s√©lectionn√©e
                selected_suggestion = None
                
                # Afficher les cartes de suggestions
                cols = st.columns(2)
                for i, suggestion in enumerate(suggestions):
                    with cols[i % 2]:
                        with st.container(border=True):
                            col1, col2 = st.columns([1, 8])
                            with col1:
                                st.markdown(f"## {suggestion['title'].split(' ')[0]}")  # Afficher uniquement l'emoji
                            with col2:
                                st.markdown(f"**{suggestion['title']}**")
                                
                            st.caption(suggestion['description'])
                            
                            # Bouton pour utiliser la suggestion
                            if st.button("Utiliser cette analyse", 
                                       key=f"suggest_btn_{i}",
                                       use_container_width=True,
                                       type="primary"):
                                # Mettre √† jour la requ√™te et le type
                                query_key = f"natural_language_query_{suggestion['code_type'].lower()}"
                                st.session_state[query_key] = suggestion['query']
                                st.session_state.query_type = suggestion['code_type']
                                st.session_state.show_generated_code = True
                                st.rerun()
                            
                            # Bouton pour voir plus de d√©tails
                            if st.button("‚ÑπÔ∏è En savoir plus", 
                                       key=f"detail_btn_{i}",
                                       use_container_width=True):
                                selected_suggestion = suggestion
                
                # Afficher les d√©tails de la suggestion s√©lectionn√©e
                if selected_suggestion:
                    st.markdown("---")
                    st.markdown(f"### üîç D√©tails de l'analyse")
                    
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown("#### üìù Description")
                        st.info(selected_suggestion['description'])
                        
                        st.markdown("#### üìä Type d'analyse")
                        st.code(selected_suggestion['code_type'], language='python')
                        
                    with col2:
                        st.markdown("#### üîç Variables impliqu√©es")
                        if 'variables' in selected_suggestion:
                            if isinstance(selected_suggestion['variables'], list):
                                for var in selected_suggestion['variables']:
                                    st.markdown(f"- `{var}`")
                        
                        st.markdown("#### üìã Requ√™te g√©n√©r√©e")
                        st.code(selected_suggestion['query'], language='python')
                    
                    # Bouton pour utiliser cette suggestion
                    if st.button("‚úÖ Utiliser cette analyse", 
                               key="use_selected_suggestion",
                               use_container_width=True,
                               type="primary"):
                        query_key = f"natural_language_query_{selected_suggestion['code_type'].lower()}"
                        st.session_state[query_key] = selected_suggestion['query']
                        st.session_state.query_type = selected_suggestion['code_type']
                        st.session_state.show_generated_code = True
                        st.rerun()
            
            else:
                st.info("‚ö†Ô∏è Pas assez de donn√©es pour g√©n√©rer des suggestions d'analyse pertinentes.")
                st.markdown("""
                Pour obtenir des suggestions d'analyse plus pertinentes :
                - Assurez-vous que vos donn√©es contiennent des colonnes num√©riques et/ou cat√©gorielles
                - V√©rifiez que les types de donn√©es sont correctement d√©tect√©s
                - Utilisez l'√©tape de nettoyage pour corriger les probl√®mes de donn√©es
                """)
                
            # Ajouter des suggestions bas√©es sur les objectifs de l'analyse
            if 'analysis_goals' in st.session_state and st.session_state.analysis_goals:
                st.markdown("---")
                st.markdown("### üéØ Suggestions bas√©es sur vos objectifs")
                st.caption("Ces suggestions sont g√©n√©r√©es sp√©cifiquement en fonction des objectifs que vous avez d√©finis.")
                
                # G√©n√©rer des suggestions bas√©es sur les objectifs de l'utilisateur
                goal_suggestions = generate_goal_based_suggestions(
                    st.session_state.analysis_goals,
                    numeric_cols,
                    cat_cols,
                    date_cols,
                    max_suggestions=3
                )
                
                if goal_suggestions:
                    # Afficher les suggestions bas√©es sur les objectifs
                    goal_cols = st.columns(min(3, len(goal_suggestions)))
                    for i, suggestion in enumerate(goal_suggestions):
                        with goal_cols[i % len(goal_cols)]:
                            with st.container(border=True):
                                col1, col2 = st.columns([1, 4])
                                with col1:
                                    st.markdown(f"## {suggestion['title'].split(' ')[0]}")
                                with col2:
                                    st.markdown(f"**{suggestion['title']}**")
                                
                                st.caption(suggestion['description'])
                                
                                if st.button("Utiliser cette analyse", 
                                           key=f"goal_btn_{i}",
                                           use_container_width=True,
                                           type="secondary"):
                                    query_key = f"natural_language_query_{suggestion['code_type'].lower()}"
                                    st.session_state[query_key] = suggestion['query']
                                    st.session_state.query_type = suggestion['code_type']
                                    st.session_state.show_generated_code = True
                                    st.rerun()
                else:
                    st.info("Aucune suggestion sp√©cifique n'a pu √™tre g√©n√©r√©e √† partir de vos objectifs.")
                    st.markdown("""
                    Pour obtenir des suggestions plus pertinentes, vous pouvez :
                    - √ätre plus pr√©cis dans vos objectifs d'analyse
                    - Mentionner des variables sp√©cifiques que vous souhaitez analyser
                    - D√©crire le type d'analyse que vous souhaitez effectuer
                    """)
        
        st.markdown("---")
        
        # D√©tection automatique des types de variables pour les suggestions
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
        cat_cols = st.session_state.df_clean.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()
        date_cols = st.session_state.df_clean.select_dtypes(include=['datetime64']).columns.tolist()
        
        # S√©lection du type de requ√™te
        query_type = st.radio("Type de requ√™te :", ["SQL", "Python"], horizontal=True, key="query_type")
        
        # Zone de saisie de la requ√™te en langage naturel
        query = st.text_area(
            f"D√©crivez en langage naturel ce que vous souhaitez faire ({query_type}):",
            key=f"natural_language_query_{query_type.lower()}",
            height=100,
            placeholder="Ex: Afficher la moyenne des ventes par cat√©gorie et par mois",
            value=st.session_state.get(f"natural_language_query_{query_type.lower()}", "")
        )
        # Bouton pour g√©n√©rer le code
        if st.button("G√©n√©rer le code", key="generate_code_btn_sql"):
            if not query.strip():
                st.warning("Veuillez entrer une description de ce que vous souhaitez faire.")
            else:
                with st.spinner("G√©n√©ration du code en cours..."):
                    try:
                        # G√©n√©rer le code en fonction du type s√©lectionn√©
                        df_columns = st.session_state.df_clean.columns.tolist()
                        generated_code = generate_code_from_natural_language(
                            query,
                            'sql' if query_type == "SQL" else 'python',
                            df_columns
                        )
                        
                        # Stocker le code g√©n√©r√© dans la session
                        st.session_state.generated_code = generated_code
                        st.session_state.show_generated_code = True
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du code : {str(e)}")
        
        # Afficher le code g√©n√©r√© s'il existe
        if hasattr(st.session_state, 'generated_code') and st.session_state.generated_code:
            st.markdown("### Code g√©n√©r√© :")
            st.code(st.session_state.generated_code, language='python' if query_type == "Python" else 'sql')
            
            # Bouton pour ex√©cuter le code
            if st.button("Ex√©cuter le code", key="execute_code_btn"):
                with st.spinner("Ex√©cution en cours..."):
                    try:
                        # Ex√©cuter le code g√©n√©r√©
                        if query_type == "SQL":
                            success, message, result = execute_sql_query(
                                st.session_state.generated_code,
                                st.session_state.df_clean
                            )
                        else:  # Python
                            # Cr√©er un espace de noms pour l'ex√©cution du code
                            local_vars = {'df': st.session_state.df_clean, 'st': st, 'plt': plt, 'px': px}
                            global_vars = {}
                            
                            # Ex√©cuter le code Python
                            exec(st.session_state.generated_code, global_vars, local_vars)
                            
                            # R√©cup√©rer le r√©sultat si une variable 'result' a √©t√© d√©finie
                            result = local_vars.get('result', None)
                            success = result is not None
                            message = "Ex√©cution r√©ussie" if success else "Aucun r√©sultat √† afficher"
                        
                        # Afficher le r√©sultat
                        if success and result is not None:
                            if hasattr(result, 'head') and hasattr(result, 'to_csv'):  # C'est un DataFrame
                                st.dataframe(result.head(100))
                                
                                # Boutons d'export
                                csv = result.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    "T√©l√©charger en CSV",
                                    csv,
                                    "resultat_analyse.csv",
                                    "text/csv",
                                    key='download-csv'
                                )
                                
                                # G√©n√©rer une interpr√©tation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("üîç Interpr√©tation des r√©sultats"):
                                    st.write(interpretation)
                            
                            elif isinstance(result, (dict, list)):  # R√©sultat structur√©
                                st.json(result)
                                
                                # G√©n√©rer une interpr√©tation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("üîç Interpr√©tation des r√©sultats"):
                                    st.write(interpretation)
                            
                            # V√©rifier si un graphique a √©t√© affich√© (via st.pyplot ou st.plotly_chart)
                            if 'plt' in locals() and plt.gcf().get_axes():
                                st.pyplot(plt.gcf())
                        
                        if not success:
                            st.warning(message)
                            
                    except Exception as e:
                        st.error(f"Erreur lors de l'ex√©cution du code : {str(e)}")
                        st.exception(e)
        
        # Affichage des suggestions bas√©es sur le contexte
        st.markdown("### üí° Suggestions de requ√™tes bas√©es sur votre contexte")
        
        # Zone de saisie de la requ√™te en langage naturel
        query = st.text_area(
            f"D√©crivez en langage naturel ce que vous souhaitez faire ({query_type}):",
            key="natural_language_query",
            height=100,
            placeholder="Ex: Afficher la moyenne des ventes par cat√©gorie et par mois"
        )
        
        # Bouton pour g√©n√©rer le code
        if st.button("G√©n√©rer le code", key="generate_code_btn_python"):
            if not query.strip():
                st.warning("Veuillez entrer une description de ce que vous souhaitez faire.")
            else:
                with st.spinner("G√©n√©ration du code en cours..."):
                    try:
                        # G√©n√©rer le code en fonction du type s√©lectionn√©
                        df_columns = st.session_state.df_clean.columns.tolist()
                        generated_code = generate_code_from_natural_language(
                            query,
                            'sql' if query_type == "SQL" else 'python',
                            df_columns
                        )
                        
                        # Stocker le code g√©n√©r√© dans la session
                        st.session_state.generated_code = generated_code
                        st.session_state.show_generated_code = True
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du code : {str(e)}")
        
        # Afficher le code g√©n√©r√© s'il existe
        if hasattr(st.session_state, 'generated_code') and st.session_state.generated_code:
            st.markdown("### Code g√©n√©r√© :")
            st.code(st.session_state.generated_code, language='python' if query_type == "Python" else 'sql')
            
            # Bouton pour ex√©cuter le code
            if st.button("Ex√©cuter le code", key="execute_code_btn"):
                with st.spinner("Ex√©cution en cours..."):
                    try:
                        # Ex√©cuter le code g√©n√©r√©
                        if query_type == "SQL":
                            success, message, result = execute_sql_query(
                                st.session_state.generated_code,
                                st.session_state.df_clean
                            )
                        else:  # Python
                            # Cr√©er un espace de noms pour l'ex√©cution du code
                            local_vars = {'df': st.session_state.df_clean, 'st': st, 'plt': plt, 'px': px}
                            global_vars = {}
                            
                            # Ex√©cuter le code Python
                            exec(st.session_state.generated_code, global_vars, local_vars)
                            
                            # R√©cup√©rer le r√©sultat si une variable 'result' a √©t√© d√©finie
                            result = local_vars.get('result', None)
                            success = result is not None
                            message = "Ex√©cution r√©ussie" if success else "Aucun r√©sultat √† afficher"
                        
                        # Afficher le r√©sultat
                        if success and result is not None:
                            if hasattr(result, 'head') and hasattr(result, 'to_csv'):  # C'est un DataFrame
                                st.dataframe(result.head(100))
                                
                                # Boutons d'export
                                csv = result.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    "T√©l√©charger en CSV",
                                    csv,
                                    "resultat_analyse.csv",
                                    "text/csv",
                                    key='download-csv'
                                )
                                
                                # G√©n√©rer une interpr√©tation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("üîç Interpr√©tation des r√©sultats"):
                                    st.write(interpretation)
                            
                            elif isinstance(result, (dict, list)):  # R√©sultat structur√©
                                st.json(result)
                                
                                # G√©n√©rer une interpr√©tation automatique
                                interpretation = generate_interpretation(result)
                                with st.expander("üîç Interpr√©tation des r√©sultats"):
                                    st.write(interpretation)
                            
                            # V√©rifier si un graphique a √©t√© affich√© (via st.pyplot ou st.plotly_chart)
                            if 'plt' in locals() and plt.gcf().get_axes():
                                st.pyplot(plt.gcf())
                        
                        if not success:
                            st.warning(message)
                            
                    except Exception as e:
                        st.error(f"Erreur lors de l'ex√©cution du code : {str(e)}")
                        st.exception(e)
                st.markdown("#### üîÑ Analyse des relations entre variables num√©riques et cat√©gorielles")
                
                # S√©lection des variables pour l'analyse crois√©e
                num_col = st.selectbox("S√©lectionnez une variable num√©rique", numeric_cols, key="num_col_cross")
                cat_col = st.selectbox("S√©lectionnez une variable cat√©gorielle", cat_cols, key="cat_col_cross")
                
                if st.button("Analyser la relation", key="analyze_relation_btn"):
                    with st.spinner("Analyse en cours..."):
                        try:
                            # Cr√©ation d'une figure avec plusieurs sous-graphiques
                            import plotly.subplots as sp
                            from plotly import graph_objects as go
                            
                            # Cr√©ation de la figure avec 2 lignes et 2 colonnes
                            fig = sp.make_subplots(
                                rows=2, cols=2,
                                subplot_titles=(
                                    f'Distribution de {num_col} par {cat_col}',
                                    f'Bo√Ætes √† moustaches',
                                    f'Statistiques descriptives',
                                    f'Test statistique ANOVA'
                                ),
                                vertical_spacing=0.15,
                                specs=[[{"type": "histogram"}, {"type": "box"}],
                                      [{"colspan": 2, "type": "table"}, None]]
                            )
                            
                            # 1. Histogramme group√©
                            hist_data = []
                            for category in st.session_state.df_clean[cat_col].unique():
                                hist_data.append(go.Histogram(
                                    x=st.session_state.df_clean[st.session_state.df_clean[cat_col] == category][num_col],
                                    name=str(category),
                                    opacity=0.7
                                ))
                            
                            for trace in hist_data:
                                fig.add_trace(trace, row=1, col=1)
                            
                            # 2. Bo√Ætes √† moustaches
                            box_data = []
                            for category in st.session_state.df_clean[cat_col].unique():
                                box_data.append(go.Box(
                                    y=st.session_state.df_clean[st.session_state.df_clean[cat_col] == category][num_col],
                                    name=str(category)
                                ))
                            
                            for trace in box_data:
                                fig.add_trace(trace, row=1, col=2)
                            
                            # 3. Tableau des statistiques descriptives
                            stats_df = st.session_state.df_clean.groupby(cat_col)[num_col].describe().T
                            
                            fig.add_trace(
                                go.Table(
                                    header=dict(
                                        values=['Statistique'] + [str(x) for x in stats_df.columns],
                                        font=dict(size=10),
                                        align="left"
                                    ),
                                    cells=dict(
                                        values=[stats_df.index] + [stats_df[col] for col in stats_df.columns],
                                        align = "left")
                                ),
                                row=2, col=1
                            )
                            
                            # 4. Test ANOVA
                            from scipy import stats
                            
                            # Pr√©paration des donn√©es pour l'ANOVA
                            groups = [st.session_state.df_clean[st.session_state.df_clean[cat_col] == category][num_col] 
                                     for category in st.session_state.df_clean[cat_col].unique()]
                            
                            # V√©rification des conditions d'application de l'ANOVA
                            try:
                                # V√©rification de la normalit√© avec Shapiro-Wilk
                                normality = True
                                for group in groups:
                                    if len(group) > 3 and len(group) < 5000:  # Shapiro est fiable pour des √©chantillons jusqu'√† 5000
                                        _, p_value = stats.shapiro(group)
                                        if p_value < 0.05:
                                            normality = False
                                            break
                            except Exception as e:
                                st.warning(f"Erreur lors du test de normalit√© : {str(e)}")
                                normality = False  # En cas d'erreur, on suppose la non-normalit√©
                            
                            if len(groups) >= 2:
                                if normality and len(groups) == 2:
                                    # Test t pour 2 groupes
                                    t_stat, p_value = stats.ttest_ind(*groups, equal_var=False)
                                    test_name = "Test t de Student (2 √©chantillons ind√©pendants)"
                                    test_result = f"t = {t_stat:.3f}, p-value = {p_value:.4f}"
                                elif len(groups) > 2 and normality:
                                    # ANOVA pour plus de 2 groupes
                                    f_stat, p_value = stats.f_oneway(*groups)
                                    test_name = "Analyse de la variance (ANOVA)"
                                    test_result = f"F = {f_stat:.3f}, p-value = {p_value:.4f}"
                                else:
                                    # Test non param√©trique de Kruskal-Wallis
                                    h_stat, p_value = stats.kruskal(*groups)
                                    test_name = "Test de Kruskal-Wallis (non param√©trique)"
                                    test_result = f"H = {h_stat:.3f}, p-value = {p_value:.4f}"
                                
                                # Interpr√©tation du test
                                interpretation = ""
                                if p_value < 0.05:
                                    interpretation = f"<span style='color:green'>Diff√©rence statistiquement significative entre les groupes (p < 0.05)</span>"
                                else:
                                    interpretation = f"<span style='color:orange'>Aucune diff√©rence statistiquement significative d√©tect√©e entre les groupes (p ‚â• 0.05)</span>"
                                
                                # Ajout des r√©sultats du test
                                test_results = [
                                    ["Test utilis√©", test_name],
                                    ["R√©sultat", test_result],
                                    ["Interpr√©tation", interpretation]
                                ]
                                
                                fig.add_trace(
                                    go.Table(
                                        header=dict(
                                            values=['M√©trique', 'Valeur'],
                                            font=dict(size=10),
                                            align="left"
                                        ),
                                        cells=dict(
                                            values=[[x[0] for x in test_results], 
                                                   [x[1] for x in test_results]],
                                            align = "left",
                                            height=25
                                        )
                                    ),
                                    row=2, col=2
                                )
                            
                            # Mise en page finale
                            fig.update_layout(
                                height=900,
                                showlegend=True,
                                title_text=f"Analyse crois√©e : {num_col} par {cat_col}",
                                margin=dict(t=100, b=50, l=50, r=50)
                            )
                            
                            # Affichage de la figure
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # G√©n√©ration d'une interpr√©tation automatique
                            interpretation_prompt = f"""
                            Je vais analyser la relation entre la variable num√©rique '{num_col}' et la variable cat√©gorielle '{cat_col}'. 
                            Voici un aper√ßu des donn√©es :
                            {st.session_state.df_clean[[num_col, cat_col]].describe().to_string()}
                            
                            Voici les r√©sultats du test statistique : {test_name}
                            R√©sultat : {test_result}
                            
                            Peux-tu fournir une interpr√©tation claire et concise de ces r√©sultats en fran√ßais, en expliquant ce que cela signifie pour un utilisateur non technique ?
                            """
                            
                            interpretation = call_gemini_api(interpretation_prompt)
                            
                            with st.expander("üìù Interpr√©tation des r√©sultats", expanded=True):
                                st.markdown(interpretation)
                            
                            # Sauvegarde de l'analyse
                            if 'cross_analyses' not in st.session_state:
                                st.session_state.cross_analyses = []
                                
                            st.session_state.cross_analyses.append({
                                'num_var': num_col,
                                'cat_var': cat_col,
                                'interpretation': interpretation,
                                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            })
                            
                            st.success("Analyse crois√©e termin√©e avec succ√®s !")
                            
                        except Exception as e:
                            st.error(f"Une erreur est survenue lors de l'analyse crois√©e : {str(e)}")
                            st.exception(e)
            
        # Section pour les analyses num√©riques
        elif analysis_type == "Num√©rique vs Num√©rique" and len(numeric_cols) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                num_col1 = st.selectbox("Premi√®re variable num√©rique", numeric_cols, key="num_col1")
            with col2:
                num_col2 = st.selectbox("Deuxi√®me variable num√©rique", 
                                     [col for col in numeric_cols if col != num_col1], 
                                     key="num_col2")
            
            if st.button("Analyser la corr√©lation", key="analyze_correlation_btn"):
                with st.spinner("Analyse en cours..."):
                    try:
                        # Cr√©ation d'une figure avec plusieurs sous-graphiques
                        import plotly.subplots as sp
                        from plotly import graph_objects as go
                        import numpy as np
                        
                        # Cr√©ation de la figure avec 2x2 sous-graphiques
                        fig = sp.make_subplots(
                            rows=2, cols=2,
                            subplot_titles=(
                                f'Nuage de points {num_col1} vs {num_col2}',
                                f'Distribution de {num_col1}',
                                f'Distribution de {num_col2}',
                                'Matrice de corr√©lation'
                            ),
                            vertical_spacing=0.15
                        )
                        
                        # 1. Nuage de points
                        fig.add_trace(
                            go.Scatter(
                                x=st.session_state.df_clean[num_col1],
                                y=st.session_state.df_clean[num_col2],
                                mode='markers',
                                opacity=0.6,
                                name='Donn√©es',
                                showlegend=False
                            ),
                            row=1, col=1
                        )
                        
                        # 2. Distribution de la premi√®re variable
                        fig.add_trace(
                            go.Histogram(
                                x=st.session_state.df_clean[num_col1],
                                name=num_col1,
                                showlegend=False
                            ),
                            row=1, col=2
                        )
                        
                        # 3. Distribution de la deuxi√®me variable
                        fig.add_trace(
                            go.Histogram(
                                x=st.session_state.df_clean[num_col2],
                                name=num_col2,
                                showlegend=False
                            ),
                            row=2, col=1
                        )
                        
                        # 4. Matrice de corr√©lation
                        corr = st.session_state.df_clean[[num_col1, num_col2]].corr().values
                        
                        fig.add_trace(
                            go.Heatmap(
                                z=corr,
                                x=[num_col1, num_col2],
                                y=[num_col1, num_col2],
                                colorscale='Viridis',
                                showscale=True,
                                zmin=-1,
                                zmax=1
                            ),
                            row=2, col=2
                        )
                        
                        # Mise en page finale
                        fig.update_layout(
                            height=800,
                            title_text=f"Analyse de corr√©lation : {num_col1} vs {num_col2}",
                            margin=dict(t=100, b=50, l=50, r=50)
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Calcul des statistiques de corr√©lation
                        from scipy import stats
                        
                        # Corr√©lation de Pearson
                        pearson_corr, pearson_p = stats.pearsonr(
                            st.session_state.df_clean[num_col1].dropna(),
                            st.session_state.df_clean[num_col2].dropna()
                        )
                        
                        # Corr√©lation de Spearman (non lin√©aire)
                        spearman_corr, spearman_p = stats.spearmanr(
                            st.session_state.df_clean[num_col1].dropna(),
                            st.session_state.df_clean[num_col2].dropna()
                        )
                        
                        # Interpr√©tation des r√©sultats
                        interpretation = f"""
                        ## üìä Analyse de corr√©lation
                        
                        ### Corr√©lation de Pearson (lin√©aire):
                        - Coefficient: {pearson_corr:.3f}
                        - P-valeur: {pearson_p:.4f}
                        
                        ### Corr√©lation de Spearman (monotone):
                        - Coefficient: {spearman_corr:.3f}
                        - P-valeur: {spearman_p:.4f}
                        
                        ### Interpr√©tation :
                        """
                        
                        # Ajout d'une interpr√©tation bas√©e sur la force de la corr√©lation
                        abs_pearson = abs(pearson_corr)
                        if abs_pearson > 0.7:
                            interpretation += "Corr√©lation forte "
                        elif abs_pearson > 0.3:
                            interpretation += "Corr√©lation mod√©r√©e "
                        else:
                            interpretation += "Corr√©lation faible "
                            
                        interpretation += f"entre {num_col1} et {num_col2}."
                        
                        if pearson_p < 0.05:
                            interpretation += " Cette relation est statistiquement significative (p < 0.05)."
                        else:
                            interpretation += " Cette relation n'est pas statistiquement significative (p ‚â• 0.05)."
                        
                        st.markdown(interpretation)
                        
                        # Sauvegarde de l'analyse
                        if 'correlation_analyses' not in st.session_state:
                            st.session_state.correlation_analyses = []
                            
                        st.session_state.correlation_analyses.append({
                            'var1': num_col1,
                            'var2': num_col2,
                            'pearson_corr': pearson_corr,
                            'spearman_corr': spearman_corr,
                            'interpretation': interpretation,
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        
                        st.success("Analyse de corr√©lation termin√©e avec succ√®s !")
                        
                    except Exception as e:
                        st.error(f"Une erreur est survenue lors de l'analyse de corr√©lation : {str(e)}")
                        st.exception(e)
        
        # Section pour les analyses cat√©gorielles
        elif analysis_type == "Cat√©gorielle vs Cat√©gorielle" and len(cat_cols) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                cat_col1 = st.selectbox("Premi√®re variable cat√©gorielle", cat_cols, key="cat_col1")
            with col2:
                cat_col2 = st.selectbox("Deuxi√®me variable cat√©gorielle", 
                                     [col for col in cat_cols if col != cat_col1], 
                                     key="cat_col2")
            
            if st.button("Analyser l'association", key="analyze_association_btn"):
                with st.spinner("Analyse en cours..."):
                    try:
                        # Cr√©ation d'un tableau de contingence
                        contingency_table = pd.crosstab(
                            st.session_state.df_clean[cat_col1],
                            st.session_state.df_clean[cat_col2],
                            margins=True
                        )
                        
                        # Calcul du khi-deux
                        from scipy.stats import chi2_contingency
                        chi2, p, dof, expected = chi2_contingency(
                            pd.crosstab(st.session_state.df_clean[cat_col1], st.session_state.df_clean[cat_col2])
                        )
                        
                        # Cr√©ation de la figure
                        import plotly.graph_objects as go
                        from plotly.subplots import make_subplots
                        
                        fig = make_subplots(
                            rows=2, cols=2,
                            subplot_titles=(
                                f'Tableau de contingence',
                                f'Heatmap des effectifs',
                                f'Pourcentages en ligne',
                                f'Pourcentages en colonne'
                            ),
                            specs=[[{"type": "table"}, {"type": "heatmap"}],
                                 [{"type": "heatmap"}, {"type": "heatmap"}]]
                        )
                        
                        # 1. Tableau de contingence
                        fig.add_trace(
                            go.Table(
                                header=dict(
                                    values=[cat_col1] + contingency_table.columns.tolist(),
                                    font=dict(size=10),
                                    align="left"
                                ),
                                cells=dict(
                                    values=[contingency_table.index] + [contingency_table[col] for col in contingency_table.columns],
                                    align = "left"
                                )
                            ),
                            row=1, col=1
                        )
                        
                        # 2. Heatmap des effectifs
                        fig.add_trace(
                            go.Heatmap(
                                z=contingency_table.values,
                                x=contingency_table.columns,
                                y=contingency_table.index,
                                text=contingency_table.values,
                                texttemplate="%{text}",
                                colorscale='Viridis'
                            ),
                            row=1, col=2
                        )
                        
                        # 3. Pourcentages en ligne
                        row_pct = contingency_table.div(contingency_table["All"], axis=0) * 100
                        fig.add_trace(
                            go.Heatmap(
                                z=row_pct.values,
                                x=row_pct.columns,
                                y=row_pct.index,
                                text=row_pct.round(1).astype(str) + "%",
                                texttemplate="%{text}",
                                colorscale='Blues'
                            ),
                            row=2, col=1
                        )
                        
                        # 4. Pourcentages en colonne
                        col_pct = contingency_table.div(contingency_table.loc["All"], axis=1) * 100
                        fig.add_trace(
                            go.Heatmap(
                                z=col_pct.values,
                                x=col_pct.columns,
                                y=col_pct.index,
                                text=col_pct.round(1).astype(str) + "%",
                                texttemplate="%{text}",
                                colorscale='Greens'
                            ),
                            row=2, col=2
                        )
                        
                        # Mise en page finale
                        fig.update_layout(
                            height=1000,
                            title_text=f"Analyse d'association : {cat_col1} vs {cat_col2}",
                            margin=dict(t=100, b=50, l=50, r=50)
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Interpr√©tation des r√©sultats
                        interpretation = f"""
                        ## üìä Analyse d'association entre variables cat√©gorielles
                        
                        ### Test du Khi-deux d'ind√©pendance :
                        - Khi-deux = {chi2:.3f}
                        - Degr√©s de libert√© = {dof}
                        - P-valeur = {p:.4f}
                        
                        ### Interpr√©tation :
                        """
                        
                        if p < 0.05:
                            interpretation += f"Il existe une association statistiquement significative entre {cat_col1} et {cat_col2} (p < 0.05)."
                        else:
                            interpretation += f"Aucune association statistiquement significative n'a √©t√© d√©tect√©e entre {cat_col1} et {cat_col2} (p ‚â• 0.05)."
                        
                        st.markdown(interpretation)
                        
                        # Sauvegarde de l'analyse
                        if 'association_analyses' not in st.session_state:
                            st.session_state.association_analyses = []
                            
                        st.session_state.association_analyses.append({
                            'var1': cat_col1,
                            'var2': cat_col2,
                            'chi2': chi2,
                            'p_value': p,
                            'dof': dof,
                            'interpretation': interpretation,
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        
                        st.success("Analyse d'association termin√©e avec succ√®s !")
                        
                    except Exception as e:
                        st.error(f"Une erreur est survenue lors de l'analyse d'association : {str(e)}")
                        st.exception(e)
        
        # Section pour les requ√™tes personnalis√©es avec IA
        st.markdown("---")
        st.markdown("## üîç Requ√™tes personnalis√©es avanc√©es")
        
        # Informations sur les donn√©es disponibles
        st.caption(f"üìä Donn√©es disponibles : {len(st.session_state.df_clean)} lignes, {len(st.session_state.df_clean.columns)} colonnes")
        
        # Aper√ßu rapide des colonnes
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üìã Afficher la structure des donn√©es", key="show_data_structure"):
                st.session_state.show_data_structure = not st.session_state.get('show_data_structure', False)
        
        if st.session_state.get('show_data_structure', False):
            st.dataframe(pd.DataFrame({
                'Colonne': st.session_state.df_clean.columns,
                'Type': st.session_state.df_clean.dtypes.astype(str).values,
                'Valeurs uniques': [st.session_state.df_clean[col].nunique() for col in st.session_state.df_clean.columns],
                'Valeurs manquantes': st.session_state.df_clean.isnull().sum().values
            }), use_container_width=True, height=300)
        
        # S√©lection du type de requ√™te avec des onglets
        query_type = st.radio(
            "Type de requ√™te :",
            ["SQL", "Python"],
            horizontal=True,
            key="query_type_selector"
        )
        
        # Exemples de requ√™tes en fonction du contexte
        if 'context_objectif' in st.session_state and st.session_state.context_objectif:
            with st.expander("üí° Suggestions de requ√™tes bas√©es sur votre contexte"):
                st.caption("Voici quelques exemples de requ√™tes qui pourraient √™tre utiles :")
                if query_type == "SQL":
                    st.code("""-- Exemple 1: Aper√ßu des donn√©es
SELECT * FROM df LIMIT 5;

-- Exemple 2: Statistiques descriptives
SELECT 
    AVG(prix) as prix_moyen,
    MIN(prix) as prix_min,
    MAX(prix) as prix_max,
    COUNT(*) as nb_elements
FROM df;

-- Exemple 3: Regroupement et agr√©gation
SELECT 
    categorie,
    COUNT(*) as nb_produits,
    AVG(prix) as prix_moyen
FROM df
GROUP BY categorie
ORDER BY prix_moyen DESC;""", language='sql')
                else:
                    st.code("""# Exemple 1: Aper√ßu des donn√©es
df.head()

# Exemple 2: Statistiques descriptives
df.describe()

# Exemple 3: Graphique de distribution
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='prix', bins=30)
plt.title('Distribution des prix')
plt.show()""", language='python')
        
        # Saisie de la requ√™te en langage naturel avec assistance
        natural_query = st.text_area(
            f"D√©crivez en langage naturel ce que vous souhaitez faire ({query_type}):",
            placeholder=f"Ex: Afficher les 10 premi√®res lignes avec les colonnes 'prix' et 'surface' tri√©es par prix d√©croissant",
            height=100,
            value=st.session_state.get('natural_language_query', ''),
            key=f"natural_query_{query_type}",
            help="D√©crivez votre besoin en langage naturel, l'IA se chargera de g√©n√©rer le code appropri√©."
        )
        
        # V√©rifier si on doit d√©clencher une ex√©cution automatique
        auto_execute = st.session_state.pop('auto_execute_analysis', False)
        
        # Options avanc√©es
        with st.expander("‚öôÔ∏è Options avanc√©es"):
            st.checkbox(
                "Afficher les explications du code g√©n√©r√©",
                value=st.session_state.get('show_code_explanations', True),
                key='show_code_explanations',
                help="Affiche des explications d√©taill√©es sur le code g√©n√©r√©"
            )
            
            st.checkbox(
                "Ex√©cuter automatiquement apr√®s g√©n√©ration",
                value=st.session_state.get('auto_execute_code', False),
                key='auto_execute_code',
                help="Ex√©cute automatiquement le code apr√®s sa g√©n√©ration"
            )
        
        # Boutons d'action
        col1, col2 = st.columns([1, 3])
        with col1:
            generate_btn = st.button("‚ú® G√©n√©rer le code", 
                                   key=f"generate_{query_type}_btn",
                                   use_container_width=True)
        
        # Bouton pour effacer
        with col2:
            if st.button("üóëÔ∏è Effacer", 
                        key=f"clear_query_btn",
                        use_container_width=True):
                st.session_state.pop('generated_code', None)
                st.session_state.pop('last_execution', None)
                st.rerun()
        
        # G√©n√©ration du code
        if generate_btn:
            if not natural_query.strip():
                st.warning("Veuillez d√©crire ce que vous souhaitez faire avant de g√©n√©rer le code.")
            else:
                with st.spinner("üß† G√©n√©ration du code en cours..."):
                    try:
                        # G√©n√©ration du code √† partir du langage naturel
                        df_columns = st.session_state.df_clean.columns.tolist()
                        
                        # Ajout du contexte utilisateur pour am√©liorer la pertinence
                        context_info = ""
                        if 'context_objectif' in st.session_state and st.session_state.context_objectif:
                            context_info = f"\nContexte du projet : {st.session_state.context_objectif}\n"
                        
                        # G√©n√©ration du code avec le contexte
                        generated_code = generate_code_from_natural_language(
                            query=f"{context_info}\n{natural_query}",
                            query_type=query_type.lower(),
                            df_columns=df_columns
                        )
                        
                        # D√©tection du type d'analyse
                        analysis_type = detect_analysis_type(natural_query)
                        
                        # Mise √† jour de l'interface avec le code g√©n√©r√©
                        st.session_state.generated_code = generated_code
                        st.session_state.show_generated_code = True
                        st.session_state.code_type = query_type.lower()
                        st.session_state.current_analysis_type = analysis_type
                        
                        # Ex√©cution automatique si activ√©e ou si d√©clench√©e par une suggestion
                        if st.session_state.get('auto_execute_code', False) or auto_execute:
                            st.session_state.execute_generated_code = True
                            
                            # Pour les analyses de s√©rie temporelle, on active automatiquement l'onglet
                            if analysis_type == 'time_series':
                                st.session_state.selected_analysis = 'time_series'
                        
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du code : {str(e)}")
                        st.exception(e)  # Affiche plus de d√©tails sur l'erreur
        
        # Affichage du code g√©n√©r√© et options d'ex√©cution
        if st.session_state.get('show_generated_code', False) and st.session_state.generated_code:
            st.markdown("---")
            st.markdown("#### Code g√©n√©r√©")
            st.code(st.session_state.generated_code, language=st.session_state.get('code_type', 'python'))
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üîÑ Ex√©cuter le code", key="execute_generated_code_btn"):
                    try:
                        # Ex√©cution du code g√©n√©r√©
                        success, message, result = execute_code(
                            code=st.session_state.generated_code,
                            code_type=st.session_state.code_type,
                            df=st.session_state.df_clean
                        )
                        
                        if success:
                            st.session_state.last_execution = {
                                'success': True,
                                'message': message,
                                'result': result,
                                'code': st.session_state.generated_code,
                                'code_type': st.session_state.code_type,
                                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            }
                            st.success(message)
                            
                            # Affichage du r√©sultat
                            if result is not None:
                                if isinstance(result, pd.DataFrame):
                                    st.dataframe(result)
                                    
                                    # Bouton d'export
                                    csv = result.to_csv(index=False).encode('utf-8')
                                    st.download_button(
                                        label="üíæ Exporter les r√©sultats (CSV)",
                                        data=csv,
                                        file_name=f"resultat_requete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        mime="text/csv"
                                    )
                                else:
                                    st.write(result)
                        else:
                            st.error(f"Erreur lors de l'ex√©cution : {message}")
                            
                    except Exception as e:
                        st.error(f"Erreur lors de l'ex√©cution du code : {str(e)}")
            
            with col2:
                if st.button("‚úèÔ∏è Modifier le code", key="edit_code_btn"):
                    st.session_state.editing_code = not st.session_state.get('editing_code', False)
                    st.rerun()
            
            # Section d'√©dition manuelle du code
            if st.session_state.get('editing_code', False):
                edited_code = st.text_area(
                    "Modifiez le code si n√©cessaire :",
                    value=st.session_state.generated_code,
                    height=200,
                    key="code_editor"
                )
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üíæ Enregistrer et ex√©cuter", key="save_execute_btn", type="primary"):
                        st.session_state.generated_code = edited_code
                        st.session_state.editing_code = False
                        st.session_state.execute_generated_code = True
                        st.rerun()
                    
                    if st.button("üíæ Enregistrer seulement", key="save_code_btn"):
                        st.session_state.generated_code = edited_code
                        st.session_state.editing_code = False
                        st.rerun()
                
                with col2:
                    if st.button("‚ùå Annuler", key="cancel_edit_btn"):
                        st.session_state.editing_code = False
                        st.rerun()
                
                st.markdown("---")
            
            # Affichage des r√©sultats de l'ex√©cution
            if st.session_state.get('last_execution') and st.session_state.last_execution.get('success'):
                st.markdown("### üìä R√©sultats de l'analyse")
                
                # Affichage des r√©sultats en fonction du type d'analyse
                if st.session_state.get('current_analysis_type') == 'time_series':
                    st.success("Analyse des s√©ries temporelles termin√©e avec succ√®s!")
                    
                    # Ajout d'un bouton pour voir les d√©tails de l'analyse
                    if st.button("üìà Voir l'analyse d√©taill√©e", key="view_time_series_btn"):
                        st.session_state.selected_analysis = 'time_series'
                        st.rerun()
                
                # Affichage g√©n√©rique des r√©sultats
                elif 'result' in st.session_state.last_execution and st.session_state.last_execution['result'] is not None:
                    result = st.session_state.last_execution['result']
                    if isinstance(result, pd.DataFrame):
                        st.dataframe(result)
                        
                        # Bouton d'export CSV
                        csv = result.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="üíæ Exporter les r√©sultats (CSV)",
                            data=csv,
                            file_name=f"resultat_analyse_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.write(result)
        
        # Affichage des r√©sultats de la derni√®re ex√©cution
        if 'last_execution' in st.session_state and st.session_state.last_execution:
            st.markdown("---")
            st.markdown("### üìú Derni√®re ex√©cution")
            exec_data = st.session_state.last_execution
            st.caption(f"Ex√©cut√© le {exec_data['timestamp']}")
            st.code(exec_data['code'], language=exec_data['code_type'])
            
            if exec_data['success'] and exec_data['result'] is not None:
                if isinstance(exec_data['result'], pd.DataFrame):
                    st.dataframe(exec_data['result'].head())
                    st.caption(f"Aper√ßu des donn√©es ({len(exec_data['result'])} lignes au total)")
                else:
                    st.write(exec_data['result'])
            
            if not exec_data['success']:
                st.error(exec_data['message'])
        
        # Section pour les requ√™tes manuelles (SQL et Python)
        with st.expander("üîß Requ√™tes manuelles", expanded=False):
            st.markdown("### Ex√©cuter des requ√™tes manuelles")
            
            # Onglets pour SQL et Python
            sql_tab, python_tab = st.tabs(["üî∑ SQL", "üêç Python"])

            with sql_tab:
                st.markdown("#### Requ√™te SQL")
                st.info("Utilisez 'df' comme nom de table dans vos requ√™tes SQL.")
                sql_query = st.text_area(
                    "Entrez votre requ√™te SQL :",
                    height=150,
                    key="sql_query_input"
                )

                if st.button("Ex√©cuter la requ√™te SQL", key="run_sql_btn"):
                    try:
                        result = sqldf(sql_query, {'df': st.session_state.df_clean})
                        st.session_state.sql_queries[sql_query] = result
                        st.success(f"Requ√™te ex√©cut√©e avec succ√®s. {len(result)} lignes retourn√©es.")

                        # Afficher les r√©sultats
                        st.dataframe(result)


                        # Bouton pour sauvegarder les r√©sultats
                        csv = result.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="üíæ Exporter les r√©sultats (CSV)",
                            data=csv,
                            file_name=f"resultat_requete_{len(st.session_state.sql_queries)}.csv",
                            mime="text/csv"
                        )

                    except Exception as e:
                        st.error(f"Erreur lors de l'ex√©cution de la requ√™te : {str(e)}")

            with python_tab:
                st.markdown("#### Code Python")
                st.info("Utilisez 'df' pour acc√©der √† votre DataFrame. Stockez le r√©sultat dans 'result'.")
                python_code = st.text_area(
                    "Entrez votre code Python :",
                    height=200,
                    key="python_code_input"
                )

                if st.button("Ex√©cuter le code Python", key="run_python_btn"):
                    try:
                        # Ex√©cution s√©curis√©e du code
                        success, message, result = execute_code(
                            code=python_code,
                            code_type='python',
                            df=st.session_state.df_clean
                        )
                        
                        if success:
                            st.session_state.python_queries[python_code] = result
                            st.success(message)
                            
                            # Afficher le r√©sultat
                            if result is not None:
                                if isinstance(result, pd.DataFrame):
                                    st.dataframe(result)
                                    
                                    # Bouton pour sauvegarder les r√©sultats
                                    csv = result.to_csv(index=False).encode('utf-8')
                                    st.download_button(
                                        label="üíæ Exporter les r√©sultats (CSV)",
                                        data=csv,
                                        file_name=f"resultat_python_{len(st.session_state.python_queries)}.csv",
                                        mime="text/csv"
                                    )
                                else:
                                    st.write(result)
                        else:
                            st.error(message)

                    except Exception as e:
                        st.error(f"Erreur lors de l'ex√©cution du code : {str(e)}")

        # Section pour la g√©n√©ration du rapport
        with st.expander("üìë G√©n√©ration du rapport", expanded=False):
            st.markdown("### Options du rapport")

            col1, col2 = st.columns(2)

            with col1:
                # Options d'export
                export_format = st.selectbox(
                    "Format du rapport",
                    ["HTML", "PDF", "Excel"],
                    index=0,
                    key="export_format"
                )

                # Options d'inclusion
                st.markdown("**√âl√©ments √† inclure :**")
                include_summary = st.checkbox("R√©sum√© ex√©cutif", value=True, key="include_summary")
                include_descriptive = st.checkbox("Statistiques descriptives", value=True, key="include_descriptive")
                include_correlations = st.checkbox("Matrice de corr√©lation", value=True, key="include_correlations")
                include_queries = st.checkbox("Requ√™tes personnalis√©es", value=True, key="include_queries")
                include_advanced = st.checkbox("Analyses avanc√©es", value=True, key="include_advanced")

            with col2:
                # Options de personnalisation
                st.markdown("**Personnalisation :**")

                primary_color = st.color_picker(
                    "Couleur principale",
                    "#4e73df",
                    key="report_primary_color"
                )

                secondary_color = st.color_picker(
                    "Couleur secondaire",
                    "#858796",
                    key="report_secondary_color"
                )

                font_family = st.selectbox(
                    "Police de caract√®res",
                    ["Arial, sans-serif", "Times New Roman, serif", "Courier New, monospace", "Georgia, serif"],
                    index=0,
                    key="report_font_family"
                )

                include_raw_data = st.checkbox(
                    "Inclure les donn√©es brutes",
                    value=st.session_state.get('include_raw_data', True),
                    key="include_raw_data"
                )

            if st.button("", key="generate_full_report_btn"):
                with st.spinner("Pr√©paration du rapport..."):
                    try:
                        # V√©rifier que df_clean est disponible et non vide
                        if 'df_clean' not in st.session_state or st.session_state.df_clean is None:
                            raise ValueError("Aucune donn√©e nettoy√©e disponible. Veuillez d'abord charger et nettoyer vos donn√©es.")
                            
                        if st.session_state.df_clean.empty:
                            raise ValueError("Le jeu de donn√©es nettoy√© est vide. Veuillez v√©rifier vos donn√©es d'entr√©e.")
                        
                        # Pr√©parer les donn√©es pour le rapport
                        try:
                            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns.tolist()
                            categorical_cols = st.session_state.df_clean.select_dtypes(
                                include=['object', 'category', 'bool']
                            ).columns.tolist()
                            
                            report_data = {
                                'metadata': {
                                    'title': 'Rapport d\'analyse avanc√©e',
                                    'author': AUTHOR_INFO['name'],
                                    'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                    'dataset_info': {
                                        'shape': st.session_state.df_clean.shape,
                                        'columns': st.session_state.df_clean.columns.tolist(),
                                        'numeric_columns': numeric_cols,
                                        'categorical_columns': categorical_cols
                                    }
                                },
                                'sections': {
                                    'summary': include_summary,
                                    'descriptive_stats': include_descriptive,
                                    'correlation_matrix': include_correlations and len(numeric_cols) > 1,
                                    'custom_queries': include_queries and bool(st.session_state.get('custom_queries')),
                                    'advanced_analyses': include_advanced
                                },
                                'style': {
                                    'primary_color': primary_color,
                                    'secondary_color': secondary_color,
                                    'font_family': font_family
                                },
                                'include_raw_data': include_raw_data,
                                # Ajout explicite des donn√©es n√©cessaires pour le rapport
                                'df_clean': st.session_state.df_clean,
                                'context': {
                                    'description': st.session_state.get('analysis_context', 'Aucun contexte fourni'),
                                    'objectives': st.session_state.get('analysis_objectives', 'Non d√©finis'),
                                    'suggested_queries': st.session_state.get('suggested_queries', [])
                                }
                            }
                            
                        except Exception as e:
                            st.error(f"Erreur lors de la pr√©paration des donn√©es du rapport: {str(e)}")
                            st.stop()

                        # Cr√©er le r√©pertoire des rapports s'il n'existe pas
                        base_reports_dir = Path("D:/Dev/Analyser/reports")
                        base_reports_dir.mkdir(parents=True, exist_ok=True)

                        # Nom de base du fichier
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        base_filename = f"rapport_analyse_avancee_{timestamp}"
                        output_path = str(base_reports_dir / base_filename)

                        # Exporter le rapport
                        export_path = export_report(
                            report_data=report_data,
                            output_path=output_path,
                            fmt=export_format.lower(),
                            style_options={
                                'primary_color': primary_color,
                                'secondary_color': secondary_color,
                                'font_family': font_family.split(',')[0],
                                'author_info': AUTHOR_INFO
                            }
                        )

                        # Stocker les donn√©es du rapport pour le t√©l√©chargement
                        with open(export_path, 'rb') as f:
                            st.session_state.report_data = f.read()

                        st.success("Rapport g√©n√©r√© avec succ√®s !")

                        # Afficher le bouton de t√©l√©chargement
                        st.download_button(
                            label="üì• T√©l√©charger le rapport",
                            data=st.session_state.report_data,
                            file_name=f"{base_filename}.{export_format.lower()}",
                            mime="application/octet-stream"
                        )

                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du rapport : {str(e)}")
                        st.exception(e)

        # Section d'interpr√©tation globale
        with st.expander("üìä Interpr√©tation globale de l'analyse", expanded=True):
            st.markdown("### Synth√®se des r√©sultats")
            
            if st.button("üîÑ G√©n√©rer l'interpr√©tation globale"):
                with st.spinner("G√©n√©ration de l'interpr√©tation globale en cours..."):
                    interpretation = generate_global_interpretation()
                    st.session_state.global_interpretation = interpretation
            
            if 'global_interpretation' in st.session_state:
                st.markdown(st.session_state.global_interpretation)
            else:
                st.info("Cliquez sur le bouton pour g√©n√©rer une interpr√©tation globale des analyses.")
                st.markdown("#### Types d'analyses √† effectuer")
                analysis_types = st.multiselect(
                    "S√©lectionnez les types d'analyses √† effectuer",
                    ["Statistiques descriptives", "Corr√©lations", "Clustering", "Analyse temporelle",
                     "Analyse de tendances", "Mod√©lisation pr√©dictive"],
                    default=["Statistiques descriptives", "Corr√©lations"],
                    key="global_analysis_types"
                )

        # Boutons de navigation
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("‚Üê Retour au nettoyage", use_container_width=True):
                st.session_state.step = 2
                st.rerun()
        with col2:
            if st.button("R√©initialiser l'analyse", use_container_width=True):
                st.session_state.df_clean = st.session_state.df_raw.copy()
                st.session_state.step = 3
                st.rerun()
        with col3:
            if st.button("Passer √† l'√©tape suivante ‚Üí", type="primary", use_container_width=True):
                st.session_state.step = 4
                st.rerun()

def generate_automated_conclusion():
    """
    G√©n√®re automatiquement une conclusion bas√©e sur les analyses disponibles dans la session.
    
    Returns:
        str: Une cha√Æne format√©e en markdown contenant la conclusion g√©n√©r√©e
    """
    conclusion = "### Synth√®se des principaux r√©sultats\n\n"
    
    # R√©cup√©rer les m√©triques de base si disponibles
    if hasattr(st.session_state, 'df_clean') and st.session_state.df_clean is not None:
        df = st.session_state.df_clean
        nb_lignes, nb_colonnes = df.shape
        
        # Ajouter des informations sur le jeu de donn√©es
        conclusion += f"- L'analyse a port√© sur un jeu de donn√©es de **{nb_lignes} lignes** et **{nb_colonnes} colonnes**\n"
        
        # Ajouter des informations sur les types de donn√©es
        types_donnees = df.dtypes.value_counts().to_dict()
        type_desc = ", ".join([f"{v} {k}" for k, v in types_donnees.items()])
        conclusion += f"- Types de donn√©es : {type_desc}\n"
    
    # Ajouter des informations sur les analyses sp√©cifiques si disponibles
    if hasattr(st.session_state, 'saved_interpretations') and st.session_state.saved_interpretations:
        nb_analyses = len(st.session_state.saved_interpretations)
        conclusion += f"- **{nb_analyses} analyses sp√©cifiques** ont √©t√© r√©alis√©es sur les donn√©es\n"
    
    # Section Recommandations
    conclusion += "\n### Recommandations\n\n"
    
    # Recommandations bas√©es sur la taille des donn√©es
    if hasattr(st.session_state, 'df_clean') and st.session_state.df_clean is not None:
        df = st.session_state.df_clean
        if len(df) > 10000:
            conclusion += "- **Volume important** : L'√©chantillon analys√© est cons√©quent. Pensez √† mettre en place des analyses plus pouss√©es comme des mod√®les pr√©dictifs.\n"
        elif len(df) < 100:
            conclusion += "- **√âchantillon limit√©** : Les r√©sultats pourraient b√©n√©ficier de davantage de donn√©es pour une meilleure robustesse.\n"
    
    # Recommandations g√©n√©rales
    conclusion += "- **Validation continue** : Ces r√©sultats devraient √™tre valid√©s sur de nouvelles donn√©es pour confirmer les tendances observ√©es.\n"
    conclusion += "- **Approfondissement** : Certaines analyses m√©riteraient d'√™tre approfondies avec des m√©thodes statistiques plus avanc√©es.\n"
    
    # Section Perspectives
    conclusion += "\n### Perspectives\n\n"
    conclusion += "- **Automatisation** : Mettre en place des tableaux de bord automatis√©s pour suivre l'√©volution des indicateurs cl√©s.\n"
    conclusion += "- **Analyse temporelle** : Si des donn√©es temporelles sont disponibles, une analyse des tendances serait pertinente.\n"
    conclusion += "- **Segmentation** : Explorer des analyses par segments pour identifier des sous-groupes int√©ressants.\n"
    
    # Ajouter les informations de contact
    conclusion += "\n---\n"
    conclusion += "*Rapport g√©n√©r√© automatiquement par Analyser IA - D√©velopp√© par Sidoine YEBADOKPO*  \n"
    conclusion += "*Contact : +229 01 96 91 13 46*"
    
    return conclusion

def render_report_step():
    """Affiche l'interface du rapport final d'analyse (√©tape 4)."""
    
    # Style CSS personnalis√© pour le rapport
    st.markdown("""
    <style>
        .main-title {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        .section-header {
            color: #2980b9;
            border-left: 4px solid #3498db;
            padding-left: 10px;
            margin-top: 30px;
        }
        .subsection {
            background-color: #f8f9fa;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
        }
        .contact-info {
            background-color: #e8f4fc;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 5px 5px 0;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # En-t√™te du rapport
    st.markdown("<h1 class='main-title'>üìä Rapport d'analyse complet</h1>", unsafe_allow_html=True)
    
    # Informations g√©n√©rales
    with st.container():
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown(f"### {st.session_state.get('project_name', 'Analyse sans titre')}")
            st.caption(f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}")
        with col2:
            st.caption(f"**Auteur:** {AUTHOR_INFO['name']}")
            st.caption(f"**Version:** {VERSION}")
    
    # 1. Introduction et pr√©sentation du contexte
    st.markdown("## 1. Introduction et contexte de l'analyse")
    with st.expander("üìã Contexte et objectifs", expanded=True):
        if 'project_name' in st.session_state and st.session_state.project_name:
            st.markdown(f"**Projet:** {st.session_state.project_name}")
        if 'industry' in st.session_state and st.session_state.industry:
            st.markdown(f"**Secteur d'activit√©:** {st.session_state.industry}")
        if 'analysis_context' in st.session_state and st.session_state.analysis_context:
            st.markdown("### Contexte")
            st.markdown(st.session_state.analysis_context)
        else:
            st.info("Aucun contexte d'analyse n'a √©t√© d√©fini.")
            
        if 'hypotheses' in st.session_state and st.session_state.hypotheses:
            st.markdown("### Hypoth√®ses")
            st.markdown(st.session_state.hypotheses)
            
        if 'constraints' in st.session_state and st.session_state.constraints:
            st.markdown("### Contraintes")
            st.markdown(st.session_state.constraints)
    
    # 2. Vue d'ensemble des donn√©es
    st.markdown("## 2. Vue d'ensemble des donn√©es")
    with st.expander("üìä Aper√ßu des donn√©es", expanded=True):
        st.dataframe(st.session_state.df_clean.head(10), use_container_width=True)
        st.caption(f"Dimensions des donn√©es : {st.session_state.df_clean.shape[0]:,} lignes x {st.session_state.df_clean.shape[1]:,} colonnes".replace(",", " "))
        
        # Statistiques rapides
        numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            st.markdown("### Statistiques descriptives")
            st.dataframe(st.session_state.df_clean[numeric_cols].describe().T, use_container_width=True)
    
    # 3. M√©thodologie d'analyse
    st.markdown("## 3. M√©thodologie d'analyse")
    with st.expander("üîç D√©tails de la m√©thodologie", expanded=False):
        st.markdown("""
        L'analyse a √©t√© r√©alis√©e selon la m√©thodologie suivante :
        
        ### 1. Pr√©paration des donn√©es
        - Nettoyage des valeurs manquantes et des doublons
        - D√©tection et traitement des valeurs aberrantes
        - Conversion des types de donn√©es appropri√©s
        
        ### 2. Analyse exploratoire
        - Statistiques descriptives
        - Visualisation des distributions
        - Identification des corr√©lations
        
        ### 3. Analyse approfondie
        - Tests statistiques
        - Mod√©lisation (si applicable)
        - Validation des hypoth√®ses
        
        ### 4. Interpr√©tation
        - Synth√®se des r√©sultats
        - Mise en perspective avec le contexte m√©tier
        - Recommandations actionnables
        """)
    
    # 4. R√©sultats d√©taill√©s
    st.markdown("## 4. R√©sultats d√©taill√©s")
    
    # 4.1. Interpr√©tation globale
    with st.expander("üìà Synth√®se des r√©sultats", expanded=True):
        if hasattr(st.session_state, 'global_interpretation'):
            st.markdown(st.session_state.global_interpretation)
        else:
            interpretation = generate_global_interpretation()
            st.session_state.global_interpretation = interpretation
            st.markdown(interpretation)
    
    # 4.2. Analyses sp√©cifiques
    if hasattr(st.session_state, 'saved_interpretations') and st.session_state.saved_interpretations:
        with st.expander("üìã D√©tails des analyses", expanded=False):
            for i, (title, content) in enumerate(st.session_state.saved_interpretations.items()):
                st.markdown(f"### {title}")
                st.markdown(content)
    
    # 5. Conclusion et recommandations
    st.markdown("## 5. Conclusion et recommandations")
    with st.expander("‚úÖ Synth√®se finale", expanded=True):
        if hasattr(st.session_state, 'analysis_conclusion') and st.session_state.analysis_conclusion:
            st.markdown(st.session_state.analysis_conclusion)
        else:
            conclusion = generate_automated_conclusion()
            st.session_state.analysis_conclusion = conclusion
            st.markdown(conclusion)
    
    # Section de contact
    st.markdown("## 6. Contact et informations compl√©mentaires")
    with st.expander("üìû Nous contacter", expanded=False):
        st.markdown("""
        <div class='contact-info'>
            <h3>Contact</h3>
            <p>Pour toute question ou demande d'information compl√©mentaire :</p>
            <p>üì± <strong>T√©l√©phone :</strong> +33 6 12 34 56 78</p>
            <p>üìß <strong>Email :</strong> contact@sidoineyebadokpo.com</p>
            <p>üåê <strong>Site web :</strong> <a href='https://sidoineyebadokpo.com' target='_blank'>sidoineyebadokpo.com</a></p>
        </div>
        """, unsafe_allow_html=True)
    
    # Boutons de navigation et d'export
    st.markdown("---")
    
    # Options d'export
    export_col1, export_col2 = st.columns([1, 1])
    
    with export_col1:
        export_format = st.selectbox(
            "Format d'export",
            ["PDF", "HTML", "Word"],
            key="export_format_selector"
        )
    
    with export_col2:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("üì• T√©l√©charger le rapport", 
                    type="primary", 
                    use_container_width=True,
                    key="download_report_btn"):
            st.session_state.show_export = True
    
    # Navigation
    nav_col1, nav_col2 = st.columns([1, 1])
    with nav_col1:
        if st.button("‚Üê Retour √† l'analyse", 
                    use_container_width=True,
                    key="back_to_analysis_btn"):
            st.session_state.step = 3
            st.rerun()
    with nav_col2:
        if st.button("üîÑ R√©g√©n√©rer les analyses", 
                    use_container_width=True,
                    key="regenerate_analysis_btn"):
            if 'global_interpretation' in st.session_state:
                del st.session_state.global_interpretation
            if 'analysis_conclusion' in st.session_state:
                del st.session_state.analysis_conclusion
            st.rerun()
            st.rerun()

def generate_global_interpretation():
    """G√©n√®re une interpr√©tation globale des analyses effectu√©es."""
    if not hasattr(st.session_state, 'analysis_metrics'):
        return "Aucune donn√©e d'analyse disponible pour g√©n√©rer une interpr√©tation."
    
    try:
        # Pr√©parer le contexte pour l'interpr√©tation globale
        context = "R√©sum√© global de l'analyse des donn√©es"
        
        # Ajouter le contexte utilisateur s'il existe
        if 'analysis_context' in st.session_state and st.session_state.analysis_context:
            context += f"\n\nContexte fourni par l'utilisateur: {st.session_state.analysis_context}"
        
        # Pr√©parer la description des donn√©es
        data_desc = "## M√©triques d'analyse collect√©es\n\n"
        
        # Ajouter les m√©triques num√©riques
        if hasattr(st.session_state, 'analysis_metrics') and st.session_state.analysis_metrics:
            data_desc += "### Variables num√©riques\n"
            for var, metrics in st.session_state.analysis_metrics.items():
                data_desc += f"- **{var}**: "
                data_desc += f"{metrics['valeurs_uniques']} valeurs uniques, "
                data_desc += f"{metrics['valeurs_manquantes']} valeurs manquantes"
                if metrics['moyenne'] is not None:
                    data_desc += f", moyenne: {metrics['moyenne']:.2f}, "
                    data_desc += f"√©cart-type: {metrics['ecart_type']:.2f}"
                data_desc += "\n"
        
        # Ajouter les m√©triques cat√©gorielles
        if hasattr(st.session_state, 'categorical_metrics') and st.session_state.categorical_metrics:
            data_desc += "\n### Variables cat√©gorielles\n"
            for var, metrics in st.session_state.categorical_metrics.items():
                data_desc += (
                    f"- **{var}**: {metrics['nb_categories']} cat√©gories, "
                    f"la plus fr√©quente est '{metrics['categorie_principale']}' "
                    f"({metrics['freq_categorie_principale']}/{metrics['total']} soit "
                    f"{metrics['freq_categorie_principale']/metrics['total']*100:.1f}%)\n"
                )
        
        # Ajouter les informations de corr√©lation
        if hasattr(st.session_state, 'correlation_metrics') and st.session_state.correlation_metrics:
            nb_vars = st.session_state.correlation_metrics['nb_variables']
            if nb_vars > 1:
                data_desc += f"\n### Analyse des corr√©lations\n"
                data_desc += f"{nb_vars} variables num√©riques analys√©es pour les corr√©lations.\n"
        
        # G√©n√©rer l'interpr√©tation avec l'IA
        interpretation = generate_ai_interpretation(
            context=context,
            data_description=data_desc,
            chart_type="global_analysis"
        )
        
        return interpretation if interpretation else "Impossible de g√©n√©rer une interpr√©tation pour le moment."
    
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration de l'interpr√©tation globale: {str(e)}")
        return f"Erreur lors de la g√©n√©ration de l'interpr√©tation: {str(e)}"

# Section pour l'export final
with st.expander("üì§ Export final", expanded=False):
    st.markdown("### Options d'export final")

    export_options = st.multiselect(
        "S√©lectionnez les √©l√©ments √† exporter",
        ["Donn√©es nettoy√©es", "Rapport complet", "Code des analyses", "Visualisations"],
        default=["Donn√©es nettoy√©es", "Rapport complet"]
    )

    export_format = st.selectbox(
        "Format d'export",
        ["ZIP (tous les formats)", "CSV", "Excel", "HTML", "PDF"],
        index=0
    )

    if st.button("Exporter les r√©sultats", type="primary"):
        with st.spinner("Pr√©paration de l'export..."):
            try:
                # Cr√©er le r√©pertoire d'export avec horodatage
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                export_dir = REPORTS_DIR / f"export_analyse_{timestamp}"
                export_dir.mkdir(parents=True, exist_ok=True)

                # Informations de contact
                author_info = {
                    'name': 'Sidoine YEBADOKPO',
                    'title': 'Data Analyst/Scientist Freelance',
                    'phone': '+229 01 96 91 13 46',
                    'email': 'yebadokposidoine2000@gmail.com',
                    'website': 'www.sidoine-yebadokpo.com'
                }

                # Exporter les donn√©es nettoy√©es
                if "Donn√©es nettoy√©es" in export_options:
                    csv_path = export_dir / "donnees_nettoyees.csv"
                    st.session_state.df_clean.to_csv(csv_path, index=False)
                    excel_path = export_dir / "donnees_nettoyees.xlsx"
                    st.session_state.df_clean.to_excel(excel_path, index=False)

                # Exporter le rapport
                if "Rapport complet" in export_options:
                    report_data = {
                        'metadata': {
                            'title': "Rapport d'analyse complet",
                            'author': author_info['name'],
                            'contact': author_info['phone'],
                            'email': author_info['email'],
                            'website': author_info['website'],
                            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        },
                        'context': st.session_state.get('analysis_context', ''),
                        'objectives': st.session_state.get('analysis_objectives', ''),
                        'df_clean': st.session_state.df_clean,
                        'analysis_results': st.session_state.get('analysis_results', {}),
                        'preprocessing_steps': st.session_state.get('preprocessing_steps', []),
                        'custom_queries': {
                            'sql': st.session_state.get('sql_queries', []),
                            'python': st.session_state.get('python_queries', [])
                        },
                        'author_info': author_info
                    }

                    # G√©n√©rer le rapport HTML
                    html_path = export_dir / "rapport_complet.html"
                    try:
                        export_report(report_data, str(html_path), fmt='html')
                        st.success(f"Rapport HTML g√©n√©r√© avec succ√®s : {html_path}")
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du rapport HTML : {str(e)}")

                    # G√©n√©rer le rapport PDF si disponible
                    if _PDF_AVAILABLE:
                        pdf_path = export_dir / "rapport_complet.pdf"
                        try:
                            export_report(report_data, str(pdf_path), fmt='pdf')
                            st.success(f"Rapport PDF g√©n√©r√© avec succ√®s : {pdf_path}")
                        except Exception as e:
                            st.warning(f"Impossible de g√©n√©rer le PDF : {str(e)}")

                # Exporter le code
                if "Code des analyses" in export_options:
                    code_path = export_dir / "code_analyses.py"
                    with open(code_path, 'w', encoding='utf-8') as f:
                        f.write("# Code g√©n√©r√© par Analyser IA\n")
                        f.write("# D√©velopp√© par Sidoine YEBADOKPO\n")
                        f.write("# Contact: +229 01 96 91 13 46\n")
                        f.write("# Date: " + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + "\n\n")
                        
                        # Ajouter les requ√™tes SQL
                        if st.session_state.get('sql_queries'):
                            f.write("# Requ√™tes SQL ex√©cut√©es\n")
                            for query in st.session_state.sql_queries:
                                f.write(f"# {query}\n")
                                f.write(f"result = sqldf(\"\"\"{query}\"\"\", {{'df': df}})\n\n")

                        # Ajouter les requ√™tes Python
                        if st.session_state.get('python_queries'):
                            f.write("# Code Python ex√©cut√©\n")
                            for code in st.session_state.python_queries:
                                    f.write(f"# {code}\n")
                                    f.write(f"{code}\n\n")

                    # Exporter les visualisations
                    if "Visualisations" in export_options:
                        try:
                            viz_dir = export_dir / "visualisations"
                            viz_dir.mkdir(exist_ok=True)
                            
                            # Exporter quelques visualisations de base
                            numeric_cols = st.session_state.df_clean.select_dtypes(include=['number']).columns
                            
                            if len(numeric_cols) > 0:
                                # Cr√©er un histogramme pour chaque colonne num√©rique (max 3)
                                for col in numeric_cols[:3]:
                                    try:
                                        import plotly.express as px
                                        fig = px.histogram(
                                            st.session_state.df_clean, 
                                            x=col, 
                                            title=f'Distribution de {col}',
                                            labels={col: 'Valeurs'},
                                            width=800,
                                            height=500
                                        )
                                        fig_path = viz_dir / f"histogram_{col}.png"
                                        fig.write_image(str(fig_path))
                                    except Exception as e:
                                        st.warning(f"Impossible d'exporter la visualisation pour {col}: {str(e)}")
                            else:
                                st.warning("Aucune colonne num√©rique trouv√©e pour g√©n√©rer des visualisations.")
                        except Exception as e:
                            st.warning(f"Erreur lors de la cr√©ation des visualisations: {str(e)}")

                # Cr√©er une archive ZIP si n√©cessaire
                if export_format == "ZIP (tous les formats)":
                    shutil.make_archive(str(export_dir), 'zip', export_dir)
                    export_path = f"{str(export_dir)}.zip"
                    mime_type = "application/zip"
                else:
                    # Trouver le fichier correspondant au format demand√©
                    if export_format == "CSV" and "Donn√©es nettoy√©es" in export_options:
                        file_path = csv_path
                        mime_type = "text/csv"
                    elif export_format == "Excel" and "Donn√©es nettoy√©es" in export_options:
                        file_path = excel_path
                        mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    elif export_format == "HTML" and "Rapport complet" in export_options:
                        file_path = html_path
                        mime_type = "text/html"
                    elif export_format == "PDF" and "Rapport complet" in export_options:
                        file_path = pdf_path
                        mime_type = "application/pdf"
                    else:
                        # Par d√©faut, cr√©er une archive ZIP
                        shutil.make_archive(str(export_dir), 'zip', export_dir)
                        export_path = f"{str(export_dir)}.zip"
                        mime_type = "application/zip"

                # T√©l√©charger le fichier
                if export_format == "ZIP (tous les formats)":
                    with open(export_path, "rb") as f:
                        st.download_button(
                            label="T√©l√©charger l'archive ZIP",
                            data=f,
                            file_name=f"export_analyse_{timestamp}.zip",
                            mime=mime_type
                        )
                else:
                    with open(file_path, "rb") as f:
                        st.download_button(
                            label=f"T√©l√©charger le fichier {export_format}",
                            data=f,
                            file_name=file_path.name,
                            mime=mime_type
                        )

                st.success("Export termin√© avec succ√®s !")

            except Exception as e:
                st.error(f"Erreur lors de l'export: {str(e)}")
                st.exception(e)

# Boutons de navigation
col1, col2 = st.columns([1, 1])
with col1:
    if st.button("‚Üê Retour √† l'analyse", use_container_width=True):
        st.session_state.step = 3
        st.rerun()
with col2:
    if st.button("G√©n√©rer le rapport final ‚Üí", type="primary", use_container_width=True):
        st.session_state.step = 4
        st.rerun()

# ============================================
# 5. Point d'entr√©e principal
# ============================================

@st.cache_resource(ttl=3600)
def load_assets():
    """Charge les ressources statiques (mod√®les, donn√©es de r√©f√©rence, etc.)."""
    # Cette fonction est mise en cache pour √©viter de recharger les ressources √† chaque interaction
    assets = {
        'example_datasets': {
            'iris': px.data.iris(),
            'tips': px.data.tips(),
            'gapminder': px.data.gapminder(),
        },
        'templates': {
            'analysis': {
                'exploratoire': """# Analyse exploratoire des donn√©es

## 1. Aper√ßu des donn√©es

### Dimensions
- Nombre d'observations : {n_rows}
- Nombre de variables : {n_cols}

### Types de donn√©es
{data_types}

## 2. Statistiques descriptives

### Variables num√©riques
{num_stats}

### Variables cat√©gorielles
{cat_stats}
"""
            }
        }
    }
    return assets

def log_interaction(action: str, details: dict = None):
    """Enregistre une interaction utilisateur pour l'analyse d'usage."""
    if details is None:
        details = {}
    
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'step': st.session_state.step,
        'action': action,
        'details': details,
        'session_duration': (datetime.now() - st.session_state.app_start_time).total_seconds()
    }
    
    # En production, on enverrait ces donn√©es √† un service d'analyse
    if st.secrets.get("ENV") == "production":
        pass  # Int√©gration avec un service d'analyse

def handle_errors(func: Callable) -> Callable:
    """D√©corateur pour g√©rer les erreurs de mani√®re √©l√©gante."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            error_details = {
                'error': str(e),
                'type': type(e).__name__,
                'traceback': traceback.format_exc()
            }
            log_interaction('error', error_details)
            error_message("Une erreur est survenue lors de l'ex√©cution.")
            st.error("D√©tails techniques : " + str(e))
            if st.checkbox("Afficher les d√©tails de l'erreur"):
                st.code(traceback.format_exc())
    return wrapper

def main():
    """Point d'entr√©e principal de l'application."""
    try:
        # Initialisation
        init_session_state()
        
        # Mise √† jour de la derni√®re interaction
        st.session_state.last_interaction = datetime.now()
        
        # Chargement des ressources
        assets = load_assets()
        
        # Barre lat√©rale
        render_sidebar()
        
        # Affichage des notifications
        if 'notifications' in st.session_state and st.session_state.notifications:
            for notification in st.session_state.notifications:
                if notification['type'] == 'success':
                    success_message(notification['message'])
                elif notification['type'] == 'error':
                    error_message(notification['message'])
                elif notification['type'] == 'warning':
                    warning_message(notification['message'])
            st.session_state.notifications = []
        
        # Gestion des √©tapes
        with st.spinner(f"Chargement de l'√©tape {st.session_state.step + 1}..."):
            if st.session_state.step == 0:
                render_context_step()
            elif st.session_state.step == 1:
                render_loading_step()
            elif st.session_state.step == 2:
                render_cleaning_step()
            elif st.session_state.step == 3:
                render_analysis_step()
            elif st.session_state.step == 4:
                render_report_step()
    except Exception as e:
        st.error(f"Une erreur inattendue s'est produite : {str(e)}")
        st.exception(e)
    finally:
        # Nettoyage des ressources si n√©cessaire
        pass



def generate_goal_based_suggestions(goals_text, numeric_cols, cat_cols, date_cols, max_suggestions=3):
    """
    G√©n√®re des suggestions d'analyse bas√©es sur les objectifs de l'utilisateur.
    
    Args:
        goals_text: Texte des objectifs d'analyse de l'utilisateur
        numeric_cols: Liste des colonnes num√©riques
        cat_cols: Liste des colonnes cat√©gorielles
        date_cols: Liste des colonnes de date
        max_suggestions: Nombre maximum de suggestions √† g√©n√©rer
        
    Returns:
        list: Liste de suggestions bas√©es sur les objectifs
    """
    if not goals_text:
        return []
        
    goals_text = goals_text.lower()
    suggestions = []
    
    # D√©tection des mots-cl√©s dans les objectifs
    if any(word in goals_text for word in ['tendance', '√©volution', 'pr√©voir', 'pr√©dire', 'futur']):
        if date_cols and numeric_cols:
            date_var = date_cols[0]
            num_var = next((col for col in numeric_cols if col != date_var), numeric_cols[0])
            suggestions.append({
                'title': f'üìà Pr√©vision de {num_var}',
                'description': f'Pr√©vision de {num_var} avec un mod√®le de s√©rie temporelle',
                'query': f'Cr√©e une pr√©vision de {num_var} pour les 12 prochaines p√©riodes en utilisant un mod√®le de s√©rie temporelle',
                'code_type': 'Python',
                'priority': 2
            })
    
    if any(word in goals_text for word in ['groupe', 'segment', 'cluster', 'regrouper']):
        if len(numeric_cols) >= 2:
            suggestions.append({
                'title': 'üîç Analyse des segments',
                'description': 'Regroupement des donn√©es en segments homog√®nes',
                'query': 'Effectue une analyse de clustering pour identifier des segments dans les donn√©es',
                'code_type': 'Python',
                'priority': 2
            })
    
    if any(word in goals_text for word in ['anomalie', 'erreur', 'incoh√©rence', 'anormal']):
        if numeric_cols:
            num_var = numeric_cols[0]
            suggestions.append({
                'title': f'‚ö†Ô∏è D√©tection des anomalies dans {num_var}',
                'description': f'Identification des valeurs aberrantes dans {num_var}',
                'query': f'D√©tecte et affiche les valeurs aberrantes dans la colonne {num_var} en utilisant la m√©thode IQR',
                'code_type': 'Python',
                'priority': 2
            })
    
    if any(word in goals_text for word in ['comparer', 'diff√©rence', 'contraste']):
        if cat_cols and numeric_cols:
            cat_var = cat_cols[0]
            num_var = next((col for col in numeric_cols if col != cat_var), numeric_cols[0])
            suggestions.append({
                'title': f'üîÑ Comparaison de {num_var} par {cat_var}',
                'description': f'Comparaison statistique de {num_var} entre les groupes de {cat_var}',
                'query': f'Compare la distribution de {num_var} entre les diff√©rentes cat√©gories de {cat_var} avec un test statistique',
                'code_type': 'Python',
                'priority': 1
            })
    
    # Trier par priorit√© et limiter le nombre de suggestions
    suggestions.sort(key=lambda x: -x.get('priority', 0))
    return suggestions[:max_suggestions]


def generate_analysis_suggestions(numeric_cols, cat_cols, date_cols, max_suggestions=6):
    """
    G√©n√®re des suggestions d'analyse bas√©es sur les variables disponibles et le contexte utilisateur.
    
    Args:
        numeric_cols: Liste des colonnes num√©riques
        cat_cols: Liste des colonnes cat√©gorielles
        date_cols: Liste des colonnes de date
        max_suggestions: Nombre maximum de suggestions √† g√©n√©rer
        
    Returns:
        list: Liste de dictionnaires contenant les suggestions d'analyse avec titre, description,
              m√©thodologie et code associ√©
    """
    suggestions = []
    df = st.session_state.get('df_clean')
    
    # R√©cup√©rer le contexte utilisateur s'il existe
    analysis_goals = st.session_state.get('analysis_goals', '').lower()
    analysis_context = st.session_state.get('analysis_context', '').lower()
    
    # 1. Analyse de corr√©lation entre variables num√©riques (si au moins 2 variables num√©riques)
    if len(numeric_cols) >= 2:
        # Prendre jusqu'√† 5 variables num√©riques pour la corr√©lation
        corr_vars = numeric_cols[:min(5, len(numeric_cols))]
        
        # G√©n√©rer une description plus d√©taill√©e
        desc = "Analyse des relations lin√©aires entre variables num√©riques cl√©s. "
        desc += "Permet d'identifier des patterns et des relations potentielles dans vos donn√©es."
        
        suggestions.append({
            'title': 'üìä Matrice de corr√©lation',
            'description': desc,
            'query': f'G√©n√®re une matrice de corr√©lation entre les variables {", ".join(corr_vars[:3])}...',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['relation', 'corr√©lation', 'lien']) else 0
        })
    
    # 2. Analyse de distribution pour les variables cat√©gorielles
    if cat_cols and numeric_cols:
        cat_var = cat_cols[0]
        num_var = next((col for col in numeric_cols if col != cat_var), numeric_cols[0])
        
        suggestions.append({
            'title': f'üì¶ Distribution de {num_var} par {cat_var}',
            'description': f'Analyse de la distribution de {num_var} selon les cat√©gories de {cat_var}.',
            'query': f'Affiche un boxplot de {num_var} group√© par {cat_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['distribution', 'comparaison', 'diff√©rence']) else 0
        })
    
    # 3. Analyse temporelle si des dates sont disponibles
    if date_cols and numeric_cols:
        date_var = date_cols[0]
        value_var = next((col for col in numeric_cols if col != date_var), numeric_cols[0])
        
        suggestions.append({
            'title': f'üìà √âvolution temporelle de {value_var}',
            'description': f'Analyse de l\'√©volution de {value_var} dans le temps.',
            'query': f'Affiche l\'√©volution de {value_var} en fonction du temps ({date_var})',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['tendance', '√©volution', 'temporel']) else 0
        })
    
    # 4. Analyse des valeurs manquantes
    missing_cols = df.isnull().sum()
    if not missing_cols.empty and missing_cols.sum() > 0:
        suggestions.append({
            'title': 'üîç Analyse des valeurs manquantes',
            'description': 'Identification et quantification des valeurs manquantes dans le jeu de donn√©es.',
            'query': 'Affiche le nombre et le pourcentage de valeurs manquantes par colonne',
            'code_type': 'Python',
            'priority': 0
        })
    
    # 5. Analyse des valeurs uniques pour les variables cat√©gorielles
    if cat_cols:
        cat_var = cat_cols[0]
        suggestions.append({
            'title': f'üè∑Ô∏è Distribution de {cat_var}',
            'description': f'Analyse de la distribution des valeurs dans la colonne {cat_var}.',
            'query': f'Affiche la distribution des valeurs uniques de {cat_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['fr√©quence', 'distribution', 'cat√©gorie']) else 0
        })
    
    # 6. Analyse bivari√©e pour les variables num√©riques
    if len(numeric_cols) >= 2:
        x_var, y_var = numeric_cols[:2]
        suggestions.append({
            'title': f'üîÑ Relation entre {x_var} et {y_var}',
            'description': f'Analyse de la relation entre {x_var} et {y_var} avec un nuage de points.',
            'query': f'Affiche un nuage de points de {y_var} en fonction de {x_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['relation', 'corr√©lation', 'lien']) else 0
        })
    
    # 7. Analyse de la distribution des variables num√©riques
    if numeric_cols:
        num_var = numeric_cols[0]
        suggestions.append({
            'title': f'üìâ Distribution de {num_var}',
            'description': f'Analyse de la distribution de la variable num√©rique {num_var}.',
            'query': f'Affiche un histogramme de la distribution de {num_var}',
            'code_type': 'Python',
            'priority': 0
        })
    
    # 8. Analyse des valeurs aberrantes
    if numeric_cols:
        num_var = numeric_cols[0]
        suggestions.append({
            'title': f'‚ö†Ô∏è D√©tection des valeurs aberrantes dans {num_var}',
            'description': f'Identification des valeurs aberrantes dans la colonne {num_var}.',
            'query': f'D√©tecte et affiche les valeurs aberrantes dans {num_var}',
            'code_type': 'Python',
            'priority': 1 if 'aberrant' in analysis_goals or 'anomalie' in analysis_goals else 0
        })
    
    # 9. Analyse temporelle avanc√©e (saisonnalit√©, tendance)
    if date_cols and numeric_cols and len(date_cols) > 0 and len(numeric_cols) > 0:
        date_var = date_cols[0]
        value_var = next((col for col in numeric_cols if col != date_var), numeric_cols[0])
        suggestions.append({
            'title': f'üìÖ Analyse de saisonnalit√© de {value_var}',
            'description': f'Analyse des motifs saisonniers pour {value_var} au fil du temps.',
            'query': f'Analyse la saisonnalit√© de {value_var} par mois/ann√©e',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['saison', 'tendance', 'p√©riodicit√©']) else 0
        })
    
    # 10. Analyse des agr√©gations par cat√©gorie
    if cat_cols and numeric_cols:
        cat_var = cat_cols[0]
        num_var = next((col for col in numeric_cols if col != cat_var), numeric_cols[0])
        suggestions.append({
            'title': f'üìä Agr√©gations de {num_var} par {cat_var}',
            'description': f'Calcul des statistiques agr√©g√©es de {num_var} pour chaque cat√©gorie de {cat_var}.',
            'query': f'Calcule les statistiques (moyenne, m√©diane, etc.) de {num_var} group√© par {cat_var}',
            'code_type': 'Python',
            'priority': 1 if any(word in analysis_goals for word in ['agr√©gation', 'moyenne', 'comparaison']) else 0
        })
    
    # Trier les suggestions par priorit√© (les plus pertinentes en premier)
    suggestions.sort(key=lambda x: (-x.get('priority', 0), x['title']))
    
    # Limiter le nombre de suggestions
    return suggestions[:max_suggestions][:max_suggestions]

# ============================================
# 6. Fonctions utilitaires
# ============================================
def safe_json(obj: Any, label: str) -> None:
    """Affiche un objet JSON ou une erreur lisible si ce n'est pas un dict."""
    st.subheader(label)
    if isinstance(obj, dict):
        st.json(obj, expanded=False)
    else:
        st.error(str(obj))

def reset_analysis():
    """R√©initialise les √©tapes d'analyse."""
    st.session_state.df_clean = None
    st.session_state.step = 1

def detect_column_type(column_name: str, df_columns: list) -> str:
    """D√©tecte le type d'une colonne bas√© sur son nom."""
    col_lower = str(column_name).lower()
    
    # D√©tection des types de colonnes courants
    if any(word in col_lower for word in ['date', 'jour', 'mois', 'annee', 'year', 'month', 'day']):
        return 'date'
    elif any(word in col_lower for word in ['prix', 'montant', 'valeur', 'quantite', 'qte', 'amount', 'price', 'value', 'total', 'cout', 'co√ªt']):
        return 'numeric'
    elif any(word in col_lower for word in ['nom', 'prenom', 'name', 'ville', 'pays', 'pays', 'adresse', 'email', 'telephone']):
        return 'text'
    elif any(word in col_lower for word in ['actif', 'valide', 'est_', 'has_', 'is_']):
        return 'boolean'
    return 'unknown'

def find_best_columns(query: str, df_columns: list, target_type: str = None) -> list:
    """Trouve les colonnes les plus pertinentes en fonction de la requ√™te."""
    query_terms = set(query.lower().split())
    best_matches = []
    
    for col in df_columns:
        col_str = str(col).lower()
        col_terms = set(col_str.split('_'))
        
        # V√©rifier le type de colonne si sp√©cifi√©
        if target_type and detect_column_type(col, df_columns) != target_type:
            continue
            
        # Calculer le score de correspondance
        score = len(query_terms.intersection(col_terms))
        if score > 0:
            best_matches.append((col, score))
    
    # Trier par score d√©croissant
    best_matches.sort(key=lambda x: x[1], reverse=True)
    return [col for col, _ in best_matches]

def generate_sql_query(query: str, df_columns: list) -> str:
    """
    G√©n√®re une requ√™te SQL √† partir d'une description en langage naturel.
    
    Args:
        query: La description en langage naturel de la requ√™te
        df_columns: Liste des colonnes disponibles dans le DataFrame
        
    Returns:
        str: La requ√™te SQL g√©n√©r√©e
    """
    try:
        # Pr√©paration du contexte pour l'API
        columns_str = "\n- " + "\n- ".join(df_columns)
        
        prompt = f"""
        Tu es un expert en SQL et en analyse de donn√©es. Ton r√¥le est de g√©n√©rer des requ√™tes SQL pr√©cises et optimis√©es
        √† partir de descriptions en langage naturel. Voici les colonnes disponibles dans la table 'df':
        {columns_str}
        
        R√®gles importantes √† suivre :
        1. Toujours utiliser des noms de colonnes exacts (respecter la casse)
        2. Utiliser des alias explicites pour les colonnes calcul√©es
        3. Inclure des commentaires explicatifs pour les parties complexes
        4. Optimiser les requ√™tes pour la performance
        5. Pour les agr√©gations, toujours inclure un GROUP BY appropri√©
        6. Pour les tris, toujours sp√©cifier l'ordre (ASC ou DESC)
        7. Utiliser des guillemets doubles pour les noms de colonnes
        8. Inclure une clause LIMIT appropri√©e pour les grands jeux de donn√©es
        9. G√©rer correctement les valeurs NULL avec COALESCE si n√©cessaire
        
        Exemples de requ√™tes :
        - "Afficher les 10 produits les plus chers" :
          SELECT * FROM df ORDER BY "prix" DESC LIMIT 10;
          
        - "Compter le nombre de produits par cat√©gorie" :
          SELECT "categorie", COUNT(*) AS nb_produits 
          FROM df 
          GROUP BY "categorie" 
          ORDER BY nb_produits DESC;
          
        - "Calculer la moyenne des ventes par mois" :
          SELECT 
              STRFTIME('%Y-%m', "date_vente") AS mois,
              AVG("montant") AS moyenne_ventes,
              COUNT(*) AS nb_ventes
          FROM df
          WHERE "date_vente" IS NOT NULL
          GROUP BY STRFTIME('%Y-%m', "date_vente")
          HAVING COUNT(*) > 5  -- Exclure les mois avec peu de donn√©es
          ORDER BY mois;
          
        - "Trouver les doublons" :
          SELECT "colonne1", "colonne2", COUNT(*) AS occurrences
          FROM df
          GROUP BY "colonne1", "colonne2"
          HAVING COUNT(*) > 1
          ORDER BY occurrences DESC;
        
        Requ√™te √† g√©n√©rer : {query}
        
        R√©ponds UNIQUEMENT avec la requ√™te SQL, sans commentaires ni explications suppl√©mentaires.
        """
        
        # Appel √† l'API Gemini pour g√©n√©rer la requ√™te
        response = call_gemini_api(prompt)
        
        # Nettoyage de la r√©ponse
        if response:
            # Extraction du code SQL entre les balises ```sql ou ```
            import re
            sql_match = re.search(r'```(?:sql)?\n?(.*?)\n?```', response, re.DOTALL)
            if sql_match:
                return sql_match.group(1).strip()
            return response.strip()
        else:
            raise ValueError("Aucune r√©ponse de l'API")
            
    except Exception as e:
        # En cas d'erreur, on retourne une requ√™te simple mais valide
        error_msg = f"-- Erreur lors de la g√©n√©ration : {str(e)}\n"
        error_msg += "-- Voici une requ√™te par d√©faut que vous pouvez adapter :\n"
        error_msg += "SELECT * FROM df LIMIT 10;"
        return error_msg

def generate_python_code(query: str, df_columns: list) -> str:
    """
    G√©n√®re du code Python √† partir d'une description en langage naturel.
    
    Args:
        query: Description en langage naturel de la requ√™te
        df_columns: Liste des colonnes disponibles dans le DataFrame
        
    Returns:
        str: Le code Python g√©n√©r√©
    """
    try:
        # Pr√©paration du contexte pour l'IA
        columns_str = "\n- " + "\n- ".join(df_columns)
        
        prompt = f"""
        Tu es un expert en analyse de donn√©es avec Python. Ton r√¥le est de g√©n√©rer du code Python
        pour analyser un DataFrame pandas √† partir d'une description en langage naturel.
        
        Le DataFrame s'appelle 'df' et contient les colonnes suivantes :
        {columns_str}
        
        R√®gles importantes √† suivre :
        1. Utiliser les bonnes pratiques de pandas pour des performances optimales
        2. Inclure des commentaires explicites
        3. G√©rer les valeurs manquantes si n√©cessaire
        4. Utiliser des visualisations appropri√©es quand c'est pertinent
        5. Le r√©sultat final doit √™tre stock√© dans une variable 'result'
        6. Toujours inclure des librairies n√©cessaires (pandas, matplotlib, seaborn, etc.)
        7. Utiliser des noms de variables explicites
        8. Ajouter des titres et des labels aux graphiques
        
        Exemples de requ√™tes :
        - "Afficher les 10 premi√®res lignes" :
          # Afficher les 10 premi√®res lignes du DataFrame
          result = df.head(10)
          
        - "Afficher les statistiques descriptives" :
          # Statistiques descriptives pour les colonnes num√©riques
          result = df.describe(include='all')
          
        - "Afficher un histogramme des prix" :
          # Importer les librairies n√©cessaires
          import matplotlib.pyplot as plt
          import seaborn as sns
          
          # Configuration du style des graphiques
          sns.set(style="whitegrid")
          
          # Cr√©ation de la figure
          plt.figure(figsize=(12, 6))
          
          # Tracer l'histogramme
          sns.histplot(data=df, x='prix', bins=30, kde=True)
          
          # Personnalisation du graphique
          plt.title('Distribution des prix', fontsize=14, pad=20)
          plt.xlabel('Prix (en ‚Ç¨)', fontsize=12)
          plt.ylabel('Fr√©quence', fontsize=12)
          
          # Afficher la grille
          plt.grid(True, linestyle='--', alpha=0.7)
          
          # Ajuster les marges
          plt.tight_layout()
          
          # Afficher le graphique
          plt.show()
          
          # Retourner les statistiques descriptives
          result = df['prix'].describe()
          
        - "Afficher la corr√©lation entre les variables num√©riques" :
          # Calcul de la matrice de corr√©lation
          correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()
          
          # Cr√©ation d'une heatmap de corr√©lation
          plt.figure(figsize=(12, 10))
          sns.heatmap(correlation_matrix, 
                     annot=True, 
                     cmap='coolwarm', 
                     center=0,
                     fmt=".2f",
                     linewidths=0.5)
          plt.title('Matrice de corr√©lation des variables num√©riques', fontsize=14, pad=20)
          plt.xticks(rotation=45, ha='right')
          plt.tight_layout()
          plt.show()
          
          result = correlation_matrix
          
        Requ√™te √† traiter : {query}
        
        R√©ponds UNIQUEMENT avec le code Python, sans commentaires ni explications suppl√©mentaires.
        """
        
        # Appel √† l'API Gemini
        response = call_gemini_api(prompt)
        
        # Nettoyage de la r√©ponse
        if response:
            # Extraction du code Python entre les balises ```python ou ```
            import re
            python_match = re.search(r'```(?:python)?\n?(.*?)\n?```', response, re.DOTALL)
            if python_match:
                return python_match.group(1).strip()
            return response.strip()
        else:
            raise ValueError("Aucune r√©ponse de l'API")
            
    except Exception as e:
        # En cas d'erreur, on retourne un code minimal
        error_msg = f"""# Erreur lors de la g√©n√©ration du code : {str(e)}
# Voici un exemple de code que vous pouvez adapter :

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Afficher les premi√®res lignes du DataFrame
result = df.head()
"""
        return error_msg

def generate_code_from_natural_language(query: str, query_type: str, df_columns: list) -> str:
    """
    G√©n√®re du code SQL ou Python √† partir d'une description en langage naturel.
    
    Args:
        query: La description en langage naturel
        query_type: 'sql' ou 'python'
        df_columns: Liste des colonnes disponibles dans le DataFrame

    Returns:
        str: Le code g√©n√©r√©
    """
    try:
        # Nettoyage de la requ√™te
        query = query.strip().strip('\'"').strip()
        
        if query_type.lower() == 'sql':
            return generate_sql_query(query, df_columns)
        else:  # Python
            return generate_python_code(query, df_columns)
                
    except Exception as e:
        error_msg = f"""# Erreur lors de la g√©n√©ration du code
# D√©tails de l'erreur: {str(e)}

# Voici un exemple de requ√™te de base que vous pouvez adapter:
# Pour SQL: SELECT * FROM df LIMIT 10
# Pour Python: df.head()
"""
        return error_msg

# ============================================
# 7. Ex√©cution de l'application
# ============================================

if __name__ == "__main__":
    main()

# La barre lat√©rale est maintenant g√©r√©e par la fonction render_sidebar()
# Cette section a √©t√© supprim√©e car elle √©tait en double
